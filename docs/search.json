[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Dise√±os experimentales y cuasiexperimentales",
    "section": "",
    "text": "Prefacio\nEste libro surge con la intenci√≥n de acompa√±ar a los estudiantes de la materia Dise√±o experimentales y cuasiexperimentales correspondiente a la carrera de Licenciatura en Ciencias del Comportamiento de la Universidad de San Andr√©s (Victoria, Argentina). Sin embargo, este libro no contiene todo los materiales de la materia, sino m√°s bien es una gu√≠a que nos permite comprender conceptos b√°sicos e identificar lo importante en cada tema. De forma complementaria, en cada cap√≠tulo se brindar√° una lista de bibliograf√≠a recomendada.",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "intro_R.html",
    "href": "intro_R.html",
    "title": "1¬† R y el tidyverse",
    "section": "",
    "text": "1.1 Tidy data\nLo primero que tenemos que pensar cuando trabajamos con el tidyverse es que nuestros datos est√©n en formato tidy. ¬øQu√© significa esto? Cuando un dataset est√° en formato tidy, cada columna corresponde a una variable y cada fila a una √∫nica observaci√≥n2. Veamos un ejemplo. Tenemos tres sujetos a los cuales les medimos el tiempo de respuesta en una tarea. Cada sujeto realiza dos repeticiones de esta medici√≥n, el trial 1 y el trial 2. En la tabla Tabla¬†1.1 podemos ver las dos formas de organizar esta informaci√≥n.\nA lo largo de este cap√≠tulo iremos viendo los beneficios de almacenar los datos en formato tidy. Por supuesto que estas ventajas tienen su precio, principalemente que las bases de datos crecen mucho en tama√±o si tenemos muchas medidas repetidas con distintos valores de las variables.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>R y el tidyverse</span>"
    ]
  },
  {
    "objectID": "intro_R.html#el-tidyverse",
    "href": "intro_R.html#el-tidyverse",
    "title": "1¬† R y el tidyverse",
    "section": "1.1 El tidyverse",
    "text": "1.1 El tidyverse\n\n1.1.1 Tidy data\nLo primero que tenemos que pensar cuando trabajamos con el tidyverse es que nuestros datos est√©n en formato tidy. ¬øQu√© significa esto? Cuando un dataset est√° en formato tidy, cada columna corresponde a una variable y cada fila a una √∫nica observaci√≥n2. Veamos un ejemplo. Tenemos tres sujetos a los cuales les medimos el tiempo de respuesta en una tarea. Cada sujeto realiza dos repeticiones de esta medici√≥n, el trial 1 y el trial 2. En la tabla Table¬†1.1 podemos ver las dos formas de organizar esta informaci√≥n.2¬†El caso contrario ser√≠a en el que una fila contiene varios mediciones para distintos niveles de una variable. Este formato se conoce como wide.\n\n\nTable¬†1.1: Ejemplo de tablas tidy y wide.\n\n\n\n\n(a) Tidy \n \n  \n    sujeto \n    trial \n    tiempo_respuesta \n  \n \n\n  \n    Jerry \n    1 \n    0.0807501 \n  \n  \n    Jerry \n    2 \n    0.8343330 \n  \n  \n    Elaine \n    1 \n    0.6007609 \n  \n  \n    Elaine \n    2 \n    0.1572084 \n  \n  \n    George \n    1 \n    0.0073994 \n  \n  \n    George \n    2 \n    0.4663935 \n  \n\n\n\n\n\n\n(b) Wide \n \n  \n    sujeto \n    trial_1 \n    trial_2 \n  \n \n\n  \n    Jerry \n    0.4977774 \n    0.7725215 \n  \n  \n    Elaine \n    0.2897672 \n    0.8746007 \n  \n  \n    George \n    0.7328820 \n    0.1749406 \n  \n\n\n\n\n\n\nA lo largo de este cap√≠tulo iremos viendo los beneficios de almacenar los datos en formato tidy. Por supuesto que estas ventajas tienen su precio, principalemente que las bases de datos crecen mucho en tama√±o si tenemos muchas medidas repetidas con distintos valores de las variables.\n\n\n1.1.2 Introducci√≥n al Tidyverse\nComo contamos m√°s arriba, el tidyverse es una colecci√≥n cerca de 25 paquetes, todos relacionados con la carga, manejo, modificaci√≥n y visualizaci√≥n de datos. La idea de este libro no es profundizar en todas sus capacidades pero consideramos importante presentar algunas de las funciones que m√°s vamos a utilizar a lo largo del libro. Estas son funciones para leer datos del paquete {readr}, los verbos de {dplyr} para manipularlos, las funciones de {tidyR} para acomodarlos y el poderos√≠simo {ggplot2} para visualizarlos.\n\n1.1.2.1 Cargando datos con readr\nUna de las cosas que vamos a hacer m√°s a menudo en este libro es cargar alg√∫n dataset. Para esto vamos a usar varias de las funcionalidades del paquete {readr}.\nEl caso m√°s simple al que nos vamos a enfrentar es la carga de una base de datos organizada en columnas y separadas por comas en un archivo de extensi√≥n .csv. En este caso lo que tenemos que hacer es bastante simple, usar la funci√≥n read_csv() como a continuaci√≥n:\n\ndata <- read_csv(\"../data/summer.csv\")\n#> Rows: 31165 Columns: 9\n#> ‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n#> Delimiter: \",\"\n#> chr (8): City, Sport, Discipline, Athlete, Country, Gender, Event, Medal\n#> dbl (1): Year\n#> \n#> ‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n#> ‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nsummary(data)\n#>       Year          City              Sport            Discipline       \n#>  Min.   :1896   Length:31165       Length:31165       Length:31165      \n#>  1st Qu.:1948   Class :character   Class :character   Class :character  \n#>  Median :1980   Mode  :character   Mode  :character   Mode  :character  \n#>  Mean   :1970                                                           \n#>  3rd Qu.:2000                                                           \n#>  Max.   :2012                                                           \n#>    Athlete            Country             Gender             Event          \n#>  Length:31165       Length:31165       Length:31165       Length:31165      \n#>  Class :character   Class :character   Class :character   Class :character  \n#>  Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n#>                                                                             \n#>                                                                             \n#>                                                                             \n#>     Medal          \n#>  Length:31165      \n#>  Class :character  \n#>  Mode  :character  \n#>                    \n#>                    \n#> \n\nLos datos adentro de summer.csv son los ganadores de medallas en los juegos ol√≠mpicos de invierno. El formato en el que read_csv() almacena los datos se llama tibble y es el formato por excelencia del tidyverse. De momento lo √∫nico que nos importa es que es un formato que almacena los casos en filas y las variables en columnas (cada variable tiene un formato). Para m√°s informaci√≥n sobre las cualidades de este formato, les recomiendo revisar la documentaci√≥n.\n\n\n1.1.2.2 El operador pipe (|>) del paquete {magrittr}\nEl operador pipe nos permite concatenar funciones que utilizan como entrada los mismos datos. El principio de operaci√≥n es el siguiente, supongan que nosotros queremos cargar un dataset y aplicarle la funci√≥n summary. Esto lo podemos hacer simplemente cargando el dataset en una l√¨nea de c√≥digo y ejecutanco la funci√≥n summary() en la siguiente.\n\ndata <- read_csv(\"../data/summer.csv\")\n#> Rows: 31165 Columns: 9\n#> ‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n#> Delimiter: \",\"\n#> chr (8): City, Sport, Discipline, Athlete, Country, Gender, Event, Medal\n#> dbl (1): Year\n#> \n#> ‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n#> ‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nsummary(data)\n#>       Year          City              Sport            Discipline       \n#>  Min.   :1896   Length:31165       Length:31165       Length:31165      \n#>  1st Qu.:1948   Class :character   Class :character   Class :character  \n#>  Median :1980   Mode  :character   Mode  :character   Mode  :character  \n#>  Mean   :1970                                                           \n#>  3rd Qu.:2000                                                           \n#>  Max.   :2012                                                           \n#>    Athlete            Country             Gender             Event          \n#>  Length:31165       Length:31165       Length:31165       Length:31165      \n#>  Class :character   Class :character   Class :character   Class :character  \n#>  Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n#>                                                                             \n#>                                                                             \n#>                                                                             \n#>     Medal          \n#>  Length:31165      \n#>  Class :character  \n#>  Mode  :character  \n#>                    \n#>                    \n#> \n\nPero, tambi√©n podemos aprovechar el operador pipe y hacer todo en una √∫nica l√≠nea de c√≥digo.\n\nread_csv(\"../data/summer.csv\") |> summary()\n#> Rows: 31165 Columns: 9\n#> ‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n#> Delimiter: \",\"\n#> chr (8): City, Sport, Discipline, Athlete, Country, Gender, Event, Medal\n#> dbl (1): Year\n#> \n#> ‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n#> ‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n#>       Year          City              Sport            Discipline       \n#>  Min.   :1896   Length:31165       Length:31165       Length:31165      \n#>  1st Qu.:1948   Class :character   Class :character   Class :character  \n#>  Median :1980   Mode  :character   Mode  :character   Mode  :character  \n#>  Mean   :1970                                                           \n#>  3rd Qu.:2000                                                           \n#>  Max.   :2012                                                           \n#>    Athlete            Country             Gender             Event          \n#>  Length:31165       Length:31165       Length:31165       Length:31165      \n#>  Class :character   Class :character   Class :character   Class :character  \n#>  Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n#>                                                                             \n#>                                                                             \n#>                                                                             \n#>     Medal          \n#>  Length:31165      \n#>  Class :character  \n#>  Mode  :character  \n#>                    \n#>                    \n#> \n\nAl dejar vac√≠o el par√©ntesis de la funci√≥n summary(), la misma va a tomar como variable de entrada a la que est√° antes del operador pipe, es decir, a la que antes llamamos data. En el caso que la funci√≥n summary() tuviera m√°s de una variable de entrada, lo que viene antes del pipe tomar√≠a el lugar de la primera de ellas.\nSi bien esta funcionalidad parece algo que complica las cosas y que no trae demasiados beneficios con un ejemplo tan simple, m√°s adelante veremos que puede ser de gran utilidad, ayudando a disminuir la cantidad de l√≠nes de c√≥digo y de variables intermedias.\n\n\n1.1.2.3 Dplyr y sus verbos\nUna de las cosas m√°s √∫tiles del Tidyverse para el tipo de procesamiento de datos que vamos a llevar a cabo en este libro son los verbos de dplyr. Estas funciones no permiten agregar columnas, resumir la informaci√≥n, filtrar filas, seleccionar columnas, etc. Y todas estas acciones las podemos hacer en la base de datos completa o en una parte de ella agrupada de acuerdo a alg√∫n criterio. Vayamos de a poco.\nhttps://dplyr.tidyverse.org/\n\n\n1.1.2.4 TidyR, el paquete para ordenar tus datos\n\n\n1.1.2.5 ggplot2 o c√≥mo hacer figuras que sean la envidia de tu compa√±ero de escritorio"
  },
  {
    "objectID": "intro_R.html#cierre",
    "href": "intro_R.html#cierre",
    "title": "1¬† R y el tidyverse",
    "section": "1.2 Cierre",
    "text": "1.2 Cierre\nComo vimos brevemente en este cap√≠tulo, los paquetes del tidyverse son una herramineta important√≠sima para el an√°lisis de datos utilizando R. Para m√°s detalles sobre estas funcionalidades les recomendamos la gu√≠a de Hadley Wickham(Wickham et al. 2019) o, si ya se quieren sumergir de lleno en el mundo del an√°lisis de datos con R, este fant√°stico libro [Wickham, √áetinkaya-Rundel, and Grolemund (2023)]3. Es decir, sin tener que cargar ning√∫n paquete de funciones adicional..3¬†Disponible gratis online en este link https://r4ds.had.co.nz/.\n\n\n\nWickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy D‚ÄôAgostino McGowan, Romain Fran√ßois, Garrett Grolemund, et al. 2019. ‚ÄúWelcome to the Tidyverse.‚Äù Journal of Open Source Software 4 (43): 1686.\n\nWickham, Hadley, Mine √áetinkaya-Rundel, and Garrett Grolemund. 2023. R for Data Science. \" O‚ÄôReilly Media, Inc.\"."
  },
  {
    "objectID": "intro_stat.html#variables-aleatorias",
    "href": "intro_stat.html#variables-aleatorias",
    "title": "2¬† Repaso de probabilidad y estad√≠stica",
    "section": "",
    "text": "1¬†Del ingl√©s Head y ceca sera T del ingl√©s Tail.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Repaso de probabilidad y estad√≠stica</span>"
    ]
  },
  {
    "objectID": "intro_stat.html#probabilidad",
    "href": "intro_stat.html#probabilidad",
    "title": "2¬† Repaso de probabilidad y estad√≠stica",
    "section": "2.2 Probabilidad",
    "text": "2.2 Probabilidad\nPara una variable como la definida en el ejemplo anterior podemos definir f√°cilmente su probabilidad de ocurrencia. Debido que la moneda es justa, todos los eventos de \\(\\Omega\\) son equiprobables, y es por eso que podemos definir:\n\n\n\n\\(\\omega\\)\n\\(X(\\omega)\\)\n\\(P({\\omega})\\)\n\n\n\n\nTT\n0\n1/4\n\n\nTH\n1\n1/4\n\n\nHT\n1\n1/4\n\n\nHH\n2\n1/4\n\n\n\nSin embargo, el concepto de probabilidad es algo complejo, pero, como esto no es un curso de probabilidad, vamos a confiar en que ustedes ya lo traen claro. Si tienen coraje puede ir a leer el cap√≠tulo 1 de (Wasserman 2004) y si quiere algo m√°s terrenal pueden ir a ver el repaso de probabilidad de (Cunningham 2021) (disponible online).\n\nCunningham, Scott. 2021. Causal inference: The mixtape. Yale university press.\nCuando las variables aleatorias son continuas la cosa se complica un poco m√°s ya que \\(P(X=c)\\), es decir, la probabilida de que una variable tome un valor dado, es cero. Esto lo vamos a repensar un poco en la siguiente secci√≥n, cuando definamos lo que nos importa para este libro: Las funci√≥nes de densidad y de distribuci√≥n.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Repaso de probabilidad y estad√≠stica</span>"
    ]
  },
  {
    "objectID": "intro_stat.html#eventos-y-probabilidad-condicional",
    "href": "intro_stat.html#eventos-y-probabilidad-condicional",
    "title": "2¬† Repaso de probabilidad y estad√≠stica",
    "section": "2.3 Eventos y probabilidad condicional",
    "text": "2.3 Eventos y probabilidad condicional\n\n\nEn construcci√≥n üöß"
  },
  {
    "objectID": "intro_stat.html#probabilidad-total",
    "href": "intro_stat.html#probabilidad-total",
    "title": "2¬† Repaso de probabilidad y estad√≠stica",
    "section": "2.4 Probabilidad total",
    "text": "2.4 Probabilidad total\nAhora imaginemos que pasa si queremos calcular la probabilidad de B (\\(P(B)\\)). Bueno, para esto tendr√≠amos que considerar la probabilidad de que ocurra B dado que ocurri√≥ S y junto con la probabilidad de B dado que NO ocurri√≥ S. A su vez, cada una de estas probabilidades deber√≠amos pesarlas por la probabilidad de que ocurra o no A. Esto ser√≠a2:\n2¬†Recordemos que \\(\\neg\\) es el s√≠mbolo l√≥gico de la negaci√≥n.\\[\nP(B) = P(B|A) \\times P(A) +  P(B|\\neg A) \\times P(\\neg A)\n\\tag{2.1}\\]\nPensemos un ejemplo. Imaginemos que una persona tiene que completar un trabajo de jardiner√≠a (evento B) en un d√≠a. La probabilidad de que termine este trabajo si llueve (evento A) es \\(0.35\\) y la probabilidad de que lo termine si no llueve es de \\(0.95\\). Si la probabilidad de que llueva es \\(P(A)=0.4\\) ¬øCu√°l es la probabilidad (\\(P(B)\\)) de que el trabajo se complete en un d√≠a? Echemos mano a la f√≥rmula de probabilidad total:\n\\[\n\\begin{array}\n_P(B) &=& P(B|A) \\times P(A) + P(B|\\neg A) \\times P(\\neg A) \\\\\n&=& 0.35 \\times 0.4 + 0.95 \\times 0.6 \\\\\n&=& 0.71\n\\end{array}\n\\tag{2.2}\\]\nEntonces, la probabilidad de completar el trabajo en un d√≠a es \\(P(B)=0.71\\).\nPor √∫ltimo, cuando tenemos muchas condiciones, podemos definir de forma general a la probabilidad total como:\n\\[\nP(B) = \\sum_n P(B|A_n) P(A_n)\n\\tag{2.3}\\]",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Repaso de probabilidad y estad√≠stica</span>"
    ]
  },
  {
    "objectID": "intro_stat.html#teorema-de-bayes",
    "href": "intro_stat.html#teorema-de-bayes",
    "title": "2¬† Repaso de probabilidad y estad√≠stica",
    "section": "2.5 Teorema de Bayes",
    "text": "2.5 Teorema de Bayes\nAhora que ya llegamos a la f√≥rmula de Bayes a partir de las definiciones de probabilidad total podemos tomar prestado un ejemplo de (Herzog, Francis, y Clarke 2019): Tenemos un test para identificar si somos portadores de un virus (llam√©moslo IKV). Este test tiene una sensibilidad de 99.99% y una especificidad de 99.99%. Es decir, la probabilidad de que el test de positivo, dado que tenemos el virus (\\(P(T^+|IKV)\\)) es de 0.9999, y lo mismo ocurre para la probabilidad de que el test de negativo en caso de que NO tengamos el virus (\\(P(T^-|\\neg IKV)\\)). Sabemos tambi√©n que la incidencia del virus IKV es de 1 en 10000.\n\nHerzog, Michael H, Gregory Francis, y Aaron Clarke. 2019. Understanding statistics and experimental design: how to not lie with statistics. Springer Nature.\nSupongamos que somos elegidos aleatoriamente para realizarnos el test y este da positivo ¬øQu√© probabilidad de ser portadores del virus tenemos (\\(P(IKV|T^+)\\))? La primera respuesta que se nos viene es 0.9999 ¬øVerdad? Pero, si estuvimos prestando atenci√≥n, ya a esta altura debemos saber que para invertir la condicionalidad de una probabilidad tenemos que acudir al bueno de Bayes. O sea:\n\\[\nP(IKV|T^+) = \\frac{P(T^+|IKV) \\times P(IKV)}{P(T+)}\n\\tag{2.4}\\]\ndonde \\(P(T^+|IKV) = 0.9999\\) y \\(P(IKV) = 1/10000 = 0.0001\\). Adem√°s, echando mano a la definici√≥n de probabilidad total podemos calcular \\(P(T+)\\) como:\n\\[\nP(T+) = P(T^+|IKV) \\times P(IKV) + P(T^+|\\neg IKV) \\times P(\\neg IKV)\n\\tag{2.5}\\]\ndonde \\(P(T^+|\\neg IKV) = 1-0.9999\\) y \\(P(\\neg IKV) = 1-0.0001\\). Reemplazando todos los valores tenemos que:\n\\[\n\\begin{array}\n_P(IKV|T^+) &=& \\frac{P(T^+|IKV) \\times P(IKV)}{P(T+)}\\\\\n&=& \\frac{P(T^+|IKV) \\times P(IKV)}{P(T^+|IKV) \\times P(IKV) + P(T^+|\\neg IKV) \\times P(\\neg IKV)} \\\\\n&=& \\frac{0.9999 \\times 0.0001}{0.9999 \\times 0.0001 + (1-0.9999) \\times (1-0.0001)} \\\\\n&=& \\frac{0.9999 \\times 0.0001}{0.9999 \\times 0.0001 + 0.0001 \\times 0.9999} \\\\\n&=& 0.5\n\\end{array}\n\\tag{2.6}\\]\n¬øQu√©? ¬øEsto significa que si el test me da positivo solo tengo un 0.5 de probabilidad de tener el virus? ¬øEsto quiere decir que los tests no sirven para nada? Momento, analicemos un poco al resultado al que llegamos. Lo que nos dice esta cuenta es que, una vez que el test nos da positivo, a pesar de lo sensible del test y por lo ‚Äúraro‚Äù de la portaci√≥n del virus, nuestra probabilidad de ser portadores es de 0.5. Pero, ¬øY nuestra probabilidad de ser portadores si el test nos da negativos? Hagamos la cuenta:\n\\[\n\\begin{array}\n_P(IKV|T^-) &=& \\frac{P(T^-|IKV) \\times P(IKV)}{P(T-)}\\\\\n&=& \\frac{P(T^-|IKV) \\times P(IKV)}{P(T^-|IKV) \\times P(IKV) + P(T^-|\\neg IKV) \\times P(\\neg IKV)} \\\\\n&=& \\frac{(1-0.9999) \\times 0.0001}{(1 - 0.9999) \\times 0.0001 + (0.9999) \\times (1-0.0001)} \\\\\n&=& 1E-8\n\\end{array}\n\\tag{2.7}\\]\nOK, ahora la cosa tiene m√°s sentido. O sea, el test es bastante bueno para decirnos cuando no somos portadores y dando negativo, el problema es cuando da positivo. En este caso tenemos que preocuparnos, pero, como vimos anteriormente, la probabilidad de ser portadores es de apenas 0.5.\nHay una soluci√≥n m√°s simple para esto y es la que deben estar pensando ustedes: ¬øY si me hacen un segundo test? ¬°BINGO! Calculemos r√°pidamente la probabilidad de estar infectados si nos testean por segunda vez:\n\\[\nP(IKV|T^{2+}) = \\frac{0.9999^2 \\times 0.0001}{0.9999^2 \\times 0.0001 + 0.0001^2 \\times 0.9999} = 0.9999\n\\tag{2.8}\\] Ahora s√≠, si somos testeados por segunda vez, la probabilidad de ser portadores dado que tenemos dos resultados positivos trepa a 0.9999. Nos podemos quedar tranquilos.\nPara cerrar, me gustar√≠a que pensemos un poco en una palabra MUY importante que se dijo en el enunciado del problema: Aleatoriamente. En muchos de los casos en los que nos testeamos para ver si somos portadores de un virus, lo hacemos porque tenemos alg√∫n tipo de presunci√≥n de que podemos serlo (por ejemplo, tenemos s√≠ntomas). ¬øCu√°l creen que ser√≠a la probabilidad que se modifica en la f√≥rmula? Exacto, \\(P(IKV)\\), ya que ser√≠a m√°s bien \\(P(IKV|s√≠ntomas)\\).",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Repaso de probabilidad y estad√≠stica</span>"
    ]
  },
  {
    "objectID": "intro_stat.html#esperanza",
    "href": "intro_stat.html#esperanza",
    "title": "2¬† Repaso de probabilidad y estad√≠stica",
    "section": "2.6 Esperanza",
    "text": "2.6 Esperanza\nLa esperanza de una variable aleatoria \\(X\\), a veces tambi√©n llamada media poblacional, es simplemente la suma pesada de todos sus valores posibles. No debemos confundir la esperanza con el promedio muestral, aunque, como veremos en breve, para algunos casos el primero es un estimador insesgado del segundo.\nLa esperanza de una variable aleatoria discreta se define como:\n\\[\nE(X) = \\sum_{1}^\\infty x_i p(x_i)\n\\tag{2.9}\\] En este caso es muy claro la naturaleza de promedio pesado, ya que a cada valor posible de \\(X\\) lo estamos pesando por su probabilidad. Sin embargo, para una variable aleatoria continua, en la que no tenemos definida una probabilidad puntual \\(p(x_i)\\) sino una funci√≥n de densidad \\(f(x)\\), la definici√≥n es la siguiente:\n\\[\nE(X) = \\int_{-\\infty}^\\infty x f(x) dx\n\\tag{2.10}\\]\nComo resulta esperable, la suma se transforma en una integral y la probabilidad puntual se reemplaza por \\(f(x)\\).\nAlgunas propiedades importantes de la esperanza son:\n\\[\n\\begin{array}\n_E(aX+b) & = & aE(X) + b\\\\\nE(\\sum_{i=1}^n X_i) & = & \\sum_{i=1}^nE(X_i)\n\\end{array}\n\\tag{2.11}\\]\nPor √∫ltimo y a modo de aviso, advertencia y amenaza, recordemos que \\(E(X)^2 \\neq E(X^2)\\).",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Repaso de probabilidad y estad√≠stica</span>"
    ]
  },
  {
    "objectID": "intro_stat.html#varianza-y-covarianza",
    "href": "intro_stat.html#varianza-y-covarianza",
    "title": "2¬† Repaso de probabilidad y estad√≠stica",
    "section": "2.7 Varianza y covarianza",
    "text": "2.7 Varianza y covarianza\nLa varianza nos da una idea de la variabilidad de los procesos aleatorios que generan una variable aleatorio3. La varianza de la variable aleatoria \\(X\\) se define como:\n3¬†Dato que ser√° de vital importancia para sentar las bases de la inferencia estad√≠stica.\\[\nV(X) = \\sigma^2 = E \\left[ (X - E(X))^2 \\right]\n\\tag{2.12}\\]\nY se puede demostrar que:\n\\[\nV(X) = E(X^2) - E^2(X)\n\\tag{2.13}\\]\nPor otro lado, la covarianza mide la cantidad de dependencia lineal entre dos variables aleatorias. La misma se define como\n\\[\nCov(X,Y) = E(XY) - E(X)E(Y)\n\\tag{2.14}\\]\nSi \\(Cov(X,Y)&gt;0\\), esto indica que las dos variables se mueven en la misma direcci√≥n, mientras que si \\(Cov(X,Y)&lt;0\\) esto indica que ambas variables se mueven en direcciones opuestas.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Repaso de probabilidad y estad√≠stica</span>"
    ]
  },
  {
    "objectID": "intro_stat.html#correlaci√≥n",
    "href": "intro_stat.html#correlaci√≥n",
    "title": "2¬† Repaso de probabilidad y estad√≠stica",
    "section": "2.8 Correlaci√≥n",
    "text": "2.8 Correlaci√≥n\nLa correlaci√≥n es la versi√≥n m√°s amigable de la covarianza. ¬øPor qu√©? Porque nos dice cu√°nto covar√≠an dos variables independiz√°ndose de la varianza de cada una de ellas, es decir, normalizando. Esto la convierte en una medida muy relevante e informativa. Si tenemos dos variables aleatorias \\(X\\) e \\(Y\\), la correlaci√≥n de se define como la covarianza es sus versiones estandarizadas:\n\\[\n\\begin{array}\n_W &=& \\frac{X-E(X)}{\\sqrt{V(X)}} \\\\\nZ &=& \\frac{Y-E(Y)}{\\sqrt{V(Y)}}\n\\end{array}\n\\tag{2.15}\\]\nDe la siguiente forma:\n\\[\n\\begin{array}\n_Corr(X,Y) &=& Cov(W,Z) \\\\\n&=&  Cov(\\frac{X-E(X)}{\\sqrt{V(X)}}, \\frac{Y-E(Y)}{\\sqrt{V(Y)}}) \\\\\n&=&  \\frac{1}{\\sqrt{V(X)}} \\frac{1}{\\sqrt{V(Y)}}  Cov(X-E(X),Y-E(Y)) \\\\\n&=&  \\frac{Cov(X,Y)}{\\sqrt{V(X) V(Y)}}\n\\end{array}\n\\tag{2.16}\\]\nUsamos la propiedad de la covarianza que dice que:\n\\[\nCov(X+a, Y+b) = Cov(X,Y) + Cov(X,b) + Cov(a,Y) + Cov(a,b)\n\\tag{2.17}\\]\nY como \\(a\\) y \\(b\\) son constantes (en nuestro caso esperanzas), el √∫nico t√©rmino que sobrevive es \\(Cov(X,Y)\\). Esta magnitud es tambi√©n conocida como el coeficiente de correlaci√≥n \\(\\rho\\).\nCon esta definici√≥n en la mano, si yo les digo que dos variables \\(X\\) e \\(Y\\) tienen una covarianza de \\(14.988\\) no les dice mucho, ¬øNo? Ahora, si les digo que el coeficiente de correlaci√≥n es de \\(0.788\\) probablemente entiendan r√°pidamente que ambas variables est√°n muy relacionadas4.\n4¬†Si quieren divertirse y de paso convertise en ases de la determinaci√≥n del coeficiente de correlaci√≥n a oj√≠metro les recomiendo este juegazo. Una estudiante ostenta el abultado r√©cord de \\(231\\) puntos ¬øLa pasaste?Veamos este ejemplo con n√∫meros y de paso repasemos como se calcula la correlaci√≥n en R:\n\n\nVer el c√≥digo\nset.seed(1234)\nx = rnorm(1000, 20, 4)\ny = x*.9 + rnorm(1000, 2, 3)\ncat(paste(\"La covarianza entre X e Y es\", round(cov(x,y), 3)))\n#&gt; La covarianza entre X e Y es 14.988\ncat(paste(\"La correlaci√≥n entre X e Y es\", round(cor(x,y), 3)))\n#&gt; La correlaci√≥n entre X e Y es 0.788\n\n\n\n\n\n\n\nRelaci√≥n lineal entre X e Y.\n\n\n\n\nEs muy importante tener en cuenta que el coeficiente de correlaci√≥n nos dice cu√°n linealmente relacionadas est√°n las variables. Veamos esto con un ejemplito:\n\n\nVer el c√≥digo\nset.seed(1234)\nx = runif(1000, -1, 1)\ny = x^2 + .1*runif(1000, -1, 1)\ncat(paste(\"La covarianza entre X e Y es\", round(cov(x,y), 3)))\n#&gt; La covarianza entre X e Y es 0.01\ncat(paste(\"La correlaci√≥n entre X e Y es\", round(cor(x,y), 3)))\n#&gt; La correlaci√≥n entre X e Y es 0.055\n\n\n\n\n\n\n\nRelaci√≥n no lineal entre X e Y.\n\n\n\n\nEn este caso vemos que claramente hay uan relaci√≥n entre X e Y (no son una nube de puntos sin estructura) pero como esta relaci√≥n no es lineal (cuadr√°tica en nuestro caso), el coeficiente de correlaci√≥n es cercano a cero.\nFinalmente, tengamos en cuenta que el coeficiente de correlaci√≥n puede tomar valores entre \\(-1\\) y \\(1\\). Una correlaci√≥n positiva indica que las variables var√≠an de la misma manera (si aumenta una aumenta la otra) y lo contrario ocurre con una correlaci√≥n negativa (si aumenta una disminuye la otra). Cuanto m√°s cerca est√© el coeficiente de \\(1\\) o, m√°s fuerte es la relaci√≥n lineal.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Repaso de probabilidad y estad√≠stica</span>"
    ]
  },
  {
    "objectID": "intro_stat.html#poblaci√≥n-y-muestra",
    "href": "intro_stat.html#poblaci√≥n-y-muestra",
    "title": "2¬† Repaso de probabilidad y estad√≠stica",
    "section": "2.9 Poblaci√≥n y muestra",
    "text": "2.9 Poblaci√≥n y muestra\nAc√° usar una versi√≥n de la figurita de All of statistics que pone la generaci√≥n de los datos en el dominio de la probabilidad y la estimaci√≥n de estos par√°metros en el dominio de la estad√≠stica. Me parece una forma ideal de empezar a hablar de qu√© queremos hacer con la estad√≠stica.\nVamos con un ejemplo que nos puede ayudar a entender de qu√© hablamos cuando hablamos de estimaci√≥n. Supongamos que conocemos distribuci√≥n de la altura de la poblaci√≥n de varones en Argentina. No estamos hablando de calcular el promedio de la altura de los varones sino de que conocemos la funci√≥n de densidad de la cual la altura de cada var√≥n es una muestra. Si no queda del todo claro respiren hondo y esperen un poco que ya se va a ir aclarando. Entonces, la altura de los varones de Argentina tiene una distribuci√≥n normal con media en cm. de \\(\\mu_{varones} = 175\\) y una desviaci√≥n est√°ndar \\(\\sigma_{varones} = 7\\), o, como ya aprendimos a decir: \\(H_{varones} \\sim \\mathcal{N}(\\mu_{varones},\\sigma^2_{varones}) = \\mathcal{N}(175, 49)\\)5. A continuaci√≥n podemos ver la funci√≥n de densidad:\n5¬†h del ingl√©s height.\n\n\n\n\nFunci√≥n de densidad de probabilidad de la variabla aleatoria H (altura de los varones)\n\n\n\n\nAhora bien, en la figura podemos ver la funci√≥n \\(f_X(x)\\) junto con una l√≠nea vertical que nos indica la media y dos l√≠neas que nos indican los percentiles \\(2.5\\) y \\(97.5\\), es decir, que contienen el 95% de la masa de probabilidad. Todo esto es muy lindo pero estamos jugando a ser dios (o el Doctor Manhattan, o en lo que ustedes crean). Es imposible conocer los par√°metros de esta distribuci√≥n pero lo que s√≠ podemos hacer en la pr√°ctica es estimarlos. Estimar los par√°metros de un modelo es el pan y manteca de la inferencia estad√≠stica y el data mining. Como podemos ver en esta hermosa figura de Wasserman(Wasserman 2004), la teor√≠a de probabilidad nos ayuda a definir modelos para la generaci√≥n de datos y la inferencia estad√≠stica nos ayuda a estimar estos par√°metros.\n\nWasserman, Larry. 2004. All of statistics: a concise course in statistical inference. Springer Science & Business Media.\nHay diversas formas de encontrar estimadores para los par√°metros de un modelo (por ejemplo, m√©todo de los momentos, m√°xima verosimilitud, etc.) pero entenemos que eso excede los contenidos de este curso. Sin embargo, para estimar todos conocemos los estimadores de los par√°metros poblacionales \\(\\mu\\) y \\(\\sigma^2\\). Claro, el promedio \\(\\bar{x}\\) y el desv√≠o muestral \\(\\hat{S}^2\\):\n\\[\n\\begin{array}\n\\\\\\bar{x} & = & n^{-1} \\sum_{i=1}^n x_i\\\\\n\\hat{S}^2 & = & (n-1)^{-1} \\sum_{i=1}^n (x_i\n\\end{array}\n\\tag{2.18}\\]\nSimulemos tres experimento tomando 10, 50 y 100 mediciones (\\(n\\)) y veamos los histogramas de estas muestras y sus estimaciones de \\(\\mu\\) y \\(\\sigma\\):\n\n\n\n\n\nDistribuci√≥n de la altura de los varones argentinos para distintos valores de n\n\n\n\n\nComo es de esperarse, podemos ver que al aumentar \\(n\\), la estimaci√≥n de los par√°metros poblacionales es mejor. Pero tenemos que tener esta idea en mente, cada vez que tomamos una muestra podemos estimar un par√°metro de la poblaci√≥n y hasta hacer inferencias estad√≠sticas sobre el mismo, pero NUNCA lo vamos a conocer.\nAlgo importante cuando usemos un estimador es que este sea consistente, lo que implica que si aumentamos \\(n\\) al infinito, el estimador converge al valor del par√°metro (en este caso el promedio muestral para \\(n \\to \\infty\\) tiende a la media poblacional \\(\\mu\\)). Decimos entonces que un estimador converge en probabilidad a un determinado par√°metro. Como usuarios de la estad√≠stica esto nos va a venir masticado y no nos vamos a tener que preocupar tanto pero es bueno tenerlo en mente cuando hablamos de estimadores y estimaciones.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Repaso de probabilidad y estad√≠stica</span>"
    ]
  },
  {
    "objectID": "potential_outcomes.html",
    "href": "potential_outcomes.html",
    "title": "3¬† Potential outcomes",
    "section": "",
    "text": "3.1 Guerra fr√≠a, manos y contraf√°cticos.\nSon las 3 de la ma√±ana del 26 de septiembre de 1983. Con una taza de caf√© en mano, Stanislav Petrov vigila las alarmas de una estaci√≥n de monitoreo de ataques nucleares a las afueras de Mosc√∫. De pronto, los paneles se iluminan con un rojo furioso: tres misiles intercontinentales est√°n en camino a la c√∫pula del Kremlin‚Ä¶ o, quiz√°s, el sistema tiene un error y se trata de una falsa alarma.\nStanislav no duda. Sigue el protocolo y llama al Kremlin. En menos de tres minutos, Rusia lanza un ataque nuclear contra las principales ciudades de EE. UU. La contrarespuesta estadounidense borra Leningrado y Stalingrado unos 40 minutos despu√©s. Adem√°s de millones de muertos, los ataques levantan tal cantidad de polvo en la atm√≥sfera que el mundo se sume en un invierno nuclear durante 30 a√±os, provocando hambruna en gran parte del hemisferio norte. Menos afectada por los ataques, la econom√≠a africana mejora lentamente y se convierte en el principal proveedor de alimentos del mundo. Para 2025, el Imperio Panafricano es la principal potencia econ√≥mica global.\nTodos sabemos que esto nunca ocurri√≥. Lo que realmente pas√≥ fue que Stanislav Petrov pens√≥ que se trataba de un error y nunca avis√≥ a nadie (pueden ver la historia aqu√≠).\nEste mundo posnuclear es un mundo donde los hechos ocurrieron de manera completamente distinta: un mundo alternativo, un what if, un escenario contraf√°ctico. Podemos especular sobre lo que habr√≠a sucedido si los eventos se hubieran desarrollado de otra forma, pero la realidad es que nunca ocurrieron. Por lo tanto, un contraf√°ctico, aunque posible, es siempre especulativo.\n¬øPara qu√© sirve entonces construir contraf√°cticos, imaginar cosas que no ocurrieron y que nunca ocurrir√°n? Veamos otra historia.\nEste cuadro se llama Praying Hands y fue pintado por Albrecht Durero. Es una de las obras m√°s importantes de su siglo.\nLos Durero eran una familia de mineros pobres del sur de Alemania. Dos de sus hijos, Albrecht y Joseph, ten√≠an talento para el dibujo y decidieron hacer un pacto: uno estudiar√≠a en N√∫remberg durante cuatro a√±os mientras el otro trabajar√≠a en las minas para pagar su educaci√≥n. Decidiria quien con una moneda. Pasado ese tiempo, intercambiar√≠an lugares.\nEl azar favoreci√≥ a Albrecht. Durante esos cuatro a√±os, se convirti√≥ en un pintor famoso y regres√≥ a casa para cumplir su parte del acuerdo. Sin embargo, al llegar, Joseph lo recibi√≥ con una triste noticia: era demasiado tarde. El arduo trabajo en la mina le hab√≠a provocado una artritis severa, impidi√©ndole sostener un pincel. Como √∫nico tributo a su sacrificio, Albrecht decidi√≥ pintar sus manos.\nAhora tenemos dos escenarios contrafacticos, lo que le hubiera sucedido a Albretch si se quedaba en la mina, y lo que le hubiera sucedido a Joseph si se iba a estudiar a Nuremberg. De modo que el escenario seria asi.\nAmbos son hermanos, comparten cierto talento y muchas cosas. Uno podria suponer que el destino de Joseph podria servir para suponer con mayor precision lo que le paso ‚Äúle hubiera pasado a Albretch de no ir a Nuremberg‚Äù (escenario contrafactico) y el destino de Albetch ‚Äúlo que le hubiera pasado a Joseph si hubiera podido ir a Nuremberg‚Äù (escenario contrafactico). Entonces imaginar escenarios contrafacticos nos permiten estimar el efecto de ir a Nuremberg o de quedarse. Para eso creamos los contrafacticos.\nAhora bien, es Joseph lo mismo que Albrecth, si la moneda hubiera favorecido a Joseph, habria un Durero pintor famoso? Bueno no estamos seguros de eso, lo que si podemos estar seguros es que pese a parecidos no son exactamente el mismo y quizas hay diferencias en talentos o en suceptibilidad a la artritis lo que hace que el destino de uno funcione como un simil o proxy de su destino contrafactico pero no el destino en si mismo. Con estas ideas podemos armar un marco teorico donde esos efectos se puedan estimar. Este marco teorico se llama outcomes potenciales.\nSupongamos que quiero evaluar la efectividad de la aspirina para mitigar el dolor de cabeza. Me duele la cabeza y lo quiero es saber el efecto diferencial entre tomar y no tomar esa aspirina. Es decir, en el tiempo 0 estoy yo con dolor de cabeza y en el tiempo 1 deber√≠a haber dos versiones m√≠as (como si una no fuera suficiente), la que tom√≥ la aspirina y la que no. A cada una de ellas les tendr√≠a que preguntar cu√°nto les duele la cabeza, el outcome de mi comparaci√≥n. No hace falta ser demasiado astuto para darse cuenta que esto es imposible ya que s√≥lo nos ser√° posible obsevar una de esas versiones mientras que la otra ser√° un contraf√°ctico.\nDe esto vamos a hablar en este cap√≠tulo, utilizando la tradici√≥n de los potential outcomes. Estas ideas terminan de tomar forma en la versi√≥n que conocemos en las ciencias sociales en (Rubin 1974).",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>*Potential outcomes*</span>"
    ]
  },
  {
    "objectID": "potential_outcomes.html#sdf",
    "href": "potential_outcomes.html#sdf",
    "title": "3¬† Potential outcomes",
    "section": "3.1 Sdf",
    "text": "3.1 Sdf"
  },
  {
    "objectID": "dags.html",
    "href": "dags.html",
    "title": "4¬† Grafos ac√≠clicos dirigidos (DAGS)",
    "section": "",
    "text": "4.1 Definiciones, caracter√≠sticas y ejemplos\nUn DAG es una representaci√≥n gr√°fica de una cadena de efectos causales. Los nodos (los circulitos o cuadraditos que vamos a ver m√°s adelante) representan variables aleatorias y las flechas que los unen representan la relaci√≥n causal que se mueve de una variable a la otra en la direcci√≥n intuitiva de la flecha. Por ejemplo, pensemos que queremos estudiar el efecto de tomar una aspirina en la intensidad de nuestro dolor de cabeza cuando nos duele la cabeza. Tenemos dos variables Aspirina (A) e Intensidad del dolor (I). Esta relaci√≥n la podemos expresar en el siguiente DAG:\nDAG que representa la relaci√≥n entre tomar una aspirina (A) y la intensidad del dolor (I).\n¬øAs√≠ de simple? S√≠ y no ¬øQu√© pasa cuando las cosas se empiezan a complicar? Pensemos en el cl√°sico ejemplo del mantra ‚Äúcorrelaci√≥n no implica causalidad‚Äù la relaci√≥n entre venta de helados (Hel) y accidentes por mordidas de tibur√≥n en Australia(Sh). Si nosotros plante√°ramos que el aumento de la venta de helados causa el aumento de los accidentes no tendr√≠a mucho sentido, ¬øNo?. Entonces, ¬øQu√© est√° pasando? ¬øQu√© pinta tiene el DAG? Bueno, como ya comentamos cuando hablamos de correlaci√≥n en este caso lo que tenemos es una causa com√∫n a ambos fen√≥menos que, a modo de simplificar, la podr√≠amos resumir como la temperatura (T). Entonces, cuando sube la temperatura sube la venta de helados, pero tambi√©n los accidentes por mordidas de tibur√≥n. Una posible relaci√≥n causal entre ambas variables podr√≠a ser esta:\nDAG que representa la relaci√≥n entre las ventas de helados (Hel), los accidentes por mordida de tibur√≥n (Sh) y la temnperatura (T) en las playas de Australia.\nTodo muy lindo, pero ¬øPara qu√©?",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Grafos ac√≠clicos dirigidos (DAGS)</span>"
    ]
  },
  {
    "objectID": "dags.html#definiciones-caracter√≠sticas-y-ejemplos",
    "href": "dags.html#definiciones-caracter√≠sticas-y-ejemplos",
    "title": "4¬† Grafos ac√≠clicos dirigidos (DAGS)",
    "section": "",
    "text": "DAGS en R\n\n\n\nPara realizar los DAGS que aparecen en este cap√≠tulo utilizamos la librer√≠a {ggdag}. Para esto primero debemos hacer un esquema de nuestro DAG en Daggity y luego copiar parte de lo generado en la definici√≥n de nuestro DAG en R. En el desarrollo del cap√≠tulo utilizaremos algunas de las herramientas de {ggdag}, varias de las cuales pueden encontrar en este tutorial. Sin embargo, para una revisi√≥n pormenorizada de sus funciones recomiendo repasar la documentaci√≥n del mismo.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Grafos ac√≠clicos dirigidos (DAGS)</span>"
    ]
  },
  {
    "objectID": "dags.html#el-criterio-de-las-puertas-de-atr√°s",
    "href": "dags.html#el-criterio-de-las-puertas-de-atr√°s",
    "title": "4¬† Grafos ac√≠clicos dirigidos (DAGS)",
    "section": "4.2 El criterio de las puertas de atr√°s",
    "text": "4.2 El criterio de las puertas de atr√°s\nUna de las principales ventajas de plantear un DAg para estudiar una relaci√≥n causal es que nos permite ajustar un modelo a partir del cual, lo que estamos estimando en uno de sus par√°metros es un estimador de la relaci√≥n causal que queremos estudiar. Empecemos planteando los caminos posibles para llegar desde Hel a Sh. En este caso ser√≠an dos:\n\\[\n\\begin{array}\n_Hel    \\longrightarrow Sh \\\\\nHel \\longleftarrow T \\longrightarrow Sh\n\\end{array}\n\\]\nEl primero es lo que se llama un camino directo y es lo relaci√≥n causal que queremos estudiar. Por otro lado, el segundo (\\(Hel \\leftarrow T \\rightarrow Sh\\)) es lo que se llama una puerta de atr√°s y lo ident√≠ficamos porque, al menos en alguna de sus relaciones causales, la flechita va para la izquierda. Identificar estos caminos puerta de atr√°s es una parte fundamental de controlar la variabilidad esp√∫rea en nuestras relaciones causales. En particular en este ejemplo, tenemos un claro confusor y lo que queremos es controlar por T.\nSimulemos esta relaci√≥n y veamos que pasa.\n\n\nVer el c√≥digo\nset.seed(1414)\nhelados &lt;- tibble(\n  Temperatura = rnorm(1000, 20, 5),\n  Helados     = 1 + 1*Temperatura + rnorm(1000),\n  Ataques     = 1 + 2*Temperatura + 0*Helados + rnorm(1000)\n)\n\n\nVeamos que Temperatura es una variable aleatoria con distribuci√≥n normal con media \\(20\\) y desviaci√≥n est√°ndar \\(5\\). Tomamos \\(1000\\) muestras de la misma y despu√©s generamos las variables Helados y Ataques como una combinaci√≥n lineal de Temperatura m√°s un error aleatorio de media \\(0\\) y desviaci√≥n est√°ndar \\(1\\). En la definici√≥n de Ataques podemos ver expl√≠citamente que la influencia de Helados en Ataques es \\(0\\). Sin embargo, miremos la relaci√≥n que existe entre ambas variables:\n\n\n\n\n\nDAG que representa la relaci√≥n entre las ventas de helados (Hel), los accidentes por mordida de tibur√≥n (Sh) y la temnperatura (T) en las playas de Australia.\n\n\n\n\nVemos que ambas variables est√°n altamente correlacionadas, de hecho, su r de Pearson vale 0.977. Sin embargo, nosotros sabemos que esa correlaci√≥n es esp√∫rea, que no hay una relaci√≥n causal entre ventas de helados y ataques de tibur√≥n y que algo tenemos que hacer. Hemos escuchado muchas veces que lo que tenemos que hacer es ‚Äúcontrolar‚Äù por la temperatura, lo que en el contexto de la regresi√≥n lineal no significa otra cosa que agergar Temperatura como una covariable. Ajustemos dos modelos de regresi√≥n, uno con la Temperatura como covariable y uno sin y comparemos las estimaciones de los efectos causales (\\(\\hat\\beta_H\\))2 :\n2¬†Recuerden que el diagrama causal no es un problema estad√≠stico sino m√°s bien se plantea previo a cualquier consideraci√≥n estad√≠stica, usando como insumo el conocimiento del dominio que tenemos.\\[\n\\begin{array}\n_lm_1&:& Ataques_i = \\alpha + \\beta_{H} Helados_i + \\epsilon_i \\\\\nlm_2&:& Ataques_i = \\alpha + \\beta_{H} Helados_i +  \\beta_{T} Temperatura_i + \\tau_i\n\\end{array}\n\\] En la siguiente tabla podemos ver las estimaciones de \\(\\hat\\beta_H\\) para cada uno de los modelos:\n\n\n\nTabla¬†4.1: Estimaciones de los par√°metros de los modelos lm1 y lm2 definidos anteriormente.\n\n\n\n\n\n\n\n\n\n\n\nDependent variable:\n\n\n\n\n\n\n\n\n\n\n\n\nAtaques\n\n\n\n\n\n\nSin controlar por Temp.\n\n\nControlando por Temp.\n\n\n\n\n\n\n(1)\n\n\n(2)\n\n\n\n\n\n\n\n\nHelados\n\n\n1.928***\n\n\n-0.001\n\n\n\n\n\n\n(0.013)\n\n\n(0.032)\n\n\n\n\n\n\n\n\n\n\n\n\nTemperatura\n\n\n\n\n2.003***\n\n\n\n\n\n\n\n\n(0.033)\n\n\n\n\n\n\n\n\n\n\n\n\nConstant\n\n\n0.602**\n\n\n1.015***\n\n\n\n\n\n\n(0.291)\n\n\n(0.134)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n1,000\n\n\n1,000\n\n\n\n\nR2\n\n\n0.954\n\n\n0.990\n\n\n\n\nAdjusted R2\n\n\n0.954\n\n\n0.990\n\n\n\n\nResidual Std. Error\n\n\n2.246 (df = 998)\n\n\n1.032 (df = 997)\n\n\n\n\nF Statistic\n\n\n20,826.210*** (df = 1; 998)\n\n\n51,243.220*** (df = 2; 997)\n\n\n\n\n\n\n\n\nNote:\n\n\np&lt;0.1; p&lt;0.05; p&lt;0.01\n\n\n\n\n\n\nComo podemos ver, si no controlamos por Temperatura , la estimaci√≥n de \\(\\hat\\beta_H\\) tiene un valor cercano a \\(1\\), mientras que si controlamos por Temperatura tiene un valor cercano a \\(0\\) lo que sabemos es el valor ‚Äúreal‚Äù del par√°metro \\(\\beta_H\\). Todo muy lindo pero, ¬øQu√© tiene que ver esto con los DAGS? Bueno, cuando planteamos un DAG existe algo que se llama el criterio de las puertas traseras que dice que para estimar el efecto causal que nos interesa debemos ‚Äúcerrar‚Äù todas las puertas traseras que conectan la causa y elefecto. Y ‚Äúcerrar‚Äù en este contexto es simplemente controlar por la variabilidad de alguna de las variables presentes en la puerta trasera. En este caso, controlando por Temperatura estamos cerrando la √∫nica puerta trasera, por lo tanto, estamos estimando el verdadero efecto causal que nos interesa.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Grafos ac√≠clicos dirigidos (DAGS)</span>"
    ]
  },
  {
    "objectID": "dags.html#colliders",
    "href": "dags.html#colliders",
    "title": "4¬† Grafos ac√≠clicos dirigidos (DAGS)",
    "section": "4.3 Colliders",
    "text": "4.3 Colliders\nHasta ahora tuvimos que lidiar casi √∫nicamente con confusores pero existe otro tipo de variables en el contexto de un camino causal que se denomina collider. Vemos un ejemplo y apliquemos el criterio de las puertas traseras. Pensemos el siguiente ejemplo. Supongamos que queremos estudiar el efecto del factor de riesgo edad (Age) en la infecci√≥n de COVID-19 (Cov), pero lo hacemos a trav√©s de datos voluntarios recavados por una aplicaci√≥n m√≥vil (App). Un DAG muy simplicado que podr√≠amos plantear es el siguiente:\n\n\n\n\n\nDAG que representa la relaci√≥n entre la edad (Age), la infecci√≥n por COVID-19 (Cov) y el uso de la aplicaci√≥n m√≥vil de autoreporte (App).\n\n\n\n\nYa que sabemos que la edad tienen un efecto en el uso de aplicaciones m√≥viles y, podemos suponer, que la gente que se infecta de COVID-19 tiende a reportar m√°s sus datos en la aplicaci√≥n. Ahora veamos los caminos:\n\\[\n\\begin{array}\n_Age    \\longrightarrow Cov \\\\\nAge \\longrightarrow App \\longleftarrow Cov\n\\end{array}\n\\] Repitamos el ejercicio de simulaci√≥n que utilizamos en el ejemplo de los confusores, s√≥lo que esta vez Covid es una variable dicot√≥mica y, por lo tanto, debemos muestrarla de una distribuci√≥n Bernoulli3:\n3¬†Esto resulta especialmente √∫til cuando los DAGS se empiezan a complicar.\n\nVer el c√≥digo\nset.seed(123)\ncovid &lt;- tibble(\n  Age   = rnorm(1000, 40, 10),\n  Covid = rbinom(1000, 1, prob = 1/(1+exp(10-.25*Age))),\n  App   = 1 - 1*Age + 1*Covid +rnorm(1000)\n)\n\n\nPuede verse que la verdadera relaci√≥n entre Covid y Age (en t√©rminos de par√°metros de una regresi√≥n log√≠stica) es \\(0.25\\). Veamos como se ve la edad de los infectados y no infectados:\n\n\n\n\n\nInfectados y no infectados de COVID-19 en funci√≥n de la edad.\n\n\n\n\nSeg√∫n el criterio de las puertas traseras deber√≠amos controlar por App para as√≠ cerrar ese camino. Ajustemos estos dos regresiones log√≠sticas y veamos sus estimaciones de los par√°metros:\n\\[\n\\begin{array}\n_glm_1&:& logit(Covid_i) = \\alpha + \\beta_{Age} Age_i + \\epsilon_i \\\\\nglm_2&:& logit(Covid_i) = \\alpha + \\beta_{Age} Age_i + \\beta_{App} App_i + \\epsilon_i\n\\end{array}\n\\]\nEn la siguiente tabla podemos ver las estimaciones de \\(\\hat\\beta_{Age}\\) para cada uno de los modelos:\n\n\n\nTabla¬†4.2: Estimaciones de los par√°metros de los modelos glm1 y glm2 definidos anteriormente.\n\n\n\n\n\n\n\n\n\n\n\nDependent variable:\n\n\n\n\n\n\n\n\n\n\n\n\nCovid\n\n\n\n\n\n\nSin controlar por App\n\n\nControlando por App\n\n\n\n\n\n\n(1)\n\n\n(2)\n\n\n\n\n\n\n\n\nAge\n\n\n0.243***\n\n\n1.354***\n\n\n\n\n\n\n(0.016)\n\n\n(0.109)\n\n\n\n\n\n\n\n\n\n\n\n\nApp\n\n\n\n\n1.100***\n\n\n\n\n\n\n\n\n(0.103)\n\n\n\n\n\n\n\n\n\n\n\n\nConstant\n\n\n-9.787***\n\n\n-11.839***\n\n\n\n\n\n\n(0.631)\n\n\n(0.763)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n1,000\n\n\n1,000\n\n\n\n\nLog Likelihood\n\n\n-419.336\n\n\n-344.156\n\n\n\n\nAkaike Inf. Crit.\n\n\n842.672\n\n\n694.312\n\n\n\n\n\n\n\n\nNote:\n\n\np&lt;0.1; p&lt;0.05; p&lt;0.01\n\n\n\n\n\n\nLa estimaci√≥n del efecto correcta ser√≠a la del modelos sin controlar pero ¬øPor qu√© pasa esto? Cuando tenemos un collider podemos considerar ese camino como cerrado por defecto y al controlar por √©l, ese camino se abre. Entonces, en si bien ten√≠amos dos posibles caminos causales, s√≥lo uno estaba abierto y no necesit√°bamos controlar por App. Esto se debe a que, al App no causar ninguna de mis otras dos variables, ese camino causal est√° cerrado. Para reflexionar un poco en por qu√© ese camino se abre al controlar por un collider recomiendo las reflexiones del cap√≠tulo 8 de (Huntington-Klein 2021).\n\n\n\n\n\n\nEl criterio de las puertas traseras\n\n\n\nEn resumen, el criterio de las puertas traseras nos dice que para estimar la relaci√≥n causal principal debemos cerrar todas las puertas traseras (caminos causales entre la causa y el efecto que queremos estudiar que tienen alguna flecha hacia atr√°s). Recordemos que para cerrar esos caminos debemos controlar por alguna de las variables que lo componen, agrag√°ndola como covariable a nuestro modelo estad√≠stico. Por √∫ltimo, recordemos que cuando tenemos un collider el camino est√° cerrado y al controlar por √©l lo abrimos.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Grafos ac√≠clicos dirigidos (DAGS)</span>"
    ]
  },
  {
    "objectID": "dags.html#un-ejemplo",
    "href": "dags.html#un-ejemplo",
    "title": "4¬† Grafos ac√≠clicos dirigidos (DAGS)",
    "section": "4.4 Un ejemplo",
    "text": "4.4 Un ejemplo\nAnalicemos un ejemplo que tiene un poquito de todo. En el mismo queremos estudiar la el efecto de las vitaminas (Vits) en los defectos de nacimiento (BD). Adem√°s de esta relaci√≥n, podemos identificar otras variables que podr√≠an influir en ellas: La dificultad para concebir un embarazo (DC); El cuidado pre-natal (PNC); el status socioecon√≥mico (SES); y aspectos gen√©ticos (Gen). El flujo de causalidad propuesto entre las variables puede verse representado en el siguiente DAG4:\n4¬†Recuerden que el diagrama causal no es un problema estad√≠stico sino m√°s bien se plantea previo a cualquier consideraci√≥n estad√≠stica, usando como insumo el conocimiento del dominio que tenemos.\n\nVer el c√≥digo\ndag_Vit &lt;- dagitty::dagitty('dag {\n                          BD [outcome,pos=\"0.109,0.631\"]\n                          DC [pos=\"0.117,-1.517\"]\n                          Gen [pos=\"0.850,-0.411\"]\n                          PNC [pos=\"-0.837,-0.433\"]\n                          SES [pos=\"-1.839,-1.468\"]\n                          Vits [exposure,pos=\"-1.844,0.645\"] \n                          DC -&gt; PNC\n                          Gen -&gt; BD\n                          Gen -&gt; DC\n                          PNC -&gt; BD\n                          PNC -&gt; Vits\n                          SES -&gt; PNC\n                          SES -&gt; Vits\n                          Vits -&gt; BD\n                          }')\n\ntidy_dag &lt;- tidy_dagitty(dag_Vit)\nggdag(tidy_dag) +\n  theme_dag()\n\n\n\n\n\nDAG que representa la relaci√≥n causal entre las vitaminas y los defectos de nacimiento.\n\n\n\n\nSi tenemos todos estos datos observados y queremos estimar el efecto causal de las vitaminas en los defectos de nacimiento, lo primero que tenemos que hacer es plantear todos los caminos abiertos. Esto lo podemos hacer a ojo, pero tambi√©n nos podemos ayudar con la funci√≥n ggdag_paths del paquete {ggdags}5. A continuaci√≥n vemos un ejemplo de uso de esta funci√≥n:\n5¬†Esto resulta especialmente √∫til cuando los DAGS se empiezan a complicar.\n\nVer el c√≥digo\ndag_Vit %&gt;% ggdag_paths(from = \"Vits\", to = \"BD\", shadow = TRUE) +\n  theme_dag() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nUsando ggdag_collider para identificar colliders en nuestro DAG.\n\n\n\n\nPodemos ver que los caminos abiertos son:\n\\[\n\\begin{array}\n_Vits \\longrightarrow BD\\\\\nVits \\longleftarrow PNC \\longrightarrow BD\\\\\nVits \\longleftarrow PNC \\longleftarrow DC \\longleftarrow Gen \\longrightarrow BD \\\\\nVits \\longleftarrow SES \\longrightarrow PNC \\longrightarrow BD\n\\end{array}\n\\]\nPero ¬øPor qu√© no est√° abierto el camino \\(Vits \\leftarrow SES \\rightarrow PNC \\leftarrow DC \\leftarrow Gen \\rightarrow BD\\)? ¬°Exacto! Est√° cerrado, porque para ese camino PNC es un collider, ya que est√° causada tanto por SES como por DC. Resulta importante notar que una variable es un collider o no en el contexto de un camino de causalidad y no lo es siempre. De hecho, podemos ver que PNC act√∫a como un confusor en el camino \\(Vits \\leftarrow PNC \\rightarrow BD\\). La funci√≥n ggdag_collider tambi√©n nos puede ayudar a identificar un collider.\n\n\nVer el c√≥digo\ndag_Vit %&gt;% ggdag_collider() +\n     theme_dag() +\n     scale_color_brewer(palette = \"Dark2\")\n\n\n\n\n\nUsando ggdag_collider para identificar colliders en nuestro DAG.\n\n\n\n\nEntonces tenemos cuatro caminos abiertos, el que queremos estudiar y tres puertas de atr√°s. Sin embargo, todo indica que tenemos que controlar por PNC y listo ¬øNo? Apliquemos esto agregando el par√°metro adjust_for = \"PNC\" a la funci√≥n ggdag_paths:\n\n\nVer el c√≥digo\ndag_Vit %&gt;% ggdag_paths(from = \"Vits\", to = \"BD\",\n                       adjust_for = \"PNC\", shadow = TRUE) +\n  theme_dag() +\n  labs(hue = NULL) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nCaminos causales abiertos luego de controlar por PNC.\n\n\n\n\nSin embargo, podemos ver que, a√∫n controlando por PNC, los caminos abiertos son:\n\\[\n\\begin{array}\n_Vits \\longrightarrow BD\\\\\nVits \\leftarrow SES \\rightarrow PNC \\leftarrow DC \\leftarrow Gen \\rightarrow BD\n\\end{array}\n\\]\n¬øQu√© pas√≥? Bueno, lo que pas√≥ es que al controlar por un collider abrimos un camino que estaba cerrado. Miremos qu√© pasa si controlamos por PNC y DC:\n\n\nVer el c√≥digo\ndag_Vit %&gt;% ggdag_paths(from = \"Vits\", to = \"BD\",\n                       adjust_for = c(\"PNC\", \"DC\"), shadow = TRUE) +\n  theme_dag() +\n  labs(hue = NULL) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nCaminos causales abiertos luego de controlar por Diab y Smok.\n\n\n\n\nAhora s√≠, el √∫nico camino abierto es \\(Vits \\rightarrow BD\\), que es la relaci√≥n causal que queremos estudiar. Finalmente, el modelo que deber√≠amos ajustar es:\n\\[\nBD_i = \\alpha + \\beta_{Vits} Vits_i + \\beta_{PNC} PNC_i + \\beta_{DC} DC_i + \\epsilon_i\n\\]\nDonde \\(\\beta_{Vits}\\) es un estimador del efecto causal que queremos estudiar.\nPara m√°s ejemplos y detalles sobre los DAGS pueden consultar (Cunningham 2021) o (Huntington-Klein 2021). El canal de YouTube de Nick Huntington-Klein tambi√©n es un excelente recurso para profundizar sobre estos temas6.\n\n\n\nCunningham, Scott. 2021. Causal inference: The mixtape. Yale university press.\n6¬†Nick es el autor de (Huntington-Klein 2021).\nHuntington-Klein, Nick. 2021. The effect: An introduction to research design and causality. Chapman; Hall/CRC.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Grafos ac√≠clicos dirigidos (DAGS)</span>"
    ]
  },
  {
    "objectID": "exp_aleatorios.html",
    "href": "exp_aleatorios.html",
    "title": "5¬† Experimentos aleatorios",
    "section": "",
    "text": "5.1 ¬øPor qu√© son importantes los experimentos aleatorios?\nEn los experimentos aleatorios1 los sujetos son asignados a los grupos (por ejemplo, tratamiento y control) aleatoriamente. Esto significa que en la asignaci√≥n de los grupos aleatorios hay involucrado un proceso realmente aleatorio, como arrojar un moneda. Ojo con confundir el concepto de asignaci√≥n aleatoria con el de muestra aleatoria: Que el muestreo sea aleatorio significa que los participantes son una muestra seleccionada al azar de una poblaci√≥n m√°s amplia, mientras que la asignaci√≥n aleatoria significa que los participantes, independientemente de si fueron seleccionados de una poblaci√≥n m√°s amplia o no, son asignados al azar a diferentes condiciones experimentales.\nPor ejemplo, en el caso m√°s simple, esto significa que dada una muestra de personas, vamos a asignar a cada de una de ellas ‚Äútirando una moneda‚Äù al grupo control (\\(D=0\\)) o tratamiento (\\(D=1\\)) como se ve en la siguiente figura.\nLos experimentos aleatorios son el gold-standard para estimar el efecto de un tratamiento. De hecho, al ser la asignaci√≥n aleatoria, podemos asegurar que, como mencionamos en el cap√≠tulo Cap√≠tulo 3, existe independencia (\\((Y^0, Y^1) \\perp D\\)). Esto nos asegura que la diferencia de medias de los grupos tratamiento y control son un estimador consistente del ATE. Dicho esto, veremos que hay formas m√°s ‚Äúeficientes‚Äù de estimar el ATE, es decir, con mayo potencia estad√≠stica.\nHay una raz√≥n extra para que en este libro empecemos hablando en detalle de los experimentos aleatorizados, y es que cuando entremos de lleno en el mundo de los cuasiexperimentos nos ser√° de gran ayuda entender cu√°l es el problema y cu√°l es la soluci√≥n que se propone. Esto nos va a permitir tener una idea m√°s concreta de las ventajas y limitaciones de cada uno de los dise√±os cuasiexperimentales que vamos a estudiar m√°s adelante.\nEn muchas ocasiones los experimentos aleatorios terminan siendo degradados a la categor√≠a de cuasiexperimento. Por ejemplo: Supongamos que hay un estudio que quiere evaluar el efecto de un programa de mindfulness en la cantidad de hechos de violencia en un establecimiento educativo. Para esto se asigno aleatoriamente a diez escuelas al grupo mindfulness y diez escuelas al grupo control. Hasta ac√° todo muy lindo, deber√≠amos llevar adelante el programa, medir la cantidad de hechos de violencia en cada escuela, hacer la diferencia de medias y voil√°, ya tenemos un estimador del ATE. Pero a veces las cosas no son tan sencillas y en el medio de este experimento van a pasar cosas. Por ejemplo, hay un grupo de colegios del grupo control que, por presi√≥n de los padres, incorporan un programa de mindfulness propio, mientras que otro grupo del colegios, esta vez del grupo tratamiento, deciden no implementar el programa de mindfulness propuesto por nosotros porque les interfiere con la curricula. Para colmo, varios colegios de ambos grupos deciden que la participaci√≥n sea voluntaria. En fin, el horror. Lo que nos termina pasando es que, aunque el dise√±o sea un experimento aleatorio, la p√©rdida de control sobre la implementaci√≥n y la participaci√≥n voluntaria generan contaminaci√≥n y sesgo de selecci√≥n, degradando el estudio a un cuasiexperimento. Es decir, la comparaci√≥n entre grupos ya no se basa en la aleatorizaci√≥n y vamos a requerir de otros controles estad√≠sticos para corregir posibles sesgos. M√°s adelante vamos a charlar un poquito m√°s de esto.\nDicho esto volvamos al maravilloso mundo de los üåàexperimentos aleatorizados idealesüåà.",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Experimentos aleatorios</span>"
    ]
  },
  {
    "objectID": "exp_aleatorios.html#sdf",
    "href": "exp_aleatorios.html#sdf",
    "title": "5¬† Experimentos aleatorios",
    "section": "5.1 Sdf",
    "text": "5.1 Sdf"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Referencias",
    "section": "",
    "text": "Barto≈°, Franti≈°ek, Alexandra Sarafoglou, Henrik R Godmann, Amir Sahrani,\nDavid Klein Leunk, Pierre Y Gui, David Voss, et al. 2023. ‚ÄúFair\nCoins Tend to Land on the Same Side They Started: Evidence from 350,757\nFlips.‚Äù arXiv Preprint arXiv:2310.04153.\n\n\nCunningham, Scott. 2021. Causal Inference: The Mixtape. Yale\nuniversity press.\n\n\nHerzog, Michael H, Gregory Francis, and Aaron Clarke. 2019.\nUnderstanding Statistics and Experimental Design: How to Not Lie\nwith Statistics. Springer Nature.\n\n\nHuntington-Klein, Nick. 2021. The Effect: An Introduction to\nResearch Design and Causality. Chapman; Hall/CRC.\n\n\nLakens, Daniel. 2022. ‚ÄúSample Size Justification.‚Äù\nCollabra: Psychology 8 (1): 33267.\n\n\nMaier, Maximilian, and Dani√´l Lakens. 2022. ‚ÄúJustify Your Alpha: A\nPrimer on Two Practical Approaches.‚Äù Advances in Methods and\nPractices in Psychological Science 5 (2): 25152459221080396.\n\n\nMcCrary, Justin. 2008. ‚ÄúManipulation of the Running Variable in\nthe Regression Discontinuity Design: A Density Test.‚Äù Journal\nof Econometrics 142 (2): 698‚Äì714.\n\n\nR Core Team. 2023. R: A Language and Environment for Statistical\nComputing. Vienna, Austria: R Foundation for Statistical Computing.\nhttps://www.R-project.org/.\n\n\nRubin, Donald B. 1974. ‚ÄúEstimating Causal Effects of Treatments in\nRandomized and Nonrandomized Studies.‚Äù Journal of Educational\nPsychology 66 (5): 688.\n\n\nSchafer, Jerome, and John B Holbein. 2020. ‚ÄúWhen Time Is of the\nEssence: A Natural Experiment on How Time Constraints Influence\nElections.‚Äù The Journal of Politics 82 (2): 418‚Äì32.\n\n\nWasserman, Larry. 2004. All of Statistics: A Concise Course in\nStatistical Inference. Springer Science & Business Media.\n\n\nWickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy\nD‚ÄôAgostino McGowan, Romain Fran√ßois, Garrett Grolemund, et al. 2019.\n‚ÄúWelcome to the Tidyverse.‚Äù Journal of Open Source\nSoftware 4 (43): 1686.\n\n\nWickham, Hadley, Mine √áetinkaya-Rundel, and Garrett Grolemund. 2023.\nR for Data Science. \" O‚ÄôReilly Media, Inc.\".",
    "crumbs": [
      "Referencias"
    ]
  },
  {
    "objectID": "dags.html#causalidad-sin-correlaci√≥n",
    "href": "dags.html#causalidad-sin-correlaci√≥n",
    "title": "4¬† Grafos ac√≠clicos dirigidos (DAGS)",
    "section": "4.3 Causalidad sin correlaci√≥n",
    "text": "4.3 Causalidad sin correlaci√≥n\nMuchas veces escuchamos que ‚Äúcorrelaci√≥n no implica causalidad‚Äù pero ¬øCausalidad implica correlaci√≥n? Respondamos esta pregunta con un ejemplo. Supongamos que hay una relaci√≥n causal entre el ingreso (I) y la satisfacci√≥n (S), a m√°s ingreso m√°s satisfacci√≥n."
  },
  {
    "objectID": "intro_R.html#tidy-data",
    "href": "intro_R.html#tidy-data",
    "title": "1¬† R y el tidyverse",
    "section": "",
    "text": "2¬†El caso contrario ser√≠a en el que una fila contiene varios mediciones para distintos niveles de una variable. Este formato se conoce como wide.\n\n\nTabla¬†1.1: Ejemplo de tablas tidy y wide.\n\n\n\n\n\n\n\n(a) Tidy\n\n\n\n\n\nsujeto\ntrial\ntiempo_respuesta\n\n\n\n\nJerry\n1\n0.0807501\n\n\nJerry\n2\n0.8343330\n\n\nElaine\n1\n0.6007609\n\n\nElaine\n2\n0.1572084\n\n\nGeorge\n1\n0.0073994\n\n\nGeorge\n2\n0.4663935\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b) Wide\n\n\n\n\n\nsujeto\ntrial_1\ntrial_2\n\n\n\n\nJerry\n0.4977774\n0.7725215\n\n\nElaine\n0.2897672\n0.8746007\n\n\nGeorge\n0.7328820\n0.1749406",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>R y el tidyverse</span>"
    ]
  },
  {
    "objectID": "intro_R.html#introducci√≥n-al-tidyverse",
    "href": "intro_R.html#introducci√≥n-al-tidyverse",
    "title": "1¬† R y el tidyverse",
    "section": "1.2 Introducci√≥n al Tidyverse",
    "text": "1.2 Introducci√≥n al Tidyverse\nComo contamos m√°s arriba, el tidyverse es una colecci√≥n cerca de 25 paquetes, todos relacionados con la carga, manejo, modificaci√≥n y visualizaci√≥n de datos. La idea de este libro no es profundizar en todas sus capacidades pero consideramos importante presentar algunas de las funciones que m√°s vamos a utilizar a lo largo del libro. Estas son funciones para leer datos del paquete {readr}, los verbos de {dplyr} para manipularlos, las funciones de {tidyR} para acomodarlos y el poderos√≠simo {ggplot2} para visualizarlos.\n\n1.2.1 Cargando datos con readr\nUna de las cosas que vamos a hacer m√°s a menudo en este libro es cargar alg√∫n dataset. Para esto vamos a usar varias de las funcionalidades del paquete {readr}.\nEl caso m√°s simple al que nos vamos a enfrentar es la carga de una base de datos organizada en columnas y separadas por comas en un archivo de extensi√≥n .csv. En este caso lo que tenemos que hacer es bastante simple, usar la funci√≥n read_csv() como a continuaci√≥n:\n\n\nVer el c√≥digo\nsummer &lt;- read_csv(\"../data/summer.csv\")\n\n\nPodemos ver que al cargar los datos read_csv nos dice que hay ocho columnas chr (o sea de texto) y una dbl (o sea, un n√∫mero). Si usamos la funci√≥n summary podemos ver un detalle de cada avriable con su tipo y alguna descripci√≥n3:\n3¬†Existen alternativas para visualizar r√°pidamente un conjunto de datos como str o glimpse o la funci√≥n skim del paquete {skimr}.\n\nVer el c√≥digo\nsummary(summer)\n#&gt;       Year          City              Sport            Discipline       \n#&gt;  Min.   :1896   Length:31165       Length:31165       Length:31165      \n#&gt;  1st Qu.:1948   Class :character   Class :character   Class :character  \n#&gt;  Median :1980   Mode  :character   Mode  :character   Mode  :character  \n#&gt;  Mean   :1970                                                           \n#&gt;  3rd Qu.:2000                                                           \n#&gt;  Max.   :2012                                                           \n#&gt;    Athlete            Country             Gender             Event          \n#&gt;  Length:31165       Length:31165       Length:31165       Length:31165      \n#&gt;  Class :character   Class :character   Class :character   Class :character  \n#&gt;  Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n#&gt;                                                                             \n#&gt;                                                                             \n#&gt;                                                                             \n#&gt;     Medal          \n#&gt;  Length:31165      \n#&gt;  Class :character  \n#&gt;  Mode  :character  \n#&gt;                    \n#&gt;                    \n#&gt; \n\n\nLos datos adentro de summer.csv son los ganadores de medallas en los juegos ol√≠mpicos de verano. Podemos ver algunas filas de muestra:\n\n\nVer el c√≥digo\nhead(summer)\n#&gt; # A tibble: 6 √ó 9\n#&gt;    Year City   Sport    Discipline Athlete               Country Gender\n#&gt;   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    &lt;chr&gt;      &lt;chr&gt;                 &lt;chr&gt;   &lt;chr&gt; \n#&gt; 1  1896 Athens Aquatics Swimming   HAJOS, Alfred         HUN     Men   \n#&gt; 2  1896 Athens Aquatics Swimming   HERSCHMANN, Otto      AUT     Men   \n#&gt; 3  1896 Athens Aquatics Swimming   DRIVAS, Dimitrios     GRE     Men   \n#&gt; 4  1896 Athens Aquatics Swimming   MALOKINIS, Ioannis    GRE     Men   \n#&gt; 5  1896 Athens Aquatics Swimming   CHASAPIS, Spiridon    GRE     Men   \n#&gt; 6  1896 Athens Aquatics Swimming   CHOROPHAS, Efstathios GRE     Men   \n#&gt; # ‚Ñπ 2 more variables: Event &lt;chr&gt;, Medal &lt;chr&gt;\n\n\nEl formato en el que read_csv almacena los datos se llama tibble y es el formato por excelencia del tidyverse. De momento lo √∫nico que nos importa es que es un formato que almacena los casos en filas y las variables en columnas (cada variable tiene un formato). Para m√°s informaci√≥n sobre las cualidades de este formato, les recomiendo revisar la documentaci√≥n.\n\n\n1.2.2 El operador pipe (|&gt;) del paquete {magrittr}\nEl operador pipe nos permite concatenar funciones que utilizan como entrada los mismos datos. El principio de operaci√≥n es el siguiente, supongan que nosotros queremos cargar un dataset y aplicarle la funci√≥n summary. Esto lo podemos hacer simplemente cargando el dataset en una l√¨nea de c√≥digo y ejecutanco la funci√≥n summary() en la siguiente.\n\n\nVer el c√≥digo\ndata &lt;- read_csv(\"../data/summer.csv\")\nsummary(data)\n#&gt;       Year          City              Sport            Discipline       \n#&gt;  Min.   :1896   Length:31165       Length:31165       Length:31165      \n#&gt;  1st Qu.:1948   Class :character   Class :character   Class :character  \n#&gt;  Median :1980   Mode  :character   Mode  :character   Mode  :character  \n#&gt;  Mean   :1970                                                           \n#&gt;  3rd Qu.:2000                                                           \n#&gt;  Max.   :2012                                                           \n#&gt;    Athlete            Country             Gender             Event          \n#&gt;  Length:31165       Length:31165       Length:31165       Length:31165      \n#&gt;  Class :character   Class :character   Class :character   Class :character  \n#&gt;  Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n#&gt;                                                                             \n#&gt;                                                                             \n#&gt;                                                                             \n#&gt;     Medal          \n#&gt;  Length:31165      \n#&gt;  Class :character  \n#&gt;  Mode  :character  \n#&gt;                    \n#&gt;                    \n#&gt; \n\n\nPero, tambi√©n podemos aprovechar el operador pipe y hacer todo en una √∫nica l√≠nea de c√≥digo.\n\n\nVer el c√≥digo\nread_csv(\"../data/summer.csv\") |&gt; summary()\n#&gt;       Year          City              Sport            Discipline       \n#&gt;  Min.   :1896   Length:31165       Length:31165       Length:31165      \n#&gt;  1st Qu.:1948   Class :character   Class :character   Class :character  \n#&gt;  Median :1980   Mode  :character   Mode  :character   Mode  :character  \n#&gt;  Mean   :1970                                                           \n#&gt;  3rd Qu.:2000                                                           \n#&gt;  Max.   :2012                                                           \n#&gt;    Athlete            Country             Gender             Event          \n#&gt;  Length:31165       Length:31165       Length:31165       Length:31165      \n#&gt;  Class :character   Class :character   Class :character   Class :character  \n#&gt;  Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n#&gt;                                                                             \n#&gt;                                                                             \n#&gt;                                                                             \n#&gt;     Medal          \n#&gt;  Length:31165      \n#&gt;  Class :character  \n#&gt;  Mode  :character  \n#&gt;                    \n#&gt;                    \n#&gt; \n\n\nAl dejar vac√≠o el par√©ntesis de la funci√≥n summary(), la misma va a tomar como variable de entrada a la que est√° antes del operador pipe, es decir, a la que antes llamamos data. En el caso que la funci√≥n summary() tuviera m√°s de una variable de entrada, lo que viene antes del pipe tomar√≠a el lugar de la primera de ellas.\nSi bien esta funcionalidad parece algo que complica las cosas y que no trae demasiados beneficios con un ejemplo tan simple, m√°s adelante veremos que puede ser de gran utilidad, ayudando a disminuir la cantidad de l√≠nes de c√≥digo y de variables intermedias.\n\n\n1.2.3 {dplyr} y sus verbos\nUna de las cosas m√°s √∫tiles del tidyverse para el tipo de procesamiento de datos que vamos a llevar a cabo en este libro son los verbos de dplyr. Estas funciones no permiten agregar columnas, resumir la informaci√≥n, filtrar filas, seleccionar columnas, etc4. Y todas estas acciones las podemos hacer en la base de datos completa o en una parte de ella agrupada de acuerdo a alg√∫n criterio. Vayamos de a poco.\n4¬†Para m√°s detalles sobre los verbos disponibles en el paquete {dplyr} pueden visital este la p√°gina de referencia.\n1.2.3.1 El verbo filter\nVolvamos a los datos de los JJOO de verano. Supongamos que nos queremos quedar s√≥lo con las medallas de Argentina. Para este tipo de filtrado de filas (o casos, o mediciones) {dplyr} tiene un verbo que se llama filter y funciona de la siguiente forma5:\n5¬†Se preguntar√°n por qu√© antes de la funci√≥n filter aparece un ::dplyr. Esto es simplemente una forma de decirle a R que la funci√≥n filter que debe utilizar es la del paquete {dplyr}. Esta es una pr√°ctica recomendable sobre todo para funciones con nombres comunes como filter o select.\n\nVer el c√≥digo\nsummer |&gt; dplyr::filter(Country == \"ARG\") |&gt; head(10)\n#&gt; # A tibble: 10 √ó 9\n#&gt;    Year City  Sport     Discipline Athlete          Country Gender\n#&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;     &lt;chr&gt;      &lt;chr&gt;            &lt;chr&gt;   &lt;chr&gt; \n#&gt; 1  1924 Paris Athletics Athletics  BRUNETO, Luis    ARG     Men   \n#&gt; 2  1924 Paris Boxing    Boxing     PORZIO, Alfredo  ARG     Men   \n#&gt; 3  1924 Paris Boxing    Boxing     QUARTUCCI, Pedro ARG     Men   \n#&gt; 4  1924 Paris Boxing    Boxing     COPELLO, Alfredo ARG     Men   \n#&gt; 5  1924 Paris Boxing    Boxing     MENDEZ, Hector   ARG     Men   \n#&gt; 6  1924 Paris Polo      Polo       KENNY, Arturo    ARG     Men   \n#&gt; # ‚Ñπ 4 more rows\n#&gt; # ‚Ñπ 2 more variables: Event &lt;chr&gt;, Medal &lt;chr&gt;\n\n\nNoten que estamos utilizando el operador |&gt; para concatenar las acciones: Con los datos de summer hacemos el filtrado y, luego, mostramos las primeras diez filas de esos datos ya filtrados.\nTambi√©n podr√≠amos quere quedarnos con las medallas de Argenitna en los JJOO de Atenas 2004, para esto debemos el operador l√≥gico ‚Äúy‚Äù, cuyo s√≠mbolo en R es &:\n\n\nVer el c√≥digo\nsummer |&gt; dplyr::filter(Country == \"ARG\" & Year == 2004) |&gt; head(5)\n#&gt; # A tibble: 5 √ó 9\n#&gt;    Year City   Sport      Discipline Athlete                   Country Gender\n#&gt;   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;                     &lt;chr&gt;   &lt;chr&gt; \n#&gt; 1  2004 Athens Aquatics   Swimming   BARDACH, Georgina         ARG     Women \n#&gt; 2  2004 Athens Basketball Basketball DELFINO, Carlos Francisco ARG     Men   \n#&gt; 3  2004 Athens Basketball Basketball FERNANDEZ, Gabriel Diego  ARG     Men   \n#&gt; 4  2004 Athens Basketball Basketball GINOBILI, Emanuel David   ARG     Men   \n#&gt; 5  2004 Athens Basketball Basketball GUTIERREZ, Leonardo Mart‚Ä¶ ARG     Men   \n#&gt; # ‚Ñπ 2 more variables: Event &lt;chr&gt;, Medal &lt;chr&gt;\n\n\nQue linda esa Generaci√≥n DoradaüèÖ, ¬øNo?.Por otro lado, si nos queremos quedar con las medallas de Argentina o Brasil debemos utilizar el operador l√≥gico ‚Äúo‚Äù, cuyo s√≠mbolo en R es |:\n\n\nVer el c√≥digo\nsummer |&gt; dplyr::filter(Country == \"ARG\" | Country == \"BRA\") |&gt; head(10)\n#&gt; # A tibble: 10 √ó 9\n#&gt;    Year City    Sport    Discipline Athlete                   Country Gender\n#&gt;   &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;    &lt;chr&gt;      &lt;chr&gt;                     &lt;chr&gt;   &lt;chr&gt; \n#&gt; 1  1920 Antwerp Shooting Shooting   PARAENSE, Guilherme       BRA     Men   \n#&gt; 2  1920 Antwerp Shooting Shooting   BARBOSA, Dario            BRA     Men   \n#&gt; 3  1920 Antwerp Shooting Shooting   DA COSTA, Afranio Antonio BRA     Men   \n#&gt; 4  1920 Antwerp Shooting Shooting   PARAENSE, Guilherme       BRA     Men   \n#&gt; 5  1920 Antwerp Shooting Shooting   SOLEDADE, Fernando        BRA     Men   \n#&gt; 6  1920 Antwerp Shooting Shooting   WOLF, Sebastiao           BRA     Men   \n#&gt; # ‚Ñπ 4 more rows\n#&gt; # ‚Ñπ 2 more variables: Event &lt;chr&gt;, Medal &lt;chr&gt;\n\n\nAunque, una alternativa muy √∫til cuando tenemos los valores de una variable que queremos filtrar en un array es:\n\n\nVer el c√≥digo\nsummer |&gt; dplyr::filter(Country %in% c(\"ARG\", \"BRA\")) |&gt; head(10)\n#&gt; # A tibble: 10 √ó 9\n#&gt;    Year City    Sport    Discipline Athlete                   Country Gender\n#&gt;   &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;    &lt;chr&gt;      &lt;chr&gt;                     &lt;chr&gt;   &lt;chr&gt; \n#&gt; 1  1920 Antwerp Shooting Shooting   PARAENSE, Guilherme       BRA     Men   \n#&gt; 2  1920 Antwerp Shooting Shooting   BARBOSA, Dario            BRA     Men   \n#&gt; 3  1920 Antwerp Shooting Shooting   DA COSTA, Afranio Antonio BRA     Men   \n#&gt; 4  1920 Antwerp Shooting Shooting   PARAENSE, Guilherme       BRA     Men   \n#&gt; 5  1920 Antwerp Shooting Shooting   SOLEDADE, Fernando        BRA     Men   \n#&gt; 6  1920 Antwerp Shooting Shooting   WOLF, Sebastiao           BRA     Men   \n#&gt; # ‚Ñπ 4 more rows\n#&gt; # ‚Ñπ 2 more variables: Event &lt;chr&gt;, Medal &lt;chr&gt;\n\n\nFinalmente, si tenemos una variable num√©rica, podemos filtrar con condiciones como mayor o menor:\n\n\nVer el c√≥digo\nsummer |&gt; dplyr::filter(Year &gt; 2010) |&gt; head(5)\n#&gt; # A tibble: 5 √ó 9\n#&gt;    Year City   Sport    Discipline Athlete          Country Gender\n#&gt;   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    &lt;chr&gt;      &lt;chr&gt;            &lt;chr&gt;   &lt;chr&gt; \n#&gt; 1  2012 London Aquatics Diving     BOUDIA, David    USA     Men   \n#&gt; 2  2012 London Aquatics Diving     QIU, Bo          CHN     Men   \n#&gt; 3  2012 London Aquatics Diving     DALEY, Thomas    GBR     Men   \n#&gt; 4  2012 London Aquatics Diving     CHEN, Ruolin     CHN     Women \n#&gt; 5  2012 London Aquatics Diving     BROBEN, Brittany AUS     Women \n#&gt; # ‚Ñπ 2 more variables: Event &lt;chr&gt;, Medal &lt;chr&gt;\n\n\n\n\n1.2.3.2 El verbo select\nEl verbo select es similar a filter pero nos permite filtrar no casos sino variables. Por ejemplo, ¬øQu√© pasa si solo nos interesa el a√±o, la ciudad y el nombre del atleta?:\n\n\nVer el c√≥digo\nsummer |&gt; dplyr::select(c(Year, City, Athlete)) |&gt; head(5)\n#&gt; # A tibble: 5 √ó 3\n#&gt;    Year City   Athlete           \n#&gt;   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;             \n#&gt; 1  1896 Athens HAJOS, Alfred     \n#&gt; 2  1896 Athens HERSCHMANN, Otto  \n#&gt; 3  1896 Athens DRIVAS, Dimitrios \n#&gt; 4  1896 Athens MALOKINIS, Ioannis\n#&gt; 5  1896 Athens CHASAPIS, Spiridon\n\n\n\n\n1.2.3.3 El verbo mutate\nAhora las cosas se complican un poco. mutate es un verbo que nos permite crear nuevas columnas ya sea con datos nuevos o en funci√≥n de los datos existentes. Por ejemplo, creemos una columna nueva que tenga un chr con el pa√≠s, un gui√≥n y el nombre del atleta y llam√©mosla nationality_athlete. Nos vamos a quedar s√≥lo con el a√±o, la medalla que gan√≥ y el nuevo nombre combinado con la nacionalidad:\n\n\nVer el c√≥digo\nsummer |&gt; \n  dplyr::mutate(nationality_athlete = paste(Country, \"-\", Athlete)) |&gt; \n  dplyr::select(c(Year, Medal, nationality_athlete)) |&gt;\n  head(5)\n#&gt; # A tibble: 5 √ó 3\n#&gt;    Year Medal  nationality_athlete     \n#&gt;   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;                   \n#&gt; 1  1896 Gold   HUN - HAJOS, Alfred     \n#&gt; 2  1896 Silver AUT - HERSCHMANN, Otto  \n#&gt; 3  1896 Bronze GRE - DRIVAS, Dimitrios \n#&gt; 4  1896 Gold   GRE - MALOKINIS, Ioannis\n#&gt; 5  1896 Silver GRE - CHASAPIS, Spiridon\n\n\nO, por ejemplo, podemos querer crear una variable que nos ponga un \\(1\\) si es griego y un \\(0\\) si no6:\n6¬†Para m√°s detalles sobre la funci√≥n if_else pueden ver el siguiente link.\n\nVer el c√≥digo\nsummer |&gt; \n  dplyr::mutate(is_greek = if_else(Country == \"GRE\", 1, 0)) |&gt; \n  dplyr::select(c(Year, Medal, Country, is_greek)) |&gt;\n  head(5)\n#&gt; # A tibble: 5 √ó 4\n#&gt;    Year Medal  Country is_greek\n#&gt;   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;      &lt;dbl&gt;\n#&gt; 1  1896 Gold   HUN            0\n#&gt; 2  1896 Silver AUT            0\n#&gt; 3  1896 Bronze GRE            1\n#&gt; 4  1896 Gold   GRE            1\n#&gt; 5  1896 Silver GRE            1\n\n\nAhora vamos a aprender algo muy importante y cool üÜí: A agrupar los casos de acuerdo a una variable. Por ejemplo, si queremos agregar una columna que contenga la cantidad total de medallas ganadas por un pa√≠s a cada atleta de ese pa√≠s podemos hacer lo siguiente:\n\n\nVer el c√≥digo\nsummer |&gt; \n  group_by(Country) |&gt;\n  dplyr::mutate(num_medals = n()) |&gt; \n  dplyr::select(c(Year, Medal, Athlete, num_medals)) |&gt;\n  head(5)\n#&gt; # A tibble: 5 √ó 5\n#&gt; # Groups:   Country [3]\n#&gt;   Country  Year Medal  Athlete            num_medals\n#&gt;   &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;                   &lt;int&gt;\n#&gt; 1 HUN      1896 Gold   HAJOS, Alfred            1079\n#&gt; 2 AUT      1896 Silver HERSCHMANN, Otto          146\n#&gt; 3 GRE      1896 Bronze DRIVAS, Dimitrios         148\n#&gt; 4 GRE      1896 Gold   MALOKINIS, Ioannis        148\n#&gt; 5 GRE      1896 Silver CHASAPIS, Spiridon        148\n\n\n¬øPerdidos? Tomens√© su tiepo para tratar de entender qu√© pas√≥ y prueben distintas alternativas en sus computadoras.\n\n\n1.2.3.4 El verbo summarise\nPor √∫ltimo, el verbo summarise nos permite sacar medidas resumen de nuestros datos. Empecemos con algo obvio: ¬øCu√°ntas medallas de oro gan√≥ cada pa√≠s en la historia de los juegos ol√≠mpicos?. Podemos hacer algo parecido a lo √∫ltimo que hicimos con mutate pero el resultados ser√° ligeramente diferente7:\n7¬†La funci√≥n arrange nos ordena los datos de acuerdo a la variable que le enviemos como par√°metro de menos a mayor. Si queremos que ordene de mayor a menor debemos agregar la funci√≥n desc en el argumento. M√°s detalles ac√°.\n\nVer el c√≥digo\nsummer |&gt; \n  dplyr::filter(Medal == \"Gold\") |&gt;\n  group_by(Country) |&gt;\n  dplyr::summarise(num_medals = n()) |&gt;\n  arrange(desc(num_medals)) |&gt;\n  head(10)\n#&gt; # A tibble: 10 √ó 2\n#&gt;   Country num_medals\n#&gt;   &lt;chr&gt;        &lt;int&gt;\n#&gt; 1 USA           2235\n#&gt; 2 URS            838\n#&gt; 3 GBR            546\n#&gt; 4 ITA            476\n#&gt; 5 GER            452\n#&gt; 6 HUN            412\n#&gt; # ‚Ñπ 4 more rows\n\n\nHay algo raro, ¬øNo? Bueno, s√≠, de esta forma estamos contando a todos los atletas que tuvieron la misma medalla (por ejemplo, si la medalla fue por f√∫tbol estamos contando cerca de 30 medallas). Para resolver esto nos podemos sacar de encima los casos duplicados por a√±o, deporte, disciplina, evento y g√©nero8:\n8¬†La funci√≥n distinct nos conserva una sola realizaci√≥n de cada caso que es igual de acuerdo a las variables que le pasemos como par√°metros. M√°s detalles ac√°.\n\nVer el c√≥digo\nsummer |&gt; \n  distinct(Year, Sport, Discipline, Event, Gender, .keep_all = TRUE) |&gt;\n  dplyr::filter(Medal == \"Gold\") |&gt;\n  group_by(Country) |&gt;\n  dplyr::summarise(num_medals = n()) |&gt;\n  arrange(desc(num_medals)) |&gt;\n  head(5)\n#&gt; # A tibble: 5 √ó 2\n#&gt;   Country num_medals\n#&gt;   &lt;chr&gt;        &lt;int&gt;\n#&gt; 1 USA             67\n#&gt; 2 GBR             46\n#&gt; 3 CHN             40\n#&gt; 4 RUS             22\n#&gt; 5 GER             19\n\n\nVayamos con lo √∫ltimo, calculemos la media y la desviaci√≥n est√°ndar de las medallas de Argentina por JJOO combinando todo lo que vimos.\n\n\nVer el c√≥digo\nsummer |&gt; \n  distinct(Year, Sport, Discipline, Event, Medal, Gender, .keep_all = TRUE) |&gt;\n  dplyr::filter(Country == \"ARG\") |&gt;\n  group_by(Country, Year) |&gt;\n  dplyr::summarise(num_medals = n()) |&gt;\n  ungroup() |&gt;\n  summarise(media  = mean(num_medals),\n            desvio = sd(num_medals))\n#&gt; # A tibble: 1 √ó 2\n#&gt;   media desvio\n#&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1  3.83   2.28\n\n\nDigieran esto tranquilos.\n\n\n\n1.2.4 {tidyR}, el paquete para ordenar tus datos\nEl paquete {tidyR} tiene muchas herramientas de manejo de tablas como reformatear, expandir tablas, manejar valores faltantes, dividir celdas, anidar datos, etc9. Sin embargo, en esta breve introducci√≥n s√≥lo vamos a presentar muy brevemente las herramientas que nos permiten convertir una tabla wide en tidy (o long) y viceverse.\n9¬†Para m√°s informaci√≥n ver el cheatsheet.\n1.2.4.1 La funci√≥n pivot_longer\nVolvamos a la tabla iniicial que ten√≠amos en formato wide:\n\n\nVer el c√≥digo\ntabla_wide &lt;- tibble(sujeto  = rep(c(\"Jerry\", \"Elaine\", \"George\")),\n                     trial_1 = runif(3),\n                     trial_2 = runif(3)) \n\ntabla_wide\n#&gt; # A tibble: 3 √ó 3\n#&gt;   sujeto trial_1 trial_2\n#&gt;   &lt;chr&gt;    &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 Jerry    0.320  0.404 \n#&gt; 2 Elaine   0.402  0.0637\n#&gt; 3 George   0.196  0.389\n\n\nSi nosotros quisi√±eramos transformar esta tabla en una tabla en formato tidy podemos utilizar la funci√≥n pivot_longer10. Veamos como funciona y despu√©s la desmenuzamos:\n10¬†M√°s informaci√≥n ac√°.\n\nVer el c√≥digo\npivot_longer(data = tabla_wide, \n             cols = trial_1:trial_2, \n             names_to = \"trial\",\n             values_to = \"tiempo_respuesta\")\n#&gt; # A tibble: 6 √ó 3\n#&gt;   sujeto trial   tiempo_respuesta\n#&gt;   &lt;chr&gt;  &lt;chr&gt;              &lt;dbl&gt;\n#&gt; 1 Jerry  trial_1           0.320 \n#&gt; 2 Jerry  trial_2           0.404 \n#&gt; 3 Elaine trial_1           0.402 \n#&gt; 4 Elaine trial_2           0.0637\n#&gt; 5 George trial_1           0.196 \n#&gt; 6 George trial_2           0.389\n\n\nLos argumentos son los siguientes: data es la tabla a la que le vamos a realizar el cambio de formato; cols son las columnas que vamos a cambiar, en este caso desde trial_1 a trial_2; en names_to indicamos la variable a la que vamos a mandar los nombres de las columnas actuales; y values_to la variables a la que vamos a mandar los valores.\nAlgo ligeramente raro es que la columna trial no es num√©rica y, s√≥lo por completitud, lo vamos a solucionar usando a nuestro gran amigo |&gt; y al verbo mutate11:\n11¬†Y la funci√≥n parse_number del paquete {readr}.\n\nVer el c√≥digo\npivot_longer(data = tabla_wide, \n             cols = trial_1:trial_2, \n             names_to = \"trial\",\n             values_to = \"tiempo_respuesta\") |&gt;\n  mutate(trial = parse_number(trial))\n#&gt; # A tibble: 6 √ó 3\n#&gt;   sujeto trial tiempo_respuesta\n#&gt;   &lt;chr&gt;  &lt;dbl&gt;            &lt;dbl&gt;\n#&gt; 1 Jerry      1           0.320 \n#&gt; 2 Jerry      2           0.404 \n#&gt; 3 Elaine     1           0.402 \n#&gt; 4 Elaine     2           0.0637\n#&gt; 5 George     1           0.196 \n#&gt; 6 George     2           0.389\n\n\n\n\n1.2.4.2 La funci√≥n pivot_wider\nAhora vamos con el caso contrario en el que tenemos una tabla en formato long y la queremos convertir en wide:\n\n\nVer el c√≥digo\ntabla_long &lt;- pivot_longer(data = tabla_wide, \n                           cols = trial_1:trial_2, \n                           names_to = \"trial\",\n                           values_to = \"tiempo_respuesta\") |&gt;\n  mutate(trial = parse_number(trial))\n\ntabla_long\n#&gt; # A tibble: 6 √ó 3\n#&gt;   sujeto trial tiempo_respuesta\n#&gt;   &lt;chr&gt;  &lt;dbl&gt;            &lt;dbl&gt;\n#&gt; 1 Jerry      1           0.320 \n#&gt; 2 Jerry      2           0.404 \n#&gt; 3 Elaine     1           0.402 \n#&gt; 4 Elaine     2           0.0637\n#&gt; 5 George     1           0.196 \n#&gt; 6 George     2           0.389\n\n\nPara esto vamos a hechar mano a la funci√≥n pivot_wider12 que tiene una sint√°xis parecida a su prima pivot_longer:\n12¬†M√°s informaci√≥n ac√°.\n\nVer el c√≥digo\npivot_wider(data = tabla_long, \n            names_from = trial, \n            values_from = tiempo_respuesta)\n#&gt; # A tibble: 3 √ó 3\n#&gt;   sujeto   `1`    `2`\n#&gt;   &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1 Jerry  0.320 0.404 \n#&gt; 2 Elaine 0.402 0.0637\n#&gt; 3 George 0.196 0.389\n\n\nEt Voil√†!, ya tenemos nuestra tabla en formato wide. En este caso le dijimos de que variable tomar los nombres de las nuevas columnas en names_from y de que variable tomar los valores en values_from.\nFinalmente, y s√≥lo para alimnetar nuestra obsesi√≥n, vamos a corregir los nombres de las columnas agregando el prefijo trial_ utilizando el par√°metro de la funci√≥n names_prefix:\n\n\nVer el c√≥digo\npivot_wider(data = tabla_long, \n            names_from = trial, \n            names_prefix = \"trial_\",\n            values_from = tiempo_respuesta)\n#&gt; # A tibble: 3 √ó 3\n#&gt;   sujeto trial_1 trial_2\n#&gt;   &lt;chr&gt;    &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 Jerry    0.320  0.404 \n#&gt; 2 Elaine   0.402  0.0637\n#&gt; 3 George   0.196  0.389",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>R y el tidyverse</span>"
    ]
  },
  {
    "objectID": "intro_R.html#algunas-palabras-finales",
    "href": "intro_R.html#algunas-palabras-finales",
    "title": "1¬† R y el tidyverse",
    "section": "1.3 Algunas palabras finales",
    "text": "1.3 Algunas palabras finales\nComo vimos brevemente en este cap√≠tulo, los paquetes del tidyverse son una herramineta important√≠sima para el an√°lisis de datos utilizando R. Para m√°s detalles sobre estas funcionalidades les recomendamos la gu√≠a de Hadley Wickham(Wickham et¬†al. 2019) o, si ya se quieren sumergir de lleno en el mundo del an√°lisis de datos con R, este fant√°stico libro (Wickham, √áetinkaya-Rundel, y Grolemund 2023)13. Es decir, sin tener que cargar ning√∫n paquete de funciones adicional..\n\n\n\nWickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy D‚ÄôAgostino McGowan, Romain Fran√ßois, Garrett Grolemund, et¬†al. 2019. ¬´Welcome to the Tidyverse¬ª. Journal of open source software 4 (43): 1686.\n\nWickham, Hadley, Mine √áetinkaya-Rundel, y Garrett Grolemund. 2023. R for data science. \" O‚ÄôReilly Media, Inc.\".\n13¬†Disponible gratis online en ac√°.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>R y el tidyverse</span>"
    ]
  },
  {
    "objectID": "potential_outcomes.html#presentaci√≥n",
    "href": "potential_outcomes.html#presentaci√≥n",
    "title": "3¬† Potential outcomes",
    "section": "3.1 Presentaci√≥n",
    "text": "3.1 Presentaci√≥n\nSupongamos que quiero evaluar la efectividad de la aspirina para mitigar el dolor de cabeza. Me duele la cabeza y lo quiero es saber el efecto diferencial entre tomar y no tomar esa aspirina. Es decir, en el tiempo 0 estoy yo con dolor de cabeza y en el tiempo 1 deber√≠a haber dos versiones m√≠as (como si una no fuera suficiente), la que tom√≥ la aspirina y la que no. A cada una de ellas les tendr√≠a que preguntar cu√°nto les duele la cabeza, el outcome de mi comparaci√≥n. No hace falta ser demasiado astuto para darse cuenta que esto es imposible ya que s√≥lo nos ser√° posible obsevar una de esas versiones mientras que la otra ser√° un contraf√°ctico.\nDe esto vamos a hablar en este cap√≠tulo, utilizando la tradici√≥n de los potential outcomes. Estas ideas terminan de tomar forma en la versi√≥n que conocemos en las ciencias sociales en (Rubin 1974)"
  },
  {
    "objectID": "intro_stat.html#inferencia-estad√≠stica",
    "href": "intro_stat.html#inferencia-estad√≠stica",
    "title": "2¬† Repaso de probabilidad y estad√≠stica",
    "section": "2.10 Inferencia estad√≠stica",
    "text": "2.10 Inferencia estad√≠stica\nVamos a hacer un breve paseo por los conceptos clave de la inferencia estad√≠stica de la mano de un ejemplo.\n\n\n\n\n\n\nEl ejemplo de inferencia\n\n\n\nSupongamos que tenemos una p√°gina web de noticias y queremos probar una nueva feature con la que queremos aumentar el tiempo de retenci√≥n de los usuarios. Para esto le vamos a presentar a los usuarios la versi√≥n nueva de la p√°gina y vamos a medir el tiempo que se mantienen en la p√°gina en ms6.\n\n\n6¬†Probabilemente lo m√°s correcto para responder esta pregunta sea un A/B test, pero ya hablaremos de eso m√°s adelante.7¬†Adem√°s, como vamos a ver m√°s adelante, cuando el \\(n\\) es lo suficientemente grande, esta condici√≥n deja de importar tanto.Primero definamos nuestra variable aleatoria: \\(X\\):‚ÄúLa diferencia de tiempo en ms entre despu√©s y antes del cambio‚Äù. Nuestro objetivo entonces es poder afirmar con cierto grado de seguridad si \\(E(X)\\) es igual a cero o distinto (nos importa tanto si aumenta como si disminuye). Empecemos con lo m√°s sencillo, supongamos que \\(X \\sim \\mathcal{N}(\\mu, \\sigma^2)\\). Esta suposici√≥n no es tan loca ya que mucho procesos naturales se distribuyen de forma normal7. Supongamos tambi√©n por un momento (m√°s adelante vamos a relajar esta condici√≥n) que, ya sea por un experimento previo o porque somos magos, conocemos la \\(\\sigma^2\\) de \\(X\\).\nComo dijimos en el recuedro, si bien nuestro objetivo es probar si \\(\\mu\\) es diferente de \\(0\\), esto lo vamos a hacer a partir de un experimento. Una vez que hagamos el experimento y midamos vamos a tener al cl√°sico estimador de \\(\\mu\\): \\(\\hat{\\mu}=\\bar{X}\\), es decir, el promedio muestral. Ahora supongamos que el promedio nos da \\(0.5\\): ¬øEs distinto de cero? Para responder esa pregunta es que vamos a utilizar las herramientas de la inferencia estad√≠stica.\nDefinamos primero las hip√≥tesis:\n\\[\n\\begin{array}\n_H_0 &:& \\mu = 0 \\\\\nH_1 &:& \\mu \\neq 0\n\\end{array}\n\\tag{2.19}\\]\nLo que vamos a querer hacer es rechazar \\(H_0\\) con cierto grado de confianza. Para esto vamos a comparar nuestra medici√≥n \\(\\bar{x}_{obs}\\) con la distribuci√≥n de los \\(\\bar{X}\\) bajo \\(H_0\\).\nRecordemos que si \\(X \\sim \\mathcal{N}(\\mu, \\sigma^2)\\) entonces \\(\\bar{X}_n \\sim \\mathcal{N}(\\mu, \\sigma^2/n)\\)8, donde \\(n\\) es la cantidad de realizaciones con las que yo calculo mi \\(\\bar{X}\\). Entonces si mi \\(\\bar{x}_{obs}\\) medida est√° lo suficientemente lejos de \\(0\\) podemos decir que que \\(\\mu\\) es diferente de cero. Pero: ¬øQu√© es suficientemente lejos?\n8¬†La \\(n\\) en \\(\\bar{X}_n\\) es simplemente para enfatizar que es el promedio de una seciencia de \\(n\\) realizaciones.Bueno, para responder esa pregunta vamos a tener que primero definir los errores que podemos cometer. Podemos cometer el error de decir que \\(\\mu\\) es diferente de cero cuando no lo es (Error tipo I o falso positivo) o podemos cometer el error de decir que \\(\\mu\\) no es diferente de cero cuando s√≠ lo es (Error tipo II o falso negativo). Nuestro razonamiento va a ser empezar acotando el error de tipo I.\nPara esto vamos a calcular qu√© tan probable es observar un valor igual o m√°s alejado del cero que \\(\\bar{x}_{obs}\\) dado que \\(H_0\\) es verdadera. Es decir, \\(P(|\\bar{X}|&gt;\\bar{x}_{obs}|H_0)\\). Esta magnitud es lo que se conoce como el viejo y querido p-valor o p-value (si te gusta hacerte el canchero). En nuestro caso lo podemos calcular expl√≠citamente. Empecemos estandarizando \\(\\bar{X}\\) de la siguiente forma:\n\\[\nZ = \\frac{\\bar{X} - \\mu}{\\sqrt{\\sigma^2/n}} \\sim \\mathcal{N}(0,1)\n\\tag{2.20}\\]\nQue bajo \\(H_0\\) es:\n\\[\nZ_{H_0} = \\frac{\\bar{X}}{\\sqrt{\\sigma^2/n}} \\sim \\mathcal{N}(0,1)\n\\tag{2.21}\\]\nEntonces, si consideramos a \\(z_{\\bar{x}}\\) como la versi√≥n estandarizada de \\(\\bar{x}_{obs}\\), podemos calcular el p-valor como:\n\\[\n\\begin{array}\n_p_{valor} &=& P(|Z| \\geq |z_{\\bar{x}}| \\: \\: |H_0) \\\\\n&=& P(Z \\geq |z_{\\bar{x}}| \\: \\: |H_0) + P(Z \\leq -|z_{\\bar{x}}| \\: \\: |H_0) \\\\\n&=& 2 P(Z \\leq -|z_{\\bar{x}}| \\: \\: |H_0)\n\\end{array}\n\\tag{2.22}\\]\nY como bajo \\(H_0\\) ocurre que \\(Z_{H_0} \\sim \\mathcal{N}(0,1)\\):\n\\[\np_{valor} = 2 \\phi(-|z_{\\bar{x}}|)\n\\tag{2.23}\\]\nY ahora que tenemos esta probabilidad qu√© hacemos. Bueno, lo que podemos hacer es decir: Si los datos vienen de \\(H_0\\) podemos calcular que tan ‚Äúraros‚Äù son, entonces pongamos una cota en esa probabilidad y de esa forma estaremos acotando el error de tipo I en el largo plazo9. As√≠ es que surge el famoso \\(\\alpha\\) que normalmente hacemos valer \\(0.05\\)10. ¬øQu√© significa eso? Bueno, significa que, si la hip√≥tesis nula fuera verdaera dir√≠amos euivocadamente que hay un efecto cuando no lo hay el \\(5%\\) de las veces. Este p√°rrafo se podr√≠a extender al infinito, pero por ahora qued√©monos con esta interpretaci√≥n ‚Äúpr√°ctica‚Äù del p-valor (si se quedan con las ganas pueden ir a leer esto).\n9¬†El enfoque frecuentista de la estad√≠stica justamente se basa en controlar los errores dada una repetici√≥n infinita de mi experimento.10¬†Para una discusi√≥n m√°s profunda sobre el tema de la selecci√≥n de \\(\\alpha\\) en la psicolog√≠a experimental les recomiendo este hermoso art√≠culo de Maier y Lakens (Maier y Lakens 2022).\nMaier, Maximilian, y Dani√´l Lakens. 2022. ¬´Justify your alpha: A primer on two practical approaches¬ª. Advances in Methods and Practices in Psychological Science 5 (2): 25152459221080396.\nEntonces el camino es el siguiente: Tomamos las medidas, calculamos el promedio, calculamos el p-valor y si este es menor que \\(\\alpha\\) podemos decir que \\(H_0\\) es falsa. Todo muy lindo, pero siempre tengamos en mente que no sabemos exactamente si para esa realizaci√≥n estamos comentiendo un error de tipo I o no, y ese es uno de las limitaciones de la estad√≠stica frecuentista.\nSimulemos un experimento para \\(n=50\\) en el que nosotros conocemos tanto \\(\\sigma^2\\) como \\(\\mu\\):\n\n\nVer el c√≥digo\nset.seed(123)\nn &lt;- 50\nmu &lt;- .5\nsigma &lt;- 2\n\nX &lt;- rnorm(n, mu, sigma)\n\ncat(paste(\"El promedio muestral es:\", round(mean(X), 3)))\n#&gt; El promedio muestral es: 0.569\ncat(paste(\"El promedio muestral estandarizado es:\", round(mean(X)/sqrt(sigma^2/n), 3)))\n#&gt; El promedio muestral estandarizado es: 2.011\n\n\nAc√° vemos que, efectivamente, \\(H_0\\) es falsa ya que \\(\\mu=0.5\\) (el verdadero par√°metro poblacional). La media observada vale 0.569 y la media estandarizada (\\(z_{\\bar{x}}\\)) vale 2.011. Miremos ccomo queda \\(z_{\\bar{x}}\\) dentro de la distribuci√≥n de los \\(Z_{H_0}\\) (los \\(\\bar{X}\\) bajo \\(H_0\\) estandarizados):\n\n#&gt; Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n#&gt; ‚Ñπ Please use `linewidth` instead.\n\n\n\n\nFunci√≥n de densidad de probabilidad de la variabla aleatoria H (altura de los varones)\n\n\n\n\nLa curva azul es la funci√≥n de densidad de \\(Z_{H_0}\\), las l√≠neas verticales naranjas delimitan los valores de \\(Z\\) cuales la probabilidad de encontrar valores m√°s extremos es mayor a \\(0.05\\), es decir, a la derecha de la l√≠nea naranja positiva y a la izquierda de la negativa estamos en la regi√≥n en la que vamos a considerar a \\(z_{\\bar{x}}\\) como evidencia significativa de que \\(H_0\\) es falsa. La suma de las integrales de la curva azul a la derecha de la l√≠nea naranja posiva y a la izquierda de la negativa da como resultado \\(\\alpha\\).\nEl punto verde (y la l√≠nea punteada que lo acompa√±a) es nuestra observaci√≥n \\(z_{\\bar{x}}\\). O sea, todo parece indicar que controlando nuestro error de tipo I con \\(\\alpha=0.05\\) el valor observado nos permitir√≠a que podemos rechazar \\(H_0\\) o, como se dice habitualmente: ‚ÄúQue \\(\\mu\\) es significativamente diferente de cero‚Äù. Calculemos el p-valor y veamos si esto es efectivamente as√≠.\n\\[\np_{valor} = 2 \\phi(-|z_{\\bar{x}}|) = 2 \\phi(-2.011)\n\\tag{2.24}\\]\nQue en R lo podemos calcular como:\n\n\nVer el c√≥digo\ncat(paste(\"El p-valor es:\", round(2*pnorm(-mean(X)/sqrt(sigma^2/n)),3)))\n#&gt; El p-valor es: 0.044\n\n\nQue como es menor que \\(0.05\\) nos permite rechazar \\(H_0\\).\nPara resolver este ejemplo hicimos dos consideraciones que les pueden hacer ruido: 1. Asumimos que conoc√≠amos la desviaci√≥n est√°ndar de X. 2. Asumimos que X tiene distribuci√≥n normal.\n\n2.10.1 ¬øQu√© pasa si no conozco \\(\\sigma\\)?\nCon respecto a 1, es natural que les haga ruido ya que en la mayor√≠a de los casos no conocemos al \\(\\sigma\\) poblacional sino que lo vamos a estimar. Y ¬øC√≥mo lo vamos a estimar? Echando mano del estimador insesgado de la desviaci√≥n est√°ndar \\(S\\). El mismo se define como:\n\\[\nS^2 = \\frac{\\sum_{i=1}^n(x_i-\\bar{x})^2}{n-1}\n\\tag{2.25}\\]\nPara nuestro ejemplo vale:\n\n\nVer el c√≥digo\ncat(paste(\"la estimaci√≥n de sigma es:\", round(sd(X), 3)))\n#&gt; la estimaci√≥n de sigma es: 1.852\n\n\nBastante cercana al valor poblacional \\(2\\).\nAhora, no es cuesti√≥n de normalizar con este nuevo \\(S^2\\) y seguir como si nada. La cosa cambia y la distribuci√≥n de \\(\\bar(X)\\) estandarizado bajo \\(H_0\\) ya no tiene una distribuci√≥n normal sino una distribuci√≥n t de student con \\(n-1\\) grados de libertad. O sea:\n\\[\n\\frac{\\bar{X} - \\mu}{\\sqrt{S^2/n}} \\sim t_{n-1}\n\\tag{2.26}\\]\nEsto se deduce a partir de que: \\[\n\\frac{\\bar{X} - \\mu}{\\sqrt{\\sigma^2/n}} \\sim \\mathcal{N}(0,1)\n\\] Y:\n\\[\n(n-1)\\frac{S^2}{\\sigma^2} \\sim \\chi^2_{n-1}\n\\tag{2.27}\\]\nY la definici√≥n de \\(t_{n-1}\\) es11:\n11¬†Dentro de la funci√≥n pt ahora se agrega el par√°metro df que representa los grados de libertad.\\[\n\\begin{array}\n_U &\\sim& \\mathcal{N}(0,1) \\\\\nV &\\sim& \\chi^2_{n} \\\\\n\\frac{U}{\\sqrt{V/n}} &\\sim& t_{n}\n\\end{array}\n\\tag{2.28}\\]\nCalculemos el p-valor de nuestro ejemplo, pero ahora como si no conoci√©ramos la \\(\\sigma\\) poblacional12:\n12¬†Dentro de la funci√≥n pt ahora se agrega el par√°metro df que representa los grados de libertad.\n\nVer el c√≥digo\ncat(paste(\"El p-valor es:\", round(2*pt(-mean(X)/sqrt(sd(X)^2/n), df = n-1),4)))\n#&gt; El p-valor es: 0.0347\n\n\nUna buena noticia es que este p valor se puede calcular directamente con la funci√≥n t.test(X) de la siguiente forma:\n\n\nVer el c√≥digo\nt.test(X)\n#&gt; \n#&gt;  One Sample t-test\n#&gt; \n#&gt; data:  X\n#&gt; t = 2.1721, df = 49, p-value = 0.03472\n#&gt; alternative hypothesis: true mean is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  0.04254842 1.09506577\n#&gt; sample estimates:\n#&gt; mean of x \n#&gt; 0.5688071\n\n\nPara cerrar, vale la pena mencionar que los par√°metros \\(\\beta\\) de un modelo lineal tambi√©n tienen distribuci√≥n t (los grados de libertad son m√°s complejos). O sea que todo lo que vimos hasta ac√° de errores tipo I, tipo II, p-valor, etc. vale tambi√©n para ellos.\n\n\n2.10.2 ¬øQu√© pasa si \\(X\\) no se distribuye normalmente?\nAhora que ya vimos que estamos haciendo cuando hacemos inferencia sobre la media, nos damos cuenta que m√°s que interesarnos la distribuci√≥n de los datos \\(X\\) nos interesa la de sus medias \\(\\bar(X)\\) (si estiman alg√∫n par√°metro de inter√©s, claro). Y ac√° viene al rescate el teorema central del l√≠mite:\n\\[\n\\frac{\\bar{X}-\\mu}{\\sqrt{\\sigma^2/n}}  \\xrightarrow{\\mathcal{D}} \\mathcal{N}(0,1)\n\\tag{2.29}\\]\nEl mismo nos dice que distribuci√≥n de la media estandarizada converge endistribuci√≥n a una \\(\\mathcal{N}(0,1)\\) sin importar la distribuci√≥n de \\(X\\). Esto significa que si el \\(n\\) es lo suficientemente grande podemos estar tranquilos de que no es una asunci√≥n tan loca13.\n13¬†Cuando las cosas no se pueden aproximar as√≠ hay soluci√≥n, existen otros tests o simplemente tests que no asumen ninguna distribuci√≥n (no param√©tricos).Supongamos que hay una variable aleatoria \\(V \\sim \\mathcal{E}(\\lambda=1)\\) tal que \\(E(V) = \\lambda\\). Si tomamos una muestra de \\(n=100\\) de \\(V\\), el histograma de la misma se ve algo as√≠:\n\n\n\n\n\nHistograma de una muestra de 100 datos de una exponencial con lambda=1\n\n\n\n\nDonde en azul vemos el histograma y en negro la funci√≥n de densidad para \\(\\mathcal{E}(\\lambda=1)\\). Ahora, qu√© pasa si tomamos \\(1000\\) muestras y hacemos el histograma de sus medias:\n\n\nVer el c√≥digo\nn = 1000\nZs &lt;- c()\nset.seed(123)\nfor (i in 1:10000) {\n  x &lt;- rexp(n, rate = 1)\n  Zs &lt;- c(Zs, (mean(x) - 1)/sqrt(sd(x)^2/n))\n}\n\nZ_means &lt;- tibble(Zs)\nZ_means %&gt;% ggplot() +\n  geom_histogram(aes(x = Zs, y = ..density..), fill = \"steelblue\") +\n  stat_function(fun = dnorm, args = list(mean = 0, sd = 1), \n                color = \"black\", linewidth = 1) +\n  labs(title = paste(\"n = \", n), x = \"Medias de v\", y = \"Densidad\") +\n  scale_x_continuous(limits = c(-4, 4))\n#&gt; Warning: Removed 2 rows containing non-finite outside the scale range\n#&gt; (`stat_bin()`).\n#&gt; Warning: Removed 2 rows containing missing values or values outside the scale range\n#&gt; (`geom_bar()`).\n\n\n\n\n\nHistograma de 1000 medias de muestras de 100 datos de una exponencial con lambda=1\n\n\n\n\nDonde ahora la curva negra es una \\(\\mathcal{N}(0,1)\\). Hagan la prueba con otras distribuciones u otros \\(n\\) y van a ver que r√°pido (o lento para las distribuciones altamente asim√©tricas) que convergen a una \\(\\mathcal{N}(0,1)\\).",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Repaso de probabilidad y estad√≠stica</span>"
    ]
  },
  {
    "objectID": "intro_stat.html#el-p-valor",
    "href": "intro_stat.html#el-p-valor",
    "title": "2¬† Repaso de probabilidad y estad√≠stica",
    "section": "2.11 El p-valor",
    "text": "2.11 El p-valor\nEn construcci√≥n üöß"
  },
  {
    "objectID": "intro_stat.html#potencia-estad√≠stica",
    "href": "intro_stat.html#potencia-estad√≠stica",
    "title": "2¬† Repaso de probabilidad y estad√≠stica",
    "section": "2.11 Potencia estad√≠stica",
    "text": "2.11 Potencia estad√≠stica\nYa hablamos de los errores de tipo I y prometimos hablar de los errores de tipo II. ¬øQu√© ser√≠a eso? Bueno, ser√≠a el caso en el que \\(H_0\\) fuera falsa y nosotros no la rechaz√°ramos. A diferencia del contros de errores de tipo I, la probabilidad de cometer errores de tipo II (llamada muy originalmente \\(\\beta\\)) depende del valor real de mi par√°metro. En el ejemplo anterior, cuando \\(H_0\\) era verdadera \\(\\mu\\) era igual a cero pero, ¬øQu√© pasa cuando es falsa? ¬øQu√© valor de \\(\\mu\\) tenemos que asumir?.\nEmpecemos definiendo a la potencia estad√≠stica, la misma se define como \\(1-\\beta\\), es decir, cuanto m√°s acotado este el error de tipo II m√°s alta ser√° la potencia. Una definici√≥n formal podr√≠a ser:\n\\[\npotencia = P(rechazar \\, H_0 | H_0 \\, falsa)\n\\tag{2.30}\\]\nQue, para el ejemplo anterior la podr√≠amos reescribir como:\n\\[\n\\begin{array}\n_potencia &=& P(rechazar \\, H_0 | H_1) \\\\\n&=& P\\left( \\left| \\frac{\\bar{X}}{\\sqrt{\\sigma^2/n}} \\right| \\geq Z_{1-\\alpha/2}  \\right)\\\\\n&=& 1 - P\\left( Z \\leq Z_{\\alpha/2} + \\frac{\\mu}{\\sqrt{\\sigma^2/n}} \\right) - P\\left( Z \\leq Z_{1-\\alpha/2} + \\frac{\\mu}{\\sqrt{\\sigma^2/n}} \\right) \\\\\n\\end{array}\n\\]\nFijens√© que para calcularla no s√≥lo necesitamos a \\(\\sigma\\) (que podr√≠amos estimar) sino tambi√©n a \\(mu\\), que es nuestro par√°metro de inter√©s. Por ejemplo, podemos ver que la pontencia depende de \\(\\mu\\), siendo m√°s grande para valores de \\(\\mu\\) m√°s alejados del cero. Esto tiene sentido ya que a medida que \\(|\\mu|\\) es mayor, es menor probable cometer errores tipo II.\n\n\nVer el c√≥digo\npotencia &lt;- function(sigma, mu, n, alpha) {\n  pnorm(qnorm(alpha/2)-mu/(sqrt(sigma^2/n))) + 1 -\n    pnorm(qnorm(1-alpha/2)-mu/(sqrt(sigma^2/n)))\n}\n\npot &lt;- potencia(3,seq(-3,3,.1),20,0.05)\npot_tbl &lt;- tibble(mu = seq(-3,3,.1), potencia = pot)\npot_tbl %&gt;% ggplot(aes(x = mu,\n           y = potencia)) +\n  geom_line(linewidth = 1) +\n  theme_bw()\n\n\n\n\n\nPotencia estad√≠stica en funci√≥n de mu.\n\n\n\n\nComo es de esperarse, la potencia tambi√©n depende del \\(\\alpha\\):\n\n\nVer el c√≥digo\npot &lt;- potencia(3,1,20,seq(0, 0.05, 0.001))\npot_tbl &lt;- tibble(alpha = seq(0, 0.05, 0.001), potencia = pot)\npot_tbl %&gt;% ggplot(aes(x = alpha,\n                       y = potencia)) +\n  geom_line(linewidth = 1) +\n  labs(title = \"Potencia en funci√≥n de alfa\") +\n  theme_bw()\n\n\n\n\n\nPotencia estad√≠stica en funci√≥n de alfa.\n\n\n\n\nCon valores de potencia mayores para valores m√°s garndes de \\(\\alpha\\). Nuevamente esto tiene sentido ya que ser m√°s restictivo con el rechazo de \\(H_0\\) (o sea, que tenga que observar un valor m√°s extremo) lleva a una disminuci√≥n de \\(\\alpha\\), a un aumento de los errores tipo II y con ello a una disminuci√≥n de la potencia.\nFinalmente, la potencia tambi√©n depende del \\(n\\):\n\n\nVer el c√≥digo\npot &lt;- potencia(3,1,seq(5, 200),0.05)\npot_tbl &lt;- tibble(n = seq(5, 200), potencia = pot)\npot_tbl %&gt;% ggplot(aes(x = n,\n                       y = potencia)) +\n  geom_line(linewidth = 1) +\n  labs(title = \"Potencia en funci√≥n de n\") +\n  theme_bw()\n\n\n\n\n\nPotencia estad√≠stica en funci√≥n de n.\n\n\n\n\nCon valores de potencia m√°s altos para \\(n\\) m√°s grande. Es decir, si tengo una muestra m√°s grande voy a cometer menos errores14. Esta √∫ltima dependencia es muy importante.\n14¬†Las distribuciones de \\(H_0\\) y \\(H_1\\) se hacen m√°s finas y hay menos solapamiento, recuerden que en ambas la varianza disminuye con \\(1/n\\).Hay una interpretaci√≥n que me gusta que es la siguiente, la potencia estad√≠stica es la lupa con la que miramos el problema. Es decir, si tenemos una potencia alta vamos a poder detectar cambios peque√±os sin cometer demasiados errores. Supongamos que queremos dise√±ar un experimento con una dada potencia. El \\(\\alpha\\) lo decidimos cuando acotamos el error de tipo I, a \\(\\mu\\) no lo conocemos (algo vamos a hacer), entonces, lo que m√°s a mano nos queda para tener un experimento m√°s potente es aumentar el \\(n\\).\nEl uso que se le da normalmente a esta herramienta es para determinar el m√≠nimo tama√±o de muestra necesario para un experimento. El procedimiento es el siguiente:\n\nEstimamos la variabilidad de nuestro experimento de alguna forma. Lo m√°s usual es hacer un piloto pero tambi√©n puede ser un dato que salga de la bibliograf√≠a, o de experimentos anteriores que hayamos realizado.\nDeterminamos el m√≠nimo tama√±o de efecto de inter√©s (SESOI15). Esta no es una determinaci√≥n estad√≠stica sino que de dominio, tenemos que conocer el problema y pensar en cu√°l ser√≠a el m√≠nimo tama√±o de efecto que considerar√≠a relevante (relevante, no significativo). Esto a veces puede ser un poco confuso pero tambi√©n nos obliga a pensar qu√© consideramos relevante en nuestro experimento.\nUna vez que tenemos estas dos magnitudes calculamos el tama√±o de muestra para una potencia dada (por ejemplo \\(0.9\\)) y un \\(\\alpha\\) dado (por ejemplo \\(0.05\\)).\n\n15¬†Del ingl√©s smallest effect size of interest.No siempre resulta tan directo como en nuestro ejemplo, en el que podemos despejar expl√≠citamente \\(n\\), pero la forma de pensar el problema es siempre similar.\nPara m√°s detalles sobre los procedimientos para justificar el tema√±o de muestra ver (Lakens 2022).\n\n\n\nLakens, Daniel. 2022. ¬´Sample size justification¬ª. Collabra: psychology 8 (1): 33267.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Repaso de probabilidad y estad√≠stica</span>"
    ]
  },
  {
    "objectID": "potential_outcomes.html#potential-outcomes",
    "href": "potential_outcomes.html#potential-outcomes",
    "title": "3¬† Potential outcomes",
    "section": "3.2 Potential outcomes",
    "text": "3.2 Potential outcomes\nLo que nos proponen los potential outcomes es la definici√≥n del efecto causal como la comparaci√≥n de dos estados en el mundo. En una versi√≥n del mundo, la ‚Äúactual‚Äù, me tomo una aspirina y a las dos horas registro la severidad de mi dolor de cabeza mientras que en la otra versi√≥n del mundo, la ‚Äúcontrafactual‚Äù, no me la tomo y las dos horas registro la severidad del dolor. A partir de esto, la tradici√≥n de los potential outcomes define al efecto causal de tomar una aspirina en el dolor de cabeza como la diferencia entre esas dos mediciones.\nTodo muy lindo, pero como ya estar√°n sospechando es imposible calcular un efecto que est√° expresado en funci√≥n de un contrafactual, ya que este contrafactual no lo podemos observar. Pero no se preocupen que le vamos a encontrar la vuelta.\nEmpecemos con un poco de notaci√≥n que nos va a ayudar a acomodar las ideas. Por simplicidad vamos a asumir una variable binaria para la asignaci√≥n del grupo (por ejemplo, tratamiento y control). Esta variable vale \\(1\\) si la unidad i recibe el tratamiento y \\(0\\) si no. Cada unidad \\(i\\) va a tener dos potential outcomes: \\(Y_i^1\\) si la unidad recibi√≥ el tratamiento y \\(Y_i^0\\) si no. Esto significa que una unidad experimental en el mismo momento del tiempo va a recibir y no recibir el tratamiento, o sea, alguno de estos va a ser contrafactual1.\n1¬†De ah√≠ el nombre de potential, porque se trata de posibles estados del mundo. Un estado en el que la unidad \\(i\\) recibe el tratamiento y uno en el que no.Los outcomes observables difieren de los potenciales. Mientras que los potenciales son variables aleatorias hipot√©ticas, los observables son variables aleatorias factuales y medibles. Hay una ecuaci√≥n que nos permite definir el outcome observable (\\(Y^i\\)) en funci√≥n de los potenciales, se llama la switching equation:\n\\[\nY_i = D_i Y_i^1 + (1-D_i) Y_i^0\n\\tag{3.1}\\]\nDonde \\(D_i\\) vale \\(1\\) si la unidad i recibi√≥ el tratamiento (entonces \\(Y_i=Y_i^1\\)) y \\(0\\) si no (entonces \\(Y_i=Y_i^0\\)). Vale la pena notar que \\(Y_i\\), el outcome observable, no tiene ning√∫n supra√≠ndice ya que no es m√°s potencial.\nUsando esta notaci√≥n definimos el efecto causal del tratamiento para una unidad \\(i\\) como: \\[\n\\delta_i = Y_i^1 - Y_i^0\n\\tag{3.2}\\]\nDonde queda claro que para estimar el efecto causal de acuerdo a la tradici√≥n de los potential outcomes debemos conocer dos estados del mundo a los que es imposible acceder simult√°neamente. Y aqui yace el problema funcamental de la inferencia causal: Para calcular el efecto causal se requiere acceso a datos que siempre nos van a faltar (los contraf√°cticos)(Rubin 1974).\n\nRubin, Donald B. 1974. ¬´Estimating causal effects of treatments in randomized and nonrandomized studies.¬ª Journal of educational Psychology 66 (5): 688.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>*Potential outcomes*</span>"
    ]
  },
  {
    "objectID": "potential_outcomes.html#efecto-promedio-del-tratamiento",
    "href": "potential_outcomes.html#efecto-promedio-del-tratamiento",
    "title": "3¬† Potential outcomes",
    "section": "3.3 Efecto promedio del tratamiento",
    "text": "3.3 Efecto promedio del tratamiento\nAl igual que los potential outcomes, el efecto para la unidad \\(i\\) (\\(\\delta_i\\)) tambi√©n es una variable aleatoria, y su esperanza es lo que vamos a llamar el efecto promedio del tratamiento (ATE2). El ATE va a ser la magnitud de inter√©s en nuestros experimentos, el efecto promedio de mi tratamiento. El mismo se define de la siguiente forma:\n2¬†Del ingl√©s Average treatment effect.\\[\n\\begin{array}\n_ATE &=& E[\\delta_i] \\\\\n&=& E[Y_i^1 - Y_i^0] \\\\\n&=& E[Y_i^1] - E[Y_i^0]\n\\end{array}\n\\tag{3.3}\\]\nAhora vamos a definir el efecto promedio, pero para el grupo tratado (es decir, los participantes asignados al grupo tratamiento, con \\(D_i=1\\)):\n\\[\n\\begin{array}\n_ATT &=& E[\\delta_i|D_i=1] \\\\\n&=& E[Y_i^1 - Y_i^0|D_i=1] \\\\\n&=& E[Y_i^1|D_i=1] - E[Y_i^0|D_i=1]\n\\end{array}\n\\tag{3.4}\\]\nEsta magnitud se llama ATT3 y se calcula de la misma forma que el ATE pero condicionando los \\(\\delta_i\\) al valor de \\(D_i\\) igual a 1. De manera an√°loga definimos el efecto promedio pero para el grupo no tratado4(\\(D_i=0\\))\n3¬†Del ingl√©s Average treatment effect for the treated.4¬†Del ingl√©s Average treatment effect for the untreated.\\[\n\\begin{array}\n_ATU &=& E[\\delta_i|D_i=0] \\\\\n&=& E[Y_i^1 - Y_i^0|D_i=0] \\\\\n&=& E[Y_i^1|D_i=0] - E[Y_i^0|D_i=0]\n\\end{array}\n\\tag{3.5}\\]\nOjo con confundir estos tres conceptos. Creo que el ATE es autoexplicativo, pero se suele confundir ATT y ATU. En el primer caso, estamos calculando la esperanza de los \\(\\delta_i\\) para los individuos pertenecientes al grupo tratamiento. Esto involucra tanto sus \\(Y^1_i\\) como sus \\(Y^0_i\\). Es una confusi√≥n com√∫n confundir estos efectos promedios con magnitudes no potenciales pero, como se observa de sus f√≥rmulas, tanto estos √∫ltimos dos como el ATE no se pueden calcular en la pr√°ctica. En las secciones siguientes vamos a ver como, cumpliendo ciertas condiciones5, podemos estimar el ATE a partir de los outcomes observables.\n5¬†Spoiler: Asignaci√≥n aleatoria de las unidades experimentales a los grupos.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>*Potential outcomes*</span>"
    ]
  },
  {
    "objectID": "potential_outcomes.html#diferencia-de-medias-simple",
    "href": "potential_outcomes.html#diferencia-de-medias-simple",
    "title": "3¬† Potential outcomes",
    "section": "3.4 Diferencia de medias simple",
    "text": "3.4 Diferencia de medias simple\n¬øQu√© es lo que s√≠ podemos observar? Una magnitud que a priori podr√≠amos creer que va aestar relacionada con el ATE y que podemos observar es la diferencia de medias entre los outcomes observados del grupo tratamiento y el grupo control. La vamos a llamar SDO6 y se calcula de la siguiente forma:\n6¬†Del ingl√©s simple difference in outcomes.\\[\n\\begin{array}\n_SDO &=& E[Y_i^1|D_i=1] - E[Y_i^0|D_i=0] \\\\\n&=& \\frac{1}{N_T} \\sum_{i=1}^{N_T} (y_i|d_i=1) - \\frac{1}{N_C} \\sum_{i=1}^{N_C} (y_i|d_i=0)\n\\end{array}\n\\tag{3.6}\\]\nDonde \\(N_T\\) y \\(N_C\\) son la cantidad de individuos en el grupo tratamiento y control respectivamente (y \\(N_T + N_C = n\\)). Todo muy lindo, pero operemos un poquito para ver hasta que punto el SDO es un estimador insesgado del ATE. Empecemos escribiendo el ATE como una suma pesada del ATT y el ATU:\n\\[\n\\begin{array}\n_ATE &=& \\pi ATT + (1-\\pi) ATU \\\\\n&=& \\pi E[Y_i^1|D_i=1] - \\pi E[Y_i^0|D_i=1] + \\\\\n& & (1-\\pi) E[Y_i^1|D_i=0] - (1-\\pi) E[Y_i^0|D_i=0] \\\\\n&=& \\bigl\\{ \\pi E[Y_i^1|D_i=1] + (1-\\pi) E[Y_i^1|D_i=0] \\bigl\\} - \\\\\n& & \\bigl\\{ \\pi E[Y_i^0|D_i=1] + (1-\\pi) E[Y_i^0|D_i=0] \\bigl\\}\n\\end{array}\n\\tag{3.7}\\]\nCon \\(\\pi = N_T/n\\) y \\(1 - \\pi = N_C/n\\).\nOperando con la Ecuaci√≥n¬†3.8 podemos despejar la diferencia entre los outcomes observables (SDO) y ver c√≥mo esta se realciona con el resto de las magnitudes definidas7.\n7¬†Pueden ver el despeje num√©rico en detalle en el cap√≠tulo 4 de (Cunningham 2021).\nCunningham, Scott. 2021. Causal inference: The mixtape. Yale university press.\n\\[\n\\begin{array}\n_E[Y_i^1|D_i=1] - E[Y_i^0|D_i=0] &=& ATE \\\\\n&+& ( E[Y_i^0|D_i=1] - E[Y_i^0|D_i=0] ) \\\\\n&+& (1-\\pi) (ATT - ATU)\n\\end{array}\n\\tag{3.8}\\]\nQue podemos reescribir como:\n\\[\n\\begin{array}\n_\\underbrace{\\frac{1}{N_T} \\sum_{i=1}^{N_T} (y_i|d_i=1) - \\frac{1}{N_C} \\sum_{i=1}^{N_C} (y_i|d_i=0)}_\\text{Diferencia de los outcomes} &=& \\underbrace{ATE}_\\text{Efecto promedio del tratamiento} \\\\\n&+& \\underbrace{( E[Y_i^0|D_i=1] - E[Y_i^0|D_i=0] )}_\\text{Sesgo de selecci√≥n} \\\\\n&+& \\underbrace{(1-\\pi) (ATT - ATU)}_\\text{Sesgo de efecto heterog√©neo}\n\\end{array}\n\\tag{3.9}\\]\nLo que puede verse en Ecuaci√≥n¬†3.9 es que si pudi√©ramos asegurar de alguna forma que los sesgos de selecci√≥n y de efecto heterog√©neo fueran cero, el SDO ser√≠a un buen estimador del ATE que es, al fin y al cabo, el efecto causal promedio que nos interesa en nuestro experimento.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>*Potential outcomes*</span>"
    ]
  },
  {
    "objectID": "potential_outcomes.html#independencia",
    "href": "potential_outcomes.html#independencia",
    "title": "3¬† Potential outcomes",
    "section": "3.5 Independencia",
    "text": "3.5 Independencia\nLa definici√≥n de independencia en el contexto de los potential outcomes es la siguiente:\n\\[\n(Y^0, Y^1) \\perp D\n\\] Momento cerebrito, pensemos una poco qu√© quiere decir. Esto significa que la asignaci√≥n de los participantes al grupo control o tratamiento (\\(D\\)) no depende de los outcomes potenciales de ese individuo.\nVamos a pensarlo con un ejemplo concreto. Imaginen que tenemos una grupo de participantes para poner a prueba una cirug√≠a experimental como altenativa a un tratamiento m√©dico establecido no quir√∫rgico. Si la asingaci√≥n de individuos al grupo tratamiento la hace un m√©dico en base a lo que cree que va a ser conveniente para √©l, por ejemplo, no asignando a pacientes de edad avanzada al grupo tratamiento por el riesgo asociado a una cirug√≠a, o asignando a pacientes cuyo pron√≥stico con el m√©todo tradicional vea poco favorable al grupo control. En este caso, la asignaci√≥n a un grupo s√≠ depende de los posibles resultados, por lo tanto, no hay independencia. Si en lugar de eso tir√°ramos una moneda antes de recibir a cada paciente, podr√≠amos de esa forma asegurar la independencia.\nLa independencia implica que se cumpla:\n\\[\n\\begin{array}\n_E[Y^1|D=1] - E[Y^1|D=0] &=& 0 \\\\\nE[Y^0|D=1] - E[Y^0|D=0] &=& 0\n\\end{array}\n\\tag{3.10}\\]\nEs decir, que la esperanza de los outcomes para los participantes que fueron asignados al grupo tratamiento como al grupo control ser√≠an iguales si pudieramos medirlos a ambos en ‚Äúmundo tratamiento‚Äù8. Y lo mismo pasar√≠a si pudi√©ramos medirlos a ambos grupos en el ‚Äúmundo control‚Äù[^indep]. Ojo que esto no implica que la esperanza del outcome para tratamiento en los tratados sea igual a la esperanza para no tratamiento en los controles (\\(E[Y^1|D=1] - E[Y^0|D=0] = 0\\)) ni igual a la esperanza no tratamiento de los tratados (\\(E[Y^1|D=1] - E[Y^0|D=1] = 0\\)).\n8¬†Tengamos en cuenta que \\(E[Y^1|D=0]\\) es un contraf√°ctico, ya que es el outcome habiendo sido expuesto al tratamiento pero de los individuos en el grupo control (de ah√≠ la condicionalidad con \\(D=0\\))¬øQu√© implicancias tiene las igualdades presentadas en Ecuaci√≥n¬†3.10 en los sesgos que vimos en la ecuaci√≥n Ecuaci√≥n¬†3.8? Empecemos por el sesgo de selecci√≥n (\\(E[Y^0|D=1] + E[Y^0|D=0]\\)). Vemos que, deacuerdo a la primera l√≠nea de Ecuaci√≥n¬†3.10 ya nos dice que, de ser independiente la asignaci√≥n del grupo experimental, este sesgo ser√≠a cero. Pensemos un poco. Lo que nos est√° diciendo la condici√≥n de independencia es que si ambos grupos fueran no tratados, ambos tendr√≠an el mismo outcome lo que pareciera indicarnos que es razonable considerar nulo al sesgo de selecci√≥n.\nLa relaci√≥n del sesgo de efecto heterog√©neo (\\((1-\\pi) (ATT - ATU)\\)) con la independencia es un poquito m√°s dif√≠cil de demostrar. Olvid√©monos del \\((1-\\pi)\\) de momento. Reescribamos los efectos ATT y ATU:\n\\[\n\\begin{array}\n_ATT &=& E[Y^1|D=1] - E[Y^0|D=1] \\\\\nATU &=& E[Y^1|D=0] - E[Y^0|D=0]\n\\end{array}\n\\]\nY ahora restemos ambos t√©rminos:\n\\[\n\\begin{array}\n_ATT - ATU &=& E[Y^1|D=1] - E[Y^0|D=1] - ( E[Y^1|D=0] - E[Y^0|D=0] )\\\\\n&=& \\bigl\\{ E[Y^1|D=1] - E[Y^1|D=0] \\bigl\\} + \\bigl\\{ E[Y^0|D=0] - E[Y^0|D=1] \\bigl\\}\n\\end{array}\n\\tag{3.11}\\]\nReescrito de esta forma podemos ver los dos primero t√©rminos de Ecuaci√≥n¬†3.11 se hacen cero por la rpimero l√≠nea de Ecuaci√≥n¬†3.10, y los √∫ltimos dos se hacen cero por la segunda.\nFinalmente, demostramos que si hay independencia en la asignaci√≥n de los grupos, la diferencia de las medias entre el grupo tratado y el control es un buen estimador del ATE.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>*Potential outcomes*</span>"
    ]
  },
  {
    "objectID": "intro_stat.html#probabilidad-condicional",
    "href": "intro_stat.html#probabilidad-condicional",
    "title": "2¬† Repaso de probabilidad y estad√≠stica",
    "section": "2.3 Probabilidad condicional",
    "text": "2.3 Probabilidad condicional\nLa probabilidad condicional es la probabilidad de que ocurra un evento A dado que ocurri√≥ un evento B y se escribe como \\(P(A|B)\\). Por ahora qued√©monos con esta definici√≥n simple que ser√° de vital importancia para lo que sigue.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Repaso de probabilidad y estad√≠stica</span>"
    ]
  },
  {
    "objectID": "potential_outcomes.html#guerra-fr√≠a-manos-y-contraf√°cticos.",
    "href": "potential_outcomes.html#guerra-fr√≠a-manos-y-contraf√°cticos.",
    "title": "3¬† Potential outcomes",
    "section": "",
    "text": "De qu√© hablamos cuando hablamos de contrafactuales\n\n\n\nEn el marco de los potential outcomes de Rubin(Rubin 1974), un contrafactual es el resultado que habr√≠a ocurrido para una unidad (por ejemplo, una persona, un paciente, un sujeto experimental) si hubiera recibido un tratamiento diferente del que realmente recibi√≥. Este concepto es fundamental para entender los efectos causales. Nos permite definir lo que entendemos por causa: la diferencia entre lo que realmente sucedi√≥ y lo que habr√≠a sucedido en un escenario alternativo.\nEn pocas palabras:\n\nPara alguien que recibi√≥ el tratamiento, el contrafactual es lo que habr√≠a sucedido si no hubiera recibido el tratamiento. Por ejemplo, si un paciente recibi√≥ un nuevo medicamento y se recuper√≥, el resultado contrafactual es su estado de salud si no hubiera recibido el medicamento. Esto nos ayuda a aislar el efecto del medicamento.\nPara alguien que no recibi√≥ el tratamiento, el contrafactual es lo que habr√≠a sucedido si hubiera recibido el tratamiento. Por ejemplo, si un estudiante no asisti√≥ a un programa de tutor√≠a y reprob√≥ un examen, el contrafactual es su calificaci√≥n hipot√©tica si hubiera asistido al programa.\n\nDado que cada unidad recibe solo un tratamiento, solo podemos observar un resultado (el resultado real). El resultado contrafactual es, por definici√≥n, inobservable. Esto se conoce a menudo como el problema fundamental de la inferencia causal. Debido a que no podemos observar simult√°neamente ambos resultados potenciales para el mismo individuo, vamos a usar m√©todos y suposiciones estad√≠sticas para estimar los efectos promedio del tratamiento en grupos de individuos. M√°s de esto en los pr√≥ximos cap√≠tulos.\n\n\n\n\n\n\n\nPraying Hands de Albrecht Durero.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>*Potential outcomes*</span>"
    ]
  },
  {
    "objectID": "exp_aleatorios.html#guerra-fr√≠a-manos-y-contraf√°cticos.",
    "href": "exp_aleatorios.html#guerra-fr√≠a-manos-y-contraf√°cticos.",
    "title": "5¬† Experimentos aleatorios",
    "section": "5.1 Guerra fr√≠a, manos y contraf√°cticos.",
    "text": "5.1 Guerra fr√≠a, manos y contraf√°cticos.\nSon las 3 de la ma√±ana del 26 de septiembre de 1983. Con una taza de caf√© en mano, Stanislav Petrov vigila las alarmas de una estaci√≥n de monitoreo de ataques nucleares a las afueras de Mosc√∫. De pronto, los paneles se iluminan con un rojo furioso: tres misiles intercontinentales est√°n en camino a la c√∫pula del Kremlin‚Ä¶ o, quiz√°s, el sistema tiene un error y se trata de una falsa alarma.\nClaro, aqu√≠ tienes un resumen detallado con subt√≠tulos para cada tema presentado en la presentaci√≥n ‚ÄúCC400-2025-Semana4‚Äù:Resumen de la Presentaci√≥n ‚ÄúCC400-2025-Semana4‚ÄùIntroducci√≥n a Dise√±os Experimentales y Aleatorizados La presentaci√≥n introduce los dise√±os experimentales y cuasi-experimentales, enfoc√°ndose en los dise√±os aleatorizados. Se presenta a Ignacio Spiousas como el presentador para el Oto√±o 2025. Potencial Outcomes y el SDO (Sample Difference of Outcomes) Se discute c√≥mo el SDO contiene al ATE (Average Treatment Effect), pero en la pr√°ctica no conocemos otros t√©rminos. Se introduce el concepto de ‚Äúpotential outcomes‚Äù y la descomposici√≥n del SDO. Independencia en Potencial Outcomes Se enfatiza la importancia de la independencia en los ‚Äúpotential outcomes‚Äù. Esto implica que la asignaci√≥n al tratamiento no debe depender de los resultados potenciales. Se advierte sobre el sesgo si los participantes son elegidos para tratamientos basados en expectativas de resultados. Experimentos Aleatorios Se explica que en los experimentos aleatorios, los sujetos son asignados a grupos (tratamiento y control) de manera aleatoria. Los experimentos aleatorios son el ‚Äúgold-standard‚Äù para estimar efectos y la base para estudiar cuasi-experimentos. Dise√±os Between-Groups Aleatorios Se describen los dise√±os between-groups aleatorios, donde los participantes son asignados a un grupo de tratamiento o control. Se aclara la diferencia entre muestra aleatoria y asignaci√≥n aleatoria. Xs y Os en Experimentos Aleatorios Se introduce la notaci√≥n de ‚ÄúX‚Äù para la administraci√≥n de un tratamiento y ‚ÄúO‚Äù para una observaci√≥n. Se presentan ejemplos de dise√±os simples between-groups, como el dise√±o posttest-only y pretest-posttest. Ejemplos de Experimentos Aleatorios en el Campo Se mencionan ejemplos de estudios RCT (Randomized Controlled Trials) en econom√≠a del desarrollo y pol√≠ticas p√∫blicas en pa√≠ses en desarrollo, citando a Duflo y el Banco Mundial. Tambi√©n se menciona un ejemplo de asignaci√≥n aleatoria de polic√≠as extra a ciertas partes de la ciudad. El Problema de la Selecci√≥n Se discute el problema de la selecci√≥n y c√≥mo los participantes pueden ser confusores de los tratamientos en dise√±os between-groups. Se destaca que la asignaci√≥n aleatoria ayuda a evitar el sesgo. Experimentos Aleatorios Posttest-Only Se presenta el modelo de regresi√≥n para experimentos posttest-only y se explica c√≥mo estimar el efecto del tratamiento. Se utiliza un ejemplo de A/B testing para ilustrar el an√°lisis. A/B Testing Se detalla un ejemplo de A/B testing, donde se comparan dos versiones de un sitio web midiendo el tiempo de permanencia. Se muestra c√≥mo simular datos, realizar an√°lisis de regresi√≥n y pruebas t para comparar los grupos. Experimentos Aleatorios Pretest-Posttest Se describe el dise√±o pretest-posttest between-group randomized experiment. Se explica c√≥mo las medidas pretest pueden aumentar la precisi√≥n y potencia del estudio. Blocking o Matching en Dise√±os Pretest-Posttest Se introduce la t√©cnica de blocking o matching, donde los sujetos son separados en grupos basados en medidas pretest. Se muestra c√≥mo esto puede mejorar el an√°lisis. Covariables en Dise√±os Pretest-Posttest Se explica c√≥mo agregar medidas pretest como covariables en el an√°lisis de regresi√≥n. Se discute c√≥mo esto puede reducir la varianza no explicada y aumentar la potencia estad√≠stica. Interacciones en Dise√±os Pretest-Posttest Se aborda el tema de las interacciones entre el tratamiento y las medidas pretest. Se muestra c√≥mo modelar y interpretar estas interacciones en el an√°lisis de regresi√≥n. Precisi√≥n y Potencia Se discute c√≥mo la relaci√≥n entre las variables pretest y posttest afecta la potencia estad√≠stica y precisi√≥n del estudio. Se menciona que cuanto m√°s relacionadas est√©n las variables, mejor ser√° la potencia. Bibliograf√≠a Se cita a Reichardt, C. S. (2019) como referencia bibliogr√°fica para el tema de cuasi-experimentaci√≥n."
  },
  {
    "objectID": "exp_aleatorios.html#por-qu√©-son-importantes-los-experimentos-aleatorios",
    "href": "exp_aleatorios.html#por-qu√©-son-importantes-los-experimentos-aleatorios",
    "title": "5¬† Experimentos aleatorios",
    "section": "",
    "text": "1¬†A lo largo del cap√≠tulo vamos a usar de forma intercambiable las expresiones experimentos aleatorios y experimentos aleatorizados. Tambi√©n vamos a usar la sigla RCT del ingl√©s randomized controlled trials.\n\n\n\n\n\nSobre la aleatoridad de las computadoras\n\n\n\nCuando hablamos de un evento aleatorio, hablamos de una entidad abstracta cuyo resultado no se puede predecir exactamente. Para poner este tipo de eventos en el mundo real solemos echar mano de ejemplos cl√°sicos que involucran una complejidad f√≠sica tal que resulta imposible predecirlos exactamente, como arrojar un dado o una moneda. El ejemplo de la moneda es la forma m√°s usual de hablar de una variable aleatoria con dos posibles valores equiprobables (aunque parezca que no tanto (Barto≈° et¬†al. 2023)). Sin embargo, esta aleatoriedad es muy costosa de reproducir. Es por eso que las computadores utilizan lo que se llama generadores de n√∫meros pseudo aleatorios2. Estos generadores utilizan series de n√∫meros generados de forma pseudo aleatoria pero que puede ser recuperada determin√≠sticamente a partir de una ‚Äúsemilla‚Äù. Es por eso que cuando simulamos datos en este libro lo primero que hacemos es ejecutar set.seed(42) (42 o el n√∫mero que sea), para de esa forma poder obtener el mismo resultado cada vez que replicamos, o el lector quiere replicar, las simulaciones.\nDicho esto. A fines pr√°cticos, es totalmente razonable utilizar un generador de n√∫meros pseudo aleatorios para la asignaci√≥n a grupos experimentales en los experimentos aleatorios.\n\n\n2¬†Para m√°s informaci√≥n pueden ir a leer esto.\nBarto≈°, Franti≈°ek, Alexandra Sarafoglou, Henrik R Godmann, Amir Sahrani, David Klein Leunk, Pierre Y Gui, David Voss, et¬†al. 2023. ¬´Fair coins tend to land on the same side they started: Evidence from 350,757 flips¬ª. arXiv preprint arXiv:2310.04153.",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Experimentos aleatorios</span>"
    ]
  },
  {
    "objectID": "exp_aleatorios.html#experimentos-bewtween-groups",
    "href": "exp_aleatorios.html#experimentos-bewtween-groups",
    "title": "5¬† Experimentos aleatorios",
    "section": "5.4 Experimentos bewtween groups",
    "text": "5.4 Experimentos bewtween groups\n\n\n\n\n\n\nHablemos un poco de la nomenclatura\n\n\n\n\n\n\n\n5.4.1 S√≥lo posttest\n\\[\n\\begin{array}\n_Y_{i} &=& \\beta_0 + \\beta_T T_i + \\epsilon_{i}\n\\end{array}\n\\tag{5.1}\\]\nDonde \\(T_i\\) es una variable indicadora que toma el valor \\(1\\) si el participante pertenece al grupo tratamiento y el valor \\(0\\) si no.\n\n\n5.4.2 Pretest-posttest",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Experimentos aleatorios</span>"
    ]
  },
  {
    "objectID": "exp_aleatorios.html#dise√±os-cl√∫ster",
    "href": "exp_aleatorios.html#dise√±os-cl√∫ster",
    "title": "5¬† Experimentos aleatorios",
    "section": "5.5 Dise√±os cl√∫ster",
    "text": "5.5 Dise√±os cl√∫ster\nLos dise√±os cl√∫ster son una forma de dise√±o experimental donde los sujetos son asignados a grupos (cl√∫steres) y luego se asignan tratamientos a esos grupos. Este enfoque es √∫til cuando no es pr√°ctico o posible asignar tratamientos a individuos de manera independiente.\nLas ventajas de los dise√±os cluster son varias:\n\nA veces puede resultar m√°s pr√°ctico o conveniente asignar aleatoriamente a grupos que a individuos. Por ejemplo, en el sistema escolar nos pueden permitir asignar cursos o escuelas a distintos tratamientos pero no a estudiantes\nLa aleatorizaci√≥n a nivel cl√∫ster puede ser √∫tiles para minimizar los efectos de difusi√≥n, imitaci√≥n de tratamientos u otros problemas de adherencia. Por ejemplo, para un estudiante es m√°s dif√≠cil ser crossover si el tratamiento diferente lo tienen en otro aula o escuela en lugar de su compa√±ero de banco.\nPueden ser necesarios para evitar los spillovers. En el estudio de la campa√±a de SMSs para mejorar la tasa de vacunaci√≥n contra el HPV hubieran hecho la aleatorizaci√≥n a nivel barrio o cioudad, no hubieran tenido el spillover debido a que un vecino te comenta del SMS que recibi√≥.\nPueden ser necesarios para evitar las externalidades. Por ejemplo, si se est√° haciendo un experimento para evaluar el efecto de un tratamiento dentro de un determinado grupo cerrado (una ciudad), el aumento de empleabilidad para el grupo tratamiento puede generar que haya menos empleos disponibles para el grupo control y que baje su tasa de empleo, no como consecuencia de ser menos ‚Äúempleables‚Äù. Aleatorizando por ciudad se puede reducir este efecto.\nAlgunos programas se aplican s√≠ o s√≠ a grupos. Por ejemplo, una campa√±a medi√°tica, una terapia de grupo o un cambio de pol√≠tica a nivel escuela.\nLos efectos pueden ser mayores cuando se aplican a todo un grupo. Esto tiene que ver con que debemos tener en cuenta que, si lo que queremos evaluar es una intervenci√≥n que se va a aplicar a nivel grupo, si lo hacemos aleatorizando a nivel individual podemos estar subestimando su efecto. Por ejemplo, una intervenci√≥n que mejore las habilidades de lectura de todo un curso puede tener un efecto sinerg√©tico que no estar√≠a presente si s√≥lo la mitad del curso est√° expuesto al tratamiento y la maestra debe alternar entre un subgrupo y el otro.\n\nAlgo muy importante es que la aleatorizaci√≥n a nivel cl√∫ster no significa que vamos a dejar de prestar atenci√≥n a los individuos y utilizar medidas a nivel cl√∫ster. De hecho todo lo contrario, si bien vamos a aleatorizar a nivel grupo, vamos a medir el outcome para cada individuo y la relaci√≥n entre la variabilidad entre e intra grupos va a jugar un papel importante (m√°s de esto en las siguientes secciones). En caso de que aleatoricemos a nivel grupo y despu√©s tomemos simplemente un outcome por grupo no estamos ante un dise√±o cl√∫ster sino que simplemente cambiamos la unidad experimental del individuo al grupo.\nTodo parece ideal, ¬øNo? Pero nada de esto viene sin un costo. En general el costo es la potencia estad√≠stica. Es decir, para tener la misma potencia estad√≠stica que aleatorizando a nivel de individuo, vamos a necesitar m√°s (y a veces muchos m√°s) sujetos experimentales divididos en grupos. M√°s de eso en la secci√≥n que sigue.\n\n5.5.1 An√°lisis de datos jer√°rquicos\nPara analizar este tipo de datos utilizamos modelos estad√≠sticos que tienen en cuenta la estructura jer√°rquica de los datos. En este libro los vamos a llamar de forma general modelos jer√°rquicos9. A continuaci√≥n tenemos la estructura de un modelo lineal jer√°rquico con un s√≥lo nivel de agrupamiento10.\n9¬†Tambi√©n se pueden llamar hierarchical linear models, linear mixed-effect model , mixed models, nested data models, random coefficient, random-effects models, random parameter models o split-plot designs. Pero siempre estamos hablando de los mismo.10¬†Por ejemplo, sirve para modelar los estudiantes de una escuela, pero tambi√©n podr√≠amos tener modelos que nos permitan modelar los estudiantes de una escuela, que a su vez pertenece a un distrito escolar, a una provincia, etc. Teniendo m√°s niveles de agrupamiento, pero eso queda afuera del alcance de este libro.\\[\n\\begin{array}\n_Y_{ij} &=& \\mu_j + \\epsilon_{ij} \\\\\n\\mu_j &=& \\beta_0 + \\beta_T T_j + r_j\n\\end{array}\n\\]\nDonde tanto \\(r_j\\) como \\(\\epsilon_{ij}\\) tiene esperanza cero y varianza \\(\\sigma^2_{inter-cl√∫ster}\\) y \\(\\sigma^2_{intra-cl√∫ster}\\) respectivamente. En la ecuaci√≥n anterior \\(T_j\\) es una variable indicadora que toma el valor \\(1\\) si la escuela, y no el participante como antes, pertenece al grupo tratamiento y el valor \\(0\\) si no. De esta forma, si la escuela pertenece al grupo tratamineto su media ser√° \\(\\mu_{j|D_j=1} = \\beta_0 + \\beta_T + r_j\\) mientras que si pertenece al grupo control ser√° \\(\\mu_{j|D_j=0} = \\beta_0 + r_j\\), y la esperanza de la diferencia entre ambas (dado que la esperanza de \\(E(r_j)=0\\)) ser√° justamente la magnitud del efecto del tratamiento \\(\\beta_T\\).\n\n\n5.5.2 La potencia y la correlaci√≥n intraclase (ICC)\nLa correlaci√≥n intraclase (ICC) es una estad√≠stica descriptiva que indica en qu√© medida los resultados: 1) tienden a ser similares dentro de cada cl√∫ster, o 2) tienden a diferir entre distintos cl√∫sters, en relaci√≥n con los resultados observados en otros grupos. Se define de la siguiente forma:\n\\[\nICC = \\frac{\\sigma^2_{inter-cl√∫ster}}{\\sigma^2_{inter-cl√∫ster} + \\sigma^2_{intra-cl√∫ster}}\n\\]\ndonde \\(\\sigma^2_{inter-cl√∫ster}\\) es la varianza entre cl√∫sters, es decir, cu√°nto se var√≠an las medias de los cl√∫sters, y \\(\\sigma^2_{intra-cl√∫ster}\\) es la varianza dentro de los cl√∫sters, es decir, cu√°nto var√≠as las mediciones de cada individuo dentro de cada cl√∫ster.\nComo mencionamos anteriormente, la aleatorizaci√≥n a nivel de cl√∫ster tiene su costo. Si los outcomes dentro de cada cl√∫ster est√°n altamente correlacionados y la magnitud de los resultados var√≠a considerablemente entre cl√∫sters, entonces es probable que los participantes dentro de un mismo grupo tengan resultados similares, y el ICC ser√° alto. En estos casos, los datos provenientes de un individuo aportan casi tanta informaci√≥n como si se incluyera a todos los miembros. Por lo tanto, el tama√±o muestral efectivo se aproxima m√°s al n√∫mero de cl√∫sters que al tama√±o total de la muestra de individuos.\nPasando en limpio. Si los cl√∫sters son m√°s similares entre s√≠, el modelo estad√≠stico ser√° m√°s potente, con un tama√±o de muestra efectivo cercano a la cantidad de individuos mientras que si los cl√∫sters difieren mucho entre s√≠ la potencia estad√≠stica cae, aproxim√°ndonos a un tama√±o de muestra efectivo igual a la cantidad de cl√∫sters.\nEs por esto √∫ltimo que en la pr√°ctica siempre conviene agergar m√°s cl√∫sters que individuos11. Pero claro, eso es lo que suele ser m√°s costoso.\n11¬†Un ejemplo num√©rico, dado un total de \\(1000\\) participantes, la potencia ser√≠a de \\(0.75\\) si hubiera \\(50\\) grupos de \\(20\\) participantes cada uno, mientras que el poder ser√≠a s√≥lo de \\(0.45\\) con \\(20\\) grupos de \\(50\\) participantes cada uno, suponiendo un \\(ICC\\) de \\(0.1\\).\n\n5.5.3 Un ejemplo con datos\nSimulemos un peque√±o ejemplo. Supongamos que, sin un √°pice de creatividad, queremos evaluar la efectividad de una intervenci√≥n educativa que s√≥lo se puede aplicar a nivel de escuela. El outcome de inter√©s a nivel estudiante va a ser la nota obtenida en un examen estandarizado de matem√°ticas. Tengamos en cuenta la ecuaci√≥n ?eq-cluster_model, en nuestro caso \\(Y_{ij}\\) ser√≠a la nota de cada estudiante, mientras que \\(mu_j\\) ser√≠a la media de cada colegio.\nLas medias de cada colegio las crearemos usitilizando los par√°metros \\(beta_0 = 50\\) y \\(beta_T = 10\\), es decir, la magnitud del efecto que deber√≠amos recuperar luego es \\(10\\). Adem√°s el error ser√° \\(r_j \\sim \\mathcal{N}(0, \\sigma_{escuelas}^2)\\), con \\(\\sigma_{escuelas} = 5\\). Vamos a simular \\(40\\) escuelas, asignando la mitad al grupo tratamiento y la otra mitad al grupo control. Veamos qu√© pasa con las medias de las escuelas que vamos a simular.\n\n\nVer el c√≥digo\n# Data jer√°rquica\nset.seed(42)\nn_escuelas &lt;- 40\n\n# Supongamos que tengo n_escuelas escuelas, cada una de ellas tiene una media de la calificacion de nota de matem√°tica\nmu_j &lt;- rnorm(n_escuelas, 50, 5)\n  \n# Las primera 3 son asignadas al grupo tratamiento y las otrasa tres al grupo control\nd &lt;- c(rep(\"Tratamiento\", n_escuelas/2), rep(\"Control\",  n_escuelas/2))\n\n# El efecto del tratamiento es 10, entonces a la media de cada escuela que pertenece al grupo tratamiento\n# le sumamos 10\nbeta_T &lt;- 10\n\n# Armo un tibble con las escuelas\nescuelas &lt;- tibble(tratamiento = d, media = mu_j) |&gt;\n    mutate(media = if_else(tratamiento == \"Tratamiento\", media + beta_T, media)) \n\n# Graficamos los promedios de las escuelas\nescuelas |&gt;\n  ggplot(aes(x = tratamiento, \n             y = media,\n             color = tratamiento)) +\n  geom_jitter(size = 2, \n              alpha = .6,\n              width = .2) +\n  scale_color_manual(values = c(\"#1380A1\", \"#ED6A5A\")) +\n  labs(color = NULL, x = NULL, y = \"Media de la escuela j\") +\n  theme_bw() +\n  theme(legend.position = \"top\")\n\n\n\n\n\n\n\n\n\nComo era esperable, las medias de las escuelas en el grupo tratamiento est√°n por encima de las medias en el grupo control. Sin embargo, hay escuelas para las que esto no es as√≠. Es por eso que es muy importante modelar a la escuela (el cl√∫ster) como una posible fuente de variabilidad.\nAhora lo que podemos hacer es simular las notas de los estudiantes dentro de cada colegio \\(Y_{ij}\\). Para eso vamos a echar mano a la primera l√≠nea de la ecuaci√≥n ?eq-cluster_model. En este caso el \\(mu_j\\) ser√° el obtenido en el punto anterior con un \\(\\epsilon_{ij} \\sim \\mathcal{N}(0, \\sigma_{estudiante}^2)\\), con \\(\\sigma_{estudiante} = 10\\). Veamos ahora qu√© pinta tienen estos datos.\n\n\nVer el c√≥digo\n# Data jer√°rquica\n\n# Ahora vamos a muestrear 20 estudiantes en cada escuela, con media mu_j y un sigma de 10\nalumnos &lt;- tibble(tratamiento = rep(d, each = 20), \n                  order =rep(1:n_escuelas, each = 20),\n                  escuela = rep(paste(\"Escuela\", 1:n_escuelas), each = 20),\n                  media = rep(mu_j, each = 20)) |&gt;\n  mutate(media = if_else(tratamiento == \"Tratamiento\", media + beta_T, media)) |&gt;\n  rowwise() |&gt;\n  mutate(Yij = rnorm(1, media, 10)) |&gt;\n  select(-media)\n\n# Graficamos los promedios de las escuelas\nalumnos |&gt;\n  ggplot(aes(x =  fct_reorder(escuela, desc(order)), \n             y = Yij,\n             color = tratamiento)) +\n  geom_jitter(size = 1, \n              alpha = .6,\n              width = .2) +\n  scale_color_manual(values = c(\"#1380A1\", \"#ED6A5A\")) +\n  labs(color = NULL, x = NULL, y = \"Yij\") +\n  coord_flip() +\n  theme(legend.position = \"top\")\n\n\n\n\n\n\n\n\n\nAc√° vemos que a la variabilidad de las escuelas se suma la variabilidad de los sujetos.\nAhora vamos a tratar de recuperar el tama√±o del efecto ajustando un modelo lineal de efectos mixtos12.\n12¬†Sin entrar en demasiado detalle, un modelo lineal de efectos mixtos tiene en cuenta la estructura jerarquica del efecto. En este caso en particular vamos a permitirle al modelo que el punto medio de cada colegio sea considerado un factor aleatorio.\n\nVer el c√≥digo\nmlmer &lt;- lmer(Yij ~ tratamiento + (1|escuela), data = alumnos)\nmodelsummary(list(\"Escuelas\"= mlmer),\n             coef_rename = c(\"tratamientoTratamiento\" = \"Tratamiento\"),\n             statistic = NULL, \n             gof_omit = 'DF|Deviance|R2|AIC|BIC|Log.Lik|F')\n\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                Escuelas\n              \n        \n        \n        \n                \n                  (Intercept)\n                  47.802\n                \n                \n                  Tratamiento\n                  12.923\n                \n                \n                  SD (Intercept escuela)\n                  6.260\n                \n                \n                  SD (Observations)\n                  9.733\n                \n                \n                  Num.Obs.\n                  800\n                \n                \n                  ICC\n                  0.3\n                \n                \n                  RMSE\n                  9.51\n                \n        \n      \n    \n\n\n\nTratemos de entender qu√© nos dice este modelo. (Intecept) no es otra cosa que \\(\\hat{\\beta_0}\\) que, de acuerdo a lo que simulamos, deber√≠a valer \\(50\\), que era el valor del par√°metro que usamos para generar las medias de las escuelas antes de sumarles el error \\(r_j\\) y el efecto del tratamiento. Hablando del efecto del tratamiento, podemos ver que para esta simulaci√≥n en particular, la estimaci√≥n del efecto de la intervenci√≥n \\(\\beta_T\\) que sabemos que vale \\(10\\) es estimada como \\(\\hat{\\beta_T} = 12.92\\). Otra cosa interesante que podemos ver es que el modelo tambi√©n estima la variabilidad de los errores donde SD (Intercept escuela) es una estimaci√≥n de \\(r_j\\) y SD (Observations) es una estimaci√≥n de \\(\\epsilon_{ij}\\), con un valor de \\(9.73\\). Ambos valores de variabilidad son similares a los que usamos para hacer las simulaciones.\nPero‚Ä¶ ¬øPor qu√© el valor estimado del efecto es \\(\\hat{\\beta_T} = 12.92\\) en lugar de \\(10\\)? Bueno, porque se trata de una simulaci√≥n con su respectiva variabilidad. Por ejemplo, veamos qu√© pasa si simulamos \\(1000\\) experimentos.\n\n\nVer el c√≥digo\n# Data jer√°rquica\nset.seed(12)\n\nn_escuelas &lt;- 100\nbetalmer &lt;- c()\nbeta_T &lt;- 10\nd &lt;- c(rep(\"Tratamiento\", n_escuelas/2), rep(\"Control\",  n_escuelas/2))\n\nfor (i in 1:1000) {\n  mu_j &lt;- rnorm(n_escuelas, 50, 5)\n  \n  alumnos &lt;- tibble(tratamiento = rep(d, each = 20), \n                    escuela = rep(paste(\"Escuela\", 1:n_escuelas), each = 20),\n                    media = rep(mu_j, each = 20)) |&gt;\n    mutate(media = if_else(tratamiento == \"Tratamiento\", media + beta_T, media)) |&gt;\n    rowwise() |&gt;\n    mutate(Yij = rnorm(1, media, 10)) |&gt;\n    select(-media)\n  \n  mlmer &lt;- lmer(Yij ~ tratamiento + (1|escuela), data = alumnos)\n  betalmer &lt;- c(betalmer, fixef(mlmer)[2])\n}\n\nbetas &lt;- tibble(betalmer = betalmer)\nmean_beta &lt;- betas |&gt;\n  summarise(m_beta = mean(betalmer))\n\nbetas |&gt;\n  ggplot(aes(x = betalmer)) +\n  geom_histogram(fill = \"#1380A1\", \n                 alpha = .6,\n                 bins = 30) +\n  geom_vline(xintercept = mean_beta$m_beta, \n             color = \"#1380A1\", \n             linewidth = 1) +\n  geom_label(data = mean_beta,\n            aes(label = paste(\"Efecto promedio =\", round(m_beta,2))),\n            x = 10, \n            y = 50)  +\n  labs(x = \"Estimaci√≥n del efecto del tratamiento\",\n       y = NULL) +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nVemos que si hacemos un histograma de todas las estimaciones del par√°metro en base a las \\(1000\\) simulaciones de los datos, el promedio es 10.02, un valor bastante cercano al valor real de \\(10\\)13. Ahora s√≠ nos podemos quedar tranquilos.\n13¬†Recordemos que en la pr√°ctica nunca vamos a conocer el valor real del par√°metro y que esa es un ventaja que s√≥lo tenemos en estos casos en los que simulamos ‚Äúmuestras‚Äù a partir de valores conocidos de los par√°metros.",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Experimentos aleatorios</span>"
    ]
  },
  {
    "objectID": "exp_aleatorios.html#el-experimento-ideal",
    "href": "exp_aleatorios.html#el-experimento-ideal",
    "title": "5¬† Experimentos aleatorios",
    "section": "5.2 El experimento ideal",
    "text": "5.2 El experimento ideal\nEl experimento ideal es ese experimento tan bien planificado, tan bien implementado y tan bien acatado por sus participantes que en la realidad nunca ocurre. Sin embargo, hay una excepci√≥n y son, en general, los medical trials. De hecho hay algunas caracter√≠sticas que esperar√≠amos ver en un RCT3 y son las siguientes.\n3¬†Randomized clinical trials, o ensayos cl√≠nicos aleatorizados. Son estudios experimentales que se utilizan para testear la eficacia o la seguridad de procedimientos m√©dicos o tratamientos.\nControles adecuados: Si dise√±amos un experimento para estimar el efecto de un tratamiento, debemos tener un grupo control adecuado con el que comparar. Sin embargo, esto no significa que el grupo control sea siempre un grupo simplemente no expuesto al tratamiento. Por ejemplo, es muy conocido el ejemplo de la determinaci√≥n de la efectividad de un f√°rmaco, en los que al grupo control se le ofrece una pastilla que no contiene a la droga siendo estudiada sino unas pastilla de igual forma, tama√±o y prescripci√≥n de consumo pero, t√≠picamente, de azucar. Esto lo que nos permite es poder descontar el efecto de consumir un placebo en la estimaci√≥n final de la efectividad del f√°rmaco4.Tambi√©n es posible que por consideraciones √©ticas no podamos dejar al grupo control con un tratamiento placebo (por ejemplo cuando ya existe un tratamiento efectivo para la enfermedad que estamos estudiando, si lo hicieramos privar√≠amos a los sujetos del grupo control de su derecho a la salud), en estos casos el grupo control recibe el tratamiento t√≠pico y el grupo tratamiento el del estudio, en estos casos descontaremos el efecto del tratamiento com√∫n y nuestro ATE es el efecto de la intervencion por encima del tratamiento usual\n\n\n4¬†Si les interesa, tambi√©n existen el efecto nocebo y know-cebo.\nAsignaci√≥n aleatoria a los grupos experimentles: Como vimos en el cap√≠tulo Cap√≠tulo 3, la mejor forma de asegurar que los grupos control y tratamiento son lo m√°s iguales posibles es asignando aleatoriamente a los participantes. Esto, junto con una cantidad de participantes suficiente nos asegura que ambos grupos son iguales en todos los factores que pueden influenciar el resultado del experimento, incluyendo los factores de los que no sabemos.\nLos individuos deben ser considerados en el grupo asignado: Los participantes asignados al grupo tratamiento deben ser considerados como tratamiento, independientemente de si se expusieron o no al mismo. Esto es conocido como el principio intention to treat y puede sonar un poco raro. Sin embargo, lo podemos pensar como un cambio del tratamiento que queremos evaluar. Por ejemplo, hay un experimento en el que se quiere evaluar el efecto de la estatinas en el colesterol LDL. Hay un grupo al que le dan estatinas y otro grupo al que le dan un placebo. Un $18% $ de los que fueron originalmente asignados al grupo estatinas dej√≥ de tomarlas y un $38% $ de los que fueron asignados al grupo placebo empez√≥ a tomar estatinas durante el trial. Esto significa que nuestro experimento no estimar√≠a correctamente el efecto de tomar las estatinas, pero por otro lado, s√≠ estimar√≠a bien el efecto de ser recetado con estatinas. Y si lo pensamos un poco: ¬øNo es algo m√°s razonable estimar el efecto de lo segundo?5\n\n\n5¬†Una mejor explicaci√≥n de este enfoque y su contraparte (no recomendada), el an√°lisis por protocolo pueden visitar este paper[esto] https://onlinelibrary.wiley.com/doi/10.1111/nep.13709\nTodos los grupos deben ser tratados igual: Por ejemplo, si en el ejemplo anterior invitamos a la gente del grupo de estatinas a controles m√©dicos m√°s seguidos, o los evaluamos con m√°s dedicaci√≥n, va a ser imposible separar los beneficios de la droga de los beneficios de las diferencias en c√≥mo tratamos a los pacientes.\nBlinded: Para que las estimaciones de un experimento no se contaminen, resulta necesario que los participantes (o unidad experimental) no conozcan a que grupo experimental pertenecen. Esto es importante porque podr√≠a haber alg√∫n tipo de contaminaci√≥n del efecto como por ejemplo que los sujetos que sepan que reciben la intervenci√≥n se esfuercen para rendir mejor en el outcome o lo contrario al saberse ‚Äúabandonados‚Äù al grupo control tiendan a rendir peor.\nDouble blinded: Siguiendo con lo mencionado antes, tambi√©n resulta deseable que los investigadores tampoco sepan a que grupo experimental pertenece un sujeto o unidad experimental. Esto tiene como objetivo reducir al m√≠nimo las diferencias entre los grupos. Por ejemplo, en un experimento para estimar la efectividad de una campa√±a de comunicaci√≥n para motivar la vacunaci√≥n, los investigadores podr√≠an espaciar menos las comunicaciones con alguno de los grupos experimentales, contaminando as√≠ el efecto de la intervenci√≥n en s√≠ misma.\nPor supuesto que esto no siempre es posible. Por ejemplo, si un experimento quiere estimar la efectividad de una nueva ciruj√≠a laparoscopica versus su alternativa tradicional, resulta imposible que el cirujano que va a llevar adelante la misma no sepa a qu√© grupo pertenece el paciente. Sin embargo, es importante que en estos casos la asignaci√≥n al grupo se retrase lo m√°s posible disminuyendo la posible influencia de otros participantes (por ejemplo, un investigador podr√≠a estar m√°s atento a la preparaci√≥n preoperatoria de alg√∫n grupo experimental).\nMedir a todos los individuos: Todos los individuos que comenzaron el experimento deben ser medidos para evaluar el efecto del tratamiento. Esto no siempre pasa y es algo de lo que vamos a hablar m√°s adelante en este cap√≠tulo.\n\nQue lindo es el dise√±o experimental. Todos somos felices, todo funciona. ¬øEl libro deber√≠a terminar ac√°?\n\n\n\n\n\nPues no mi ciela. Ojal√° llevar adelante experimentos fuera tan f√°cil.",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Experimentos aleatorios</span>"
    ]
  },
  {
    "objectID": "exp_aleatorios.html#cuando-la-cosa-no-es-tan-ideal",
    "href": "exp_aleatorios.html#cuando-la-cosa-no-es-tan-ideal",
    "title": "5¬† Experimentos aleatorios",
    "section": "5.3 Cuando la cosa no es tan ideal",
    "text": "5.3 Cuando la cosa no es tan ideal\n\n5.3.1 Aleatorizaci√≥n por bloques\nIntuitivamente pensamos que la aleatorizacion de los sujetos a un grupo control o un grupo tratamiento es tan simple como lanzar una moneda (y muchas veces lo es), este m√©todo se conoce como aletorizaci√≥n simple. Sin embargo puede que este m√©todo no sea siempre deseado. Por ejemplo, se quiere testear la ventaja de una intervenci√≥n laparosc√≥pica (m√≠nimamente invasiva) sobre una cirug√≠a tradicional (en la que se abre el abdomen). Es razonable pensar que los cirujanos se vuelven mejores con el tiempo sin importar a que tipo de cirug√≠a, porque la pr√°ctica hace al maestro. Bueno imaginemos que aplicamos un proceso de aleatorizaci√≥n simple, es posible que los primeros sujetos sean asignados con m√°s frecuencia al grupo tratamiento que al grupo control y los √∫ltimos viceversa (ya que la randomizacion es un proceso independiente, la asignaci√≥n del sujeto anterior no condiciona al que sigue, y esto es posible). En este escenario hipotetico pero posible, el ATE que queremos estimar se encuentra contaminado por una variable confusora (la habilidad del cirujano). ¬øC√≥mo evitamos esto? Bueno una forma razonable es evitar que los sujetos se asignen al grupo todos juntos sino a medida que el cirujano va aprendiendo. Para hacer esto se pueden crear bloques temporales, por ejemplo, los 10 primeros voluntarios, los 10 siguientes y as√≠ sucesivamente. Dentro de cada bloque hacemos una asignaci√≥n aleatoria, de esta forma nos aseguramos que haya un numero mas o menos balanceado de sujetos en el grupo control e intervencion expuestos al cirujano torpe, intermedio y master level.\n\n\n\n\n\n\n\n5.3.2 Spillover\nEn un experimento ideal, los sujetos son asignados aletoriamente a los grupos experimentales y se quedan ah√≠. El efecto spillover o derrame sucede cuando los sujetos del grupo control reciben en forma indirecta parte o todo el tratamiento que esta dise√±ado para el grupo de intervenci√≥n. ¬øC√≥mo es esto posible? Es muy posible, sobre todo en intervenciones conductuales. Pongamos ejemplos para que se entienda. Supongamos que queremos ver el efecto de una intervenci√≥n educativa como h√°bitos saludables para prevenir cierta enfermedad, algunos sujetos son asignados a la intervenci√≥n y reciben una charla educativa y otros nada. Un par de amigos (i y j) han sido aleatorizados a un grupo y al otro respectivamente. Al terminar la intervenci√≥n el sujeto intervenido (i) le cuenta la charla al sujeto del grupo control (j) y este ‚Äúrecibe el tratamiento‚Äù. En este ejemplo un sujeto asignado a un grupo control recibe el tratamiento destinado al grupo intervenci√≥n. Es decir, el grupo tratamiento ha derramado hacia el grupo control.\n\nVale la pena preguntarse por qu√© el spillover es relevante en los estudios aleatorizados. Si volvemos al cap√≠tulo 3 y a repasar outcomes potenciales podemos ver que este marco requiere una asuncion a la que llamamos SUTVA6 o en otras palabras este supuesto establece que los resultados potenciales del sujeto j dependen √∫nicamente de su propio estado de tratamiento (el que fue asignado), sin verse afectados por el tratamiento recibido por otro sujeto i. Sin embargo esto no es as√≠, ya que i es responsable del resultado potencial de j porque ‚Äúle ha aplicado‚Äù el tratamiento. Al violar esta asunci√≥n, estimar el ATE a trav√©s de una diferencia de medias puede estar francamente sesgado por este efecto. El spillover es un efecto dif√≠cil de rastrear y sobretodo dif√≠cil de corregir, es frecuente en intervenciones que tienen que ver con comunicacion o informacion, ya que la comunicaci√≥n fluye despues de la intervenci√≥n de forma incontrolable para los investigadores. El mejor enfoque es preveer esta posibilidad e instaurar barreras a priori para disminuir el contagio que una intervenci√≥n pueda tener sobr el grupo control.\n6¬†Del ingl√©s stable unit treatment value assumption.\n\n5.3.3 Reversi√≥n de la cadena causal (o reverse causation)\nLa reversi√≥n causal es uno de los sesgos que pueden plagar nuestra interpretaci√≥n de la cadena causa-efecto, sobre todo en los estudios observacionales.\nInventemos un escenario hipot√©tico: pensemos que un investigador quiere evaluar si la lluvia ca√≠da aumenta la frecuencia de gente con parag√ºas en la calle. La respuesta es obvia para nosotros que conocemos las leyes de la naturaleza y que la gente odia mojarse. Cada vez que llueve, la gente sale a la calle con parag√ºas. Pero que pasa si nuestro investigador fuera un ser completamente ajeno a todo esto (digamos un batiduende de la 5ta dimensi√≥n) y no tuviera conocimiento alguno previo. Este ser, podr√≠a contar la frecuencia de paraguas en la calle y si llueve o no, hacer una regresi√≥n log√≠stica (por poner un ejemplo) para predecir la lluvia en funci√≥n de la cantidad de parag√ºas de la calle y de seguro que ser√≠a un predictor significativo. Y es m√°s, podr√≠a cerrar su estudio concluyendo que un aumento de una unidad en la frecuencia de parag√ºas aumenta en un cierto porcentaje las chances de que llueva, o sea que los parag√ºas causan la lluvia. Nuestro batiduende investigador habr√≠a incurrido en un sesgo de causalidad inversa. Podr√≠amos pensar por lo absurdo del ejemplo que este sesgo es dif√≠cil de que afecte a nuestras investigaciones, sin embargo es muy frecuente. Ejemplos de causalidad reversa son por ejemplo: observar que los barrios con propiedades mas costosas tienen un centro comercial y suponer que colocar un centro comercial en un barrio aumenta el valor de la vivienda, cuando lo que pasa es que los centros comerciales decidan colocarse en barrios con propiedades costosas; u observar que las personas que hacen m√°s ejercicio tienen menos s√≠ntomas depresivos, e interpretar que hacer ejercicio reduce la depresi√≥n cuando podr√≠a ser que las personas menos deprimidas tienen m√°s energ√≠a o motivaci√≥n para hacer ejercicio.\nLos dise√±os experimentales pueden protegernos mejor que los estudios observacionales de este tipo de sesgo, por qu√©, fundamentalmente porque en nuestro dise√±o experimental vamos a aplicar la causa y esperar que la consecuencia suceda despu√©s de esto. Por regla general las causas no pueden ocurrir despu√©s que sus consecuencias y de esta manera la direcci√≥n de la causalidad es forzada hacia un solo lado. Sin embargo, el sesgo de causalidad inversa puede ocurrir a√∫n as√≠ en un ensayo experimental bajo ciertas condiciones:\n\nNo cumplimiento del tratamiento (non-compliance): Supongamos que en el experimento se asigna aleatoriamente a algunos sujetos a recibir un tratamiento, por ejemplo una nueva terapia para la caida de cabello, pero los sujetos con mas caida de cabello en las primeras dosis del grupo tratamiento sienten que el tratamiento es inutil y dejan de tomar las pastillas . Este evento introduce un sesgo de causalidad inversa si analizamos a los sujetos por si tomaron el tratamiento o no (por protocolo en lugar de intention-to-treat) ya que el outcome (la caida del cabello) genera la exposici√≥n (la cantidad de medicaci√≥n que las personas en el grupo de tratamiento reciben.\nEfectos anticipados o comportamiento reactivo: A veces, los participantes modifican su comportamiento en respuesta a saber su asignaci√≥n. Ejemplo: alguien asignado al grupo control empieza a buscar alternativas por su cuenta (porque no recibi√≥ tratamiento), y eso afecta su resultado. O alguien en el grupo tratado ya anticipa que tendr√° mejor√≠a y cambia su comportamiento desde antes del tratamiento real. El resultado cambia en respuesta a la expectativa del tratamiento, y no necesariamente al tratamiento en s√≠.\nMediciones mal temporizadas: En algunos experimentos, puede que la variable de outcome sea medida antes de que el tratamiento surta efecto, o incluso antes de aplicarlo bien. Si los resultados se usan para definir o cambiar el tratamiento asignado (por error o por dise√±o), ya no hay garant√≠a de temporalidad: el resultado podr√≠a estar influyendo en el tratamiento.\n\n\n\n\n\n\n\nAdvertencia\n\n\n\nSi prestaron atenci√≥n a las secciones anteriores sospecharan que muchos de estos sesgos de causalidad inversa puedan evitarse aplicando analisis ITT y asegurandonos un blinded adecuado, es as√≠",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Experimentos aleatorios</span>"
    ]
  },
  {
    "objectID": "exp_aleatorios.html#experimentos-between-groups",
    "href": "exp_aleatorios.html#experimentos-between-groups",
    "title": "5¬† Experimentos aleatorios",
    "section": "5.4 Experimentos between groups",
    "text": "5.4 Experimentos between groups\n\n\n\n\n\n\nHablemos un poco de la nomenclatura\n\n\n\n\n\n\nEn este cap√≠tulo definimos los experimentos aleatorizados como aquellos en los que se asigna al azar a los participantes a una condici√≥n de tratamiento o de control. Este enfoque corresponde, en realidad a un s√≥lo tipo de dise√±o aletorizado, los dise√±os conocidos como between-groups.\nEn los experimentos between-groups, los participantes se distribuyen aleatoriamente entre diferentes condiciones de tratamiento, formando grupos que luego se comparan entre s√≠. Por ejemplo, se puede asignar a estudiantes a distintos m√©todos de ense√±anza, a pacientes hipertensos a planes de dieta variados o a adultos mayores a programas de ejercicio f√≠sico.\nAntes de analizar los distintos tipos de dise√±os dentro de esta categor√≠a, presentaremos algunas definiciones y notaciones clave.\nCuando querramos representar esquematicamente un dise√±o, vamos a recurrir a la notaci√≥n cl√°sica. Seg√∫n esta, se representar√°n gr√°ficamente tanto los experimentos aleatorizados como los cuasi-experimentos usando las letras \\(X\\) y \\(O\\). Una \\(X\\) indica la administraci√≥n de un tratamiento, y una \\(O\\) representa una observaci√≥n. Una \\(O\\) puede referirse a una observaci√≥n de una o varias variables en un momento determinado. Una observaci√≥n puede ser cualquier tipo de medici√≥n, ya sea un test escrito, un registro fisiol√≥gico, un informe verbal, o cualquier otra evaluaci√≥n emp√≠rica. En estos diagramas, el tiempo (como la lectura) fluye de izquierda a derecha. Cuando se realizan varias observaciones, se utilizan sub√≠ndices en las \\(O\\) para indicar el momento de cada medici√≥n.\nUtilizando esta notaci√≥n, el experimento aleatorizado entre grupos m√°s simple se representa as√≠:\n\n\n\\[\\begin{array}{lcl}\n\\text{R:} & X & O \\\\\n\\text{R:} &   & O \\\\\n\\end{array}\\]\n\n\nVamos a tratar de entender que significa esta notaci√≥n, en principio hay dos l√≠neas, esto indica que hay dos grupos, cada l√≠nea empieza con una \\(R\\), esto indica que los sujetos fueron asignados aleatoriamente (o random) a la participacion de ese grupo, vemos en la primera l√≠nea que ese grupo a recibido un tratamiento \\(X\\) y el otro no y que ambos grupos han sido evaluados posterior a ello en una instancia \\(O\\). Este dise√±o se conoce como post-test only o s√≥lo post-test ya que como puede verse en este dise√±o la √∫nica medida que se toma es despues de la intervenci√≥n.\nUna vez que hemos entendido este dise√±o sencillo podemos introducir otro un poco m√°s complejo como este\n\\[\\begin{array}{lcl}\n\\text{R:}& O_1 & X & O_2 \\\\\n\\text{R:}& O_1 &   & O_2 \\\\\n\\end{array}\\]\nLa fila superior indica que un grupo es observado (\\(O_1\\)), luego recibe un tratamiento (\\(X\\)), y se observa nuevamente (\\(O_2\\)). La fila inferior muestra que un segundo grupo es observado, no recibe el tratamiento (aunque puede recibir uno alternativo), y luego es observado de nuevo. Nuevamente, la ‚Äú\\(R:\\)‚Äù indica asignaci√≥n aleatoria. (Lo ideal es realizar la asignaci√≥n aleatoria despu√©s de la \\(O_1\\), as√≠ que la posici√≥n de ‚Äú\\(R:\\)‚Äù no indica necesariamente el orden temporal, ya discutiremos el por qu√© de esto). En pocas palabras lo que diferencia este dise√±o del anterior es que existe una observaci√≥n m√°s, una antes de la intervenci√≥n. Este tipo de dise√±o entonces se llama pretest-posttest. Ahora que hemos introducido esquem√°ticamente los dos dise√±os fundamentales de los experimentos aleatorizados entre grupos vamos a hablar de ello.\n\n5.4.1 S√≥lo posttest\nRecapitulemos, los dise√±os post-test only son la forma m√°s simple de experimentos aletorizados entre grupos en donde un grupo es aleatoriamente asignado a una intervenci√≥n, el otro a su condici√≥n de control, y posteriormente a ello se evalua el outcome. Resumiendo e la notaci√≥n:\n\\[\\begin{array}{lcl}\n\\text{R:} & X & O \\\\\n\\text{R:} &   & O \\\\\n\\end{array}\\]\nEste dise√±o puede escribirse (y analizarse) utilizando un modelo lineal que tiene la siguiente forma:\n\\[\n\\begin{array}\n_Y_{i} &=& \\beta_0 + \\beta_T T_i + \\epsilon_{i}\n\\end{array}\n\\tag{5.1}\\]\nDonde \\(Y_i\\) es el valor de que adopta \\(O\\) (es decir nuestro outcome post-intervenci√≥n), y \\(T_i\\) es una variable indicadora que toma el valor \\(1\\) si el participante pertenece al grupo tratamiento y el valor \\(0\\) si no y \\(\\epsilon_{i}\\) representa el t√©rmino de error (varianza no explicada por el modelo). Para los modelos que veamos en estas secciones \\(\\epsilon_{i}\\) tiene una distribuci√≥n \\(\\epsilon_{i} \\sim \\mathcal{N}(0, \\sigma_\\epsilon^2)\\),\nVamos a ver como podemos usar este dise√±o (y este modelo), para estimar el ATE.\n\n5.4.1.1 Un A/B test\nUn A/B test es un experimento aletorizado muy popular en el campo del dise√±o de p√°ginas web. El mismo consiste en presentar a los usuarios con dos versiones del mismo sitio web (la versi√≥n A y la versi√≥n B) y medir su comportamiento en funci√≥n de la versi√≥n que se les presenta. Por ejemplo, se puede medir el tiempo que los usuarios pasan en el sitio web, la tasa de clics en un bot√≥n o cualquier otra m√©trica relevante. La idea es comparar el rendimiento de las dos versiones para determinar cu√°l es m√°s efectiva.\nEn nuestro ejemplo vamnos a asignar aleatoriamente a los usuarios a dos versiones distintas de un sitio web (la version anterior Website A o control, y la version nueva Website B o intervenci√≥n) y mediremos el tiempo de permanencia en segundos. Es decir, queremos ver si el cambio de dise√±o de la p√°gina web tiene un efecto positivo en el tiempo que los usuarios pasan en el sitio. En este caso, el tiempo de permanencia es nuestro outcome y la variable de tratamiento es la versi√≥n del sitio web.\nVamos a simular los datos para \\(100\\) usuarios (50 en cada grupo) y luego vamos a estimar el ATE usando un modelo lineal. Como los datos son simulados, conocemos el efecto real de la intervenci√≥n (el ATE) que es de \\(5\\) segundos. De hecho, sabemos que el tiempo promedio de permanencia en la versi√≥n A es de \\(50\\) segundos y en la versi√≥n B es de \\(55\\) segundos 7.\n7¬†¬øPor qu√© decimos que la asignaci√≥n es aleatoria si en ning√∫n momento tiramos una moneda? Bueno, si miran el c√≥digo que utilizamos para la simulaci√≥n de los datos, vamos a ver que los tiempos base (antes de sumar el tratamiento, \\(\\beta_0 + \\epsilon_{i}\\) en nuestro modelo) son muestras de una \\(\\mathcal{N}(50, 10^2)\\), es decir, una normal con media \\(50\\) y desviaci√≥n est√°ndar \\(10\\). Luego asignamos la mitad para el grupo control y la mitad para el grupo tratamiento (a los que les sumamos \\(\\beta_T\\)). Como nuestros sujetos no tienen una ‚Äúidentidad‚Äù, al separar mitad para cada lado dado que son muestras aleatorias tomadas de una distribuci√≥n es como si estuvi√©ramos asignando aleatoriamente a los grupos experimentales.\n\nVer el c√≥digo\nset.seed(42)\n# Simulamos el experimento\nn &lt;- 50 # Sujetos por condici√≥n\nt &lt;- rnorm(2*n, 50, 10) # Variable que indica la exposici√≥n al tratamiento\nt_control &lt;- t[1:n] # Tiempos del grupo control\nt_tratamiento &lt;- t[(n+1):(2*n)] + 5 # Tiempos del grupo tratamiento\n\ndata &lt;- tibble(tiempo = c(t_control, t_tratamiento),\n               condicion = c(rep(\"Website A\", n), rep(\"Website B\", n)))\n\ndata |&gt;\n  ggplot(aes(x = condicion, \n             y = tiempo, \n             color = condicion)) +\n  geom_jitter(width = .2) + \n  scale_color_manual(values = c(\"#1380A1\", \"#ED6A5A\")) +\n  labs(x = NULL,\n       y = \"Tiempo (s)\", \n       color = NULL) +\n  theme_bw() +\n  theme(legend.position = \"top\")\n\n\n\n\n\n\n\n\n\nEn nuestro caso la versi√≥n del modelo de la ecuaci√≥n Ecuaci√≥n¬†5.1 es la siguiente:\n\\[\n\\begin{array}\n_t_{i} &=& \\beta_0 + \\beta_T T_i + \\epsilon_{i}\n\\end{array}\n\\]\nDonde \\(t_i\\) es el tiempo de permanencia en segundos, y \\(T_i\\) es una variable indicadora que toma el valor \\(1\\) si el participante pertenece al grupo tratamiento (Website B) y el valor \\(0\\) si pertenece al grupo control (Website A). En este caso, \\(\\beta_T\\) representa la diferencia promedio entre los dos grupos, es decir, el ATE.\nAjustemos un modelo lineal y veamos c√≥mo da la cosa.\n\n\nVer el c√≥digo\nmodel_postets_only &lt;- lm(data = data, tiempo ~ condicion, model = T)\nmodelsummary(list(\"A/B Postest only\"= model_postets_only),\n             coef_rename = c(\"condicionWebsite B\" = \"Website B\"),\n             statistic = c(\"Error est√°ndar = {std.error}\"),\n             gof_omit = \".*\",)\n\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                A/B Postest only\n              \n        \n        \n        \n                \n                  (Intercept)\n                  49.643\n                \n                \n                  \n                  Error est√°ndar = 1.477\n                \n                \n                  Website B\n                  6.364\n                \n                \n                  \n                  Error est√°ndar = 2.089\n                \n        \n      \n    \n\n\n\nComo podemos ver, la estimaci√≥n del efecto del tratamiento es de 6.36 segundos. Esto significa que la nueva versi√≥n del sitio web tiene un efecto positivo en el tiempo de permanencia de los usuarios en comparaci√≥n con la versi√≥n anterior.\n¬øPero no era que el efecto real era de \\(5\\) segundos y que el \\(\\hat\\beta_T\\) era un estimador insesgado del efecto porque se trata de un experimento aleatorio?8 La respuesta es simple y complicada al mismo tiempo. Al simular los datos del experimento estamos tomando una muestra aleatoria y este \\(\\hat\\beta_T\\) no es m√°s que una estimaci√≥n, es decir, una realizaci√≥n. Esto tiene que ver con que si bien el par√°metro \\(\\beta_T\\) vale \\(5\\) sus estimaciones no son siempre exactamente \\(5\\). Lo que si nos asegura el experimento aleatorizado es que el estimador \\(\\hat\\beta_T\\) es un estimador insesgado del par√°metro \\(\\beta_T\\). Es decir, si repiti√©ramos el experimento muchas veces, la media de todas las estimaciones \\(\\hat\\beta_T\\) ser√≠a igual a \\(5\\).\n8¬†No confundamos esa diferencia de 1.36 con un sesgo como el que vimos en el cap√≠tulo [#sec-pot-outcomes]. En ese caso recordemos que hab√≠a esperanzas involucradas.Como simulamos los datos, podemos simular \\(1000\\) realizaciones del experiento y ver qu√© pinta tiene esto, ¬øNo?\n\n\nVer el c√≥digo\n# Simulemos mil experimentos\n\nset.seed(42)\n# Simulamos el experimento\nn &lt;- 50 # Sujetos por condici√≥n\n\nbetapostest &lt;- c()\nbeta_T &lt;- 5\nd &lt;- c(rep(\"Website A\", n), rep(\"Website B\", n))\n\nfor (i in 1:1000) {\n  t &lt;- rnorm(2*n, 50, 10) # Variable que indica la exposici√≥n al tratamiento\n  t_control &lt;- t[1:n] # Tiempos del grupo control\n  t_tratamiento &lt;- t[(n+1):(2*n)] + beta_T # Tiempos del grupo tratamiento\n  \n  data &lt;- tibble(tiempo = c(t_control, t_tratamiento),\n                 condicion = d)\n  \n  model_postets_only &lt;- lm(data = data, tiempo ~ condicion, model = T)\n  betapostest &lt;- c(betapostest, coef(model_postets_only)[2])\n}\n\nbetas_post &lt;- tibble(betapostest = betapostest)\nmean_beta &lt;- betas_post |&gt;\n  summarise(m_beta = mean(betapostest))\n\nbetas_post |&gt;\n  ggplot(aes(x = betapostest)) +\n  geom_histogram(fill = \"#1380A1\", \n                 alpha = .6,\n                 bins = 30) +\n  geom_vline(xintercept = mean_beta$m_beta, \n             color = \"#1380A1\", \n             linewidth = 1) +\n  geom_label(data = mean_beta,\n            aes(label = paste(\"Efecto promedio =\", round(m_beta,2))),\n            x = 5, \n            y = 50)  +\n  labs(x = \"Estimaci√≥n del efecto del tratamiento\",\n       y = NULL) +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nBueno, el promedio de las mil estimaciones de \\(\\beta_T\\) es de 4.99, ya podemos dormir sin frazada.\n\n\n\n5.4.2 Pretest-posttest\n¬øLes parece que al dise√±o simple de la secci√≥n anterior le falta algo? Hay algo que cualquiera que haya le√≠do, planificado o llevado a cabo un experiemnto tiene en mente. Es m√°s potente medir el outcome antes de la intervenci√≥n y despu√©s de la intervenci√≥n. Esto nos permite tener una mejor estimaci√≥n del efecto del tratamiento, ya que podemos controlar por el efecto de la medici√≥n inicial. En este caso, el dise√±o se llama pretest-posttest y se representa as√≠:\n\\[\\begin{array}{lcl}\n\\text{R:}& O_1 & X & O_2 \\\\\n\\text{R:}& O_1 &   & O_2 \\\\\n\\end{array}\\]\nPara analizar los resultados de este tipo de experimentos, tenemos que agregar de alguna forma la medida pre. Lo hacemos de la siguiente forma:\n\\[\n\\begin{array}\n_Y_{i} &=& \\beta_0 + \\beta_T T_i + \\beta_X X_i + \\epsilon_{i}\n\\end{array}\n\\tag{5.2}\\]\nDonde todo representa lo mismo que en la ecuaci√≥n Ecuaci√≥n¬†5.1, pero ahora \\(X_i\\) es la medida pre del sujeto \\(i\\). En este caso, \\(\\beta_T\\) representa de nuevo el efecto del tratamiento y \\(\\beta_X\\) representa el efecto de la medida pre.\nVeamos como se adaptar√≠a el ejemplo de la secci√≥n anterior si agregamos una medici√≥n\n\n5.4.2.1 Midamos algo antes en el A/B test\nA los datos que simulamos anteriormente les vamos a agergar una nueva medida, el tiempo que est√°n en el sitio web antes de la intervenci√≥n. Vamos a suponer, igual que en el ejemplo anterior, que el tiempo promedio de permanencia en la versi√≥n A es de \\(50\\) segundos y en la versi√≥n B es de \\(55\\) segundos. Vamos a simular de nuevo los datos para \\(100\\) usuarios (\\(50\\) en cada grupo).\nEmpecemos mirando los datos como los vimos antes\n\n\nVer el c√≥digo\n# Pretest-posttest ####\nset.seed(123)\nn &lt;- 50\ntime_post &lt;- rnorm(2*n, 50, 10)\ntime_pre &lt;-time_post + rnorm(n,  0, 5)\n\ncontrol_pre  &lt;- time_pre[1:n] \ntratamiento_pre  &lt;- time_pre[(n+1):(2*n)]\ncontrol_post &lt;- time_post[1:n] \ntratamiento_post &lt;- time_post[(n+1):(2*n)] + 5\n\ndata_pre &lt;- tibble(tiempo_pre = c(control_pre, tratamiento_pre),\n                   tiempo_post = c(control_post, tratamiento_post),\n                   condicion = c(rep(\"Website A\", n), rep(\"Website B\", n)))\n\ndata_pre %&gt;% ggplot(aes(x = condicion, \n                        y = tiempo_post, \n                        color = condicion)) +\n  geom_jitter(width = .2) + \n  geom_smooth(method = \"lm\", se = F) +\n  scale_color_manual(values = c(\"#1380A1\", \"#ED6A5A\")) +\n  labs(x = NULL,\n       y = \"Tiempo post (s)\", \n       color = NULL) +\n  theme_bw() +\n  theme(legend.position = \"top\")\n#&gt; `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nSe ve bastante parecido a lo que vimos antes ¬øNo? Tratemos de medir el efecto del tratamiento como lo hicimos en el ejemplo anterior, usando la ecuaci√≥n Ecuaci√≥n¬†5.1. Si ajustamos ese modelo, que no tiene en cuenta a la medida pre, vamos a obtener las mismas estimaciones que en el ejemplo previo. Tiene sentido ¬øNo? Claro que s√≠, porque usamos la misma semilla para generar los datos.\n\n\nVer el c√≥digo\nmodelo_pre_basico &lt;- lm(data = data_pre, \n                        tiempo_post ~ condicion)\n\nmodelsummary(list(\"A/B Sin incluir el tiempo pre\"= modelo_pre_basico),\n             coef_rename = c(\"condicionWebsite B\" = \"Website B\"),\n             statistic = NULL, \n             gof_omit = 'DF|Deviance|R2|AIC|BIC|Log.Lik|F')\n\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                A/B Sin incluir el tiempo pre\n              \n        \n        \n        \n                \n                  (Intercept)\n                  50.344\n                \n                \n                  Website B\n                  6.120\n                \n                \n                  Num.Obs.\n                  100\n                \n                \n                  RMSE\n                  9.07\n                \n        \n      \n    \n\n\n\n¬øEsto est√° mal? Por supuesto que no. Pero miremos los datos, pero esta vez usando el tiempo pre como predictor.\n\n\nVer el c√≥digo\ndata_pre %&gt;% ggplot(aes(x = tiempo_pre, y = tiempo_post, color = condicion)) +\n  geom_jitter(width = .2) + \n  geom_smooth(method = \"lm\", se = F) +\n  scale_color_manual(values = c(\"#1380A1\", \"#ED6A5A\")) +\n  labs(x = \"Tiempo pre (s)\",\n       y = \"Tiempo post (s)\", \n       color = NULL) +\n  theme_bw() +\n  theme(legend.position = \"top\")\n#&gt; `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nLo que podemos ver es que, debido a c√≥mo simulamos los datos, el tiempo pre y el tiempo post est√°n correlacionados, es decir, parte de la variabilidad que tenemos en el tiempo post la podemos explicar por diferencias en el tiempo pre. Entonces vamos a incorporar el tiempo pre como predictor en nuestro modelo. En este caso (usando la ecuaci√≥n Ecuaci√≥n¬†5.2). Comparemos las estimaciones de este modelo con las del de la ecuaci√≥n Ecuaci√≥n¬†5.1.\n\n\nVer el c√≥digo\nmodelo_pre_basico &lt;- lm(data = data_pre, tiempo_post ~ condicion)\nmodelo_pre &lt;- lm(data = data_pre, tiempo_post ~ condicion + tiempo_pre)\n\nmodelsummary(list(\"A/B Sin incluir el tiempo pre\"= modelo_pre_basico,\n                  \"A/B Pretest-postest only\"= modelo_pre),\n             coef_rename = c(\"condicionWebsite B\" = \"Website B\",\n                             \"tiempo_pre\" = \"Tiempo-pre\"),\n             statistic = NULL, \n             gof_omit = 'DF|Deviance|R2|AIC|BIC|Log.Lik|F')\n\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                A/B Sin incluir el tiempo pre\n                A/B Pretest-postest only\n              \n        \n        \n        \n                \n                  (Intercept)\n                  50.344\n                  11.614\n                \n                \n                  Website B\n                  6.120\n                  5.236\n                \n                \n                  Tiempo-pre\n                  \n                  0.789\n                \n                \n                  Num.Obs.\n                  100\n                  100\n                \n                \n                  RMSE\n                  9.07\n                  4.42\n                \n        \n      \n    \n\n\n\nAhora el estimador del modelo pretest-postest es de 5.24 segundos. Una estimaci√≥n m√°s cercana al valor del par√°metro \\(\\beta_T\\) que sabemos que es \\(5\\). Esto, como ya vimos en el ejemplo anterior, no significa que el estimador sea sesgado en el caso de no usar el timpo pre. Pero vamos a ver que la estimaci√≥n es mejor y vamos a ver por qu√©.\nRepitamos la simulaci√≥n de \\(1000\\) experimentos, pero ahora usando el modelo pretest-postest. Vamos a ver c√≥mo se distribuyen las estimaciones de \\(\\beta_T\\) incluyendo y no incluyendo el tiempo pre.\n\n\nVer el c√≥digo\n# Simulemos mil experimentos\n\nset.seed(123)\n# Simulamos el experimento\nn &lt;- 50 # Sujetos por condici√≥n\n\nbetapostest &lt;- c()\nbetaprepostest &lt;- c()\nbeta_T &lt;- 5\nd &lt;- c(rep(\"Website A\", n), rep(\"Website B\", n))\n\nfor (i in 1:1000) {\n  time_post &lt;- rnorm(2*n, 50, 10)\n  time_pre &lt;- time_post + rnorm(n,  0, 5)\n  \n  control_pre  &lt;- time_pre[1:n] \n  tratamiento_pre  &lt;- time_pre[(n+1):(2*n)]\n  control_post &lt;- time_post[1:n] \n  tratamiento_post &lt;- time_post[(n+1):(2*n)] + beta_T\n  \n  data &lt;- tibble(tiempo_pre = c(control_pre, tratamiento_pre),\n                     tiempo_post = c(control_post, tratamiento_post),\n                     condicion = d)\n  \n  model_postets_only &lt;- lm(data = data, tiempo_post ~ condicion, model = T)\n  betapostest &lt;- c(betapostest, coef(model_postets_only)[2])\n  \n  model_pre_postets &lt;- lm(data = data, tiempo_post ~ condicion + tiempo_pre, model = T)\n  betaprepostest &lt;- c(betaprepostest, coef(model_pre_postets)[2])\n}\n\nbetas &lt;- tibble(beta = c(betapostest, betaprepostest),\n                modelo = c(rep(\"Posttest only\", 1000), rep(\"Pretest-posttest\", 1000)))\n\nmean_beta &lt;- betas |&gt;\n  group_by(modelo) |&gt;\n  summarise(m_beta = mean(beta)) |&gt;\n  mutate(ypos = c(50, 100))\n\nbetas |&gt;\n  ggplot(aes(x = beta, fill = modelo)) +\n  geom_histogram(alpha = .5,\n                 bins = 30,\n                 position = \"identity\") +\n  geom_vline(data = mean_beta,\n             aes(xintercept = m_beta, \n                 color = modelo), \n             linewidth = 1) +\n  geom_label(data = mean_beta,\n            aes(label = paste(\"Efecto promedio =\", round(m_beta,2)),\n                y = ypos),\n            x = 5,\n            show.legend=FALSE)  +\n  scale_color_manual(values = c(\"#1380A1\", \"#ED6A5A\")) +\n  scale_fill_manual(values = c(\"#1380A1\", \"#ED6A5A\")) +\n  labs(x = \"Estimaci√≥n del efecto del tratamiento\",\n       y = NULL,\n       fill = NULL,\n       color = NULL) +\n  theme_bw() +\n  theme(legend.position = \"top\")\n\n\n\n\n\n\n\n\n\nAc√° viene lo importante. Podemos ver que cuando incluimos la medici√≥n del tiempo pre en el modelo, la distribuci√≥n de las estimaciones de \\(\\beta_T\\) es m√°s angosta. Esto significa que la variabilidad de las estimaciones es menor y que el error est√°ndar de la estimaci√≥n del efecto del tratamiento es menor. En otras palabras, al incluir la medici√≥n pre en el modelo, estamos reduciendo la varianza no explicada por el modelo y, por lo tanto, mejorando la precisi√≥n de nuestras estimaciones y con ella la potencia estad√≠stica de nuestro test.\nDe hecho, para \\(n\\) infinito podemos escibir una relaci√≥n entre las varianzas no explicadas por los modelos que incluyen o no la tiempo pre. De lo que estamos hablando es de \\(\\sigma_\\epsilon^2\\) en ambos modelos, es decir, la varianza del t√©rmino de error.\n\\[\n\\sigma^2_{\\epsilon \\,pre-post} = \\sigma^2_{\\epsilon \\, post} (1 - \\rho_{pre-post}^2)\n\\]\nDonde \\(\\sigma^2_{\\epsilon \\,pre-post}\\) es la varianza del t√©rmino de error en el modelo que incluye la medida pre y \\(\\sigma^2_{\\epsilon \\, post}\\) es la varianza del t√©rmino de error en el modelo que no incluye la medida pre. \\(\\rho_{pre-post}\\) es la correlaci√≥n entre las medidas pre y post. Esta relaci√≥n nos dice que al incluir la medida pre en el modelo, estamos reduciendo la varianza del t√©rmino de error en un porcentaje igual a \\(1 - \\rho_{pre-post}^2\\). Esto significa que cuanto mayor sea la correlaci√≥n entre las medidas pre y post, mayor ser√° la reducci√≥n de la varianza del t√©rmino de error y, por lo tanto, mayor ser√° la mejora en la precisi√≥n de nuestras estimaciones y la potencia estad√≠stica de nuestros tests.\nEsta relaci√≥n para n infinito podemos verla gr√°ficamente en la siguiente figura. En la figura se muestra la relaci√≥n entre la correlaci√≥n entre las medidas pre y post y el error est√°ndar de la estimaci√≥n del efecto del tratamiento.\n\n\nVer el c√≥digo\nerrores &lt;- tibble(rho = seq(0, 1, 0.01),\n                  sigma_Ancova = (1-rho^2))\n\nerrores %&gt;% ggplot(aes(x = rho,\n           y = sigma_Ancova)) +\n  geom_line(linewidth = 1) + \n  geom_hline(yintercept = c(0,1), linetype = \"dashed\") +\n  labs(x = \"Correlaci√≥n entre pre y post\",\n       y = \"Error est√°ndar de la estimaci√≥n del efecto del tratamiento\") +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nPodemos ver que con correlaci√≥n \\(1\\) entre las medidas pre y post la potencia ser√≠a infinita, pero bueno, recordemos que esto es para n infinito.",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Experimentos aleatorios</span>"
    ]
  },
  {
    "objectID": "matching.html",
    "href": "matching.html",
    "title": "6¬† Subclasificaci√≥n y matching",
    "section": "",
    "text": "6.1 Subclasificaci√≥n",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Subclasificaci√≥n y *matching*</span>"
    ]
  },
  {
    "objectID": "index.html#lo-que-vas-a-aprender-en-este-libro",
    "href": "index.html#lo-que-vas-a-aprender-en-este-libro",
    "title": "Dise√±os experimentales y cuasiexperimentales",
    "section": "Lo que vas a aprender en este libro",
    "text": "Lo que vas a aprender en este libro\nEl objetivo de este libro es acercar a los lectores y lectoras los conceptos b√°sicos del dise√±o experimental y cuasiexperimental para que de esta manera sean capaces de dise√±ar sus propios experimentos para expresar y verificar efectivamente hip√≥tesis cient√≠ficas. Asimismo se busca generar intuiciones que les permitan evaluar dise√±os experimentales con los que se puedan encontrar tanto en la literatura cient√≠fica como en cualquier dato obtenido experimentalmente que se les presente al momento de tomar una decisi√≥n.\nSe espera que los lectores y lectoras sean capaces de comunicar los dise√±os experimentales, sus resultados y las implicancias de los mismos de manera clara, concisa y ‚Äúapta para todo p√∫blico‚Äù. As√≠mismo, un concepto transversal es que no siempre es posible implementar un dise√±o experimental ‚Äúideal‚Äù (si este existiera) y que tomar decisiones informadas sobre los mismos (modelos estad√≠sticos, m√©tricas, dise√±os, etc.) es una parte importante de nuestra labor como generadores de evidencia o tomadores de decisi√≥n basada en evidencia.\n\n\n\n\n\n\nSIGA SIGA‚Ä¶\n\n\n\nSi bien los ejemplos que se presentan en el libro est√°n orientados a las ciencias del comportamiento, su contenido puede ser adaptado a cualquier ciencia experimental, desde la biolog√≠a hasta la econom√≠a.",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#qu√©-es-este-libro",
    "href": "index.html#qu√©-es-este-libro",
    "title": "Dise√±os experimentales y cuasiexperimentales",
    "section": "¬øQu√© es este libro?",
    "text": "¬øQu√© es este libro?\nEn este libro no vas a encontrar grandes desarrollos te√≥ricos ni ejemplos complejos. Es simplemente una gu√≠a de lectura que tiene como objetivo ser la puerta de entrada para algunos conceptos clave del dise√±o experimental y la inferencia causal. Para esto vamos a chapotear en R y tidyverse, mojar las patas en la estad√≠stica, aguantar un poco la respiraci√≥n en inferencia y potential outcomes, bucear en dise√±os aleatorizados (experimentos) para finalmente sumergirnos (con la idea de volver a salir a flote) en las profundas aguas del dise√±o cuasiexperimental y la inferencia causal.",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#lo-que-no-vas-a-aprender-en-este-libro",
    "href": "index.html#lo-que-no-vas-a-aprender-en-este-libro",
    "title": "Dise√±os experimentales y cuasiexperimentales",
    "section": "Lo que NO vas a aprender en este libro",
    "text": "Lo que NO vas a aprender en este libro\nEste libro no es un libro de inferencia estad√≠stica y no vamos a hablar de tests estad√≠sticos sino en el contexto de una hip√≥tesis cient√≠fica y de un dise√±o experimental en particular. Es decir, este libro NO es un manual de estad√≠stica. Existen cientos de libros que desarrollan en detalle esos contenidos y para nada este libro pretende cubrir esos contenidos.\nEste libro tampoco es un manual de programaci√≥n ni de an√°lisis de datos en R. Si bien en la primera secci√≥n del libro haremos una presentaci√≥n de algunas de las funcionalidades de la colecci√≥n de paquetes para an√°lisis de datos que es el tidyverse, no vamos a repasar ninguna de las bases de R ni de Rstudio. Existen infinidad de recursos invre√≠bles para aprender esto y sentimos que no hay necesida de, a eso, sumarle uno mediocre.",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#prerequisitos",
    "href": "index.html#prerequisitos",
    "title": "Dise√±os experimentales y cuasiexperimentales",
    "section": "Prerequisitos",
    "text": "Prerequisitos\nPara sacarle el jugo a los contenidos de este libro hace falta tener conocimientos b√°sicos de probabilidad y estad√≠stica as√≠ como estar familiarizado con la programaci√≥n en R. Ninguno de estos son obst√°culos hoy en d√≠a ya que hay cientos de fuentes (libros, cursos, etc.) a las que el lector puede consultar previo o durante la lectura de este libro.\n\n\n\n\n\n\nDON‚ÄôT PANIC\n\n\n\nEl libro comienza con un breve repaso de conceptos b√°sicos de probabilidad y estad√≠stica y presenta los comandos b√°sicos para correr c√≥digos en R.",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#agradecimientos",
    "href": "index.html#agradecimientos",
    "title": "Dise√±os experimentales y cuasiexperimentales",
    "section": "Agradecimientos",
    "text": "Agradecimientos\nAgradecemos profundamente a Magdalena Cobb, Juan Cruz Menutti y Teresa Laszeki, alumnos asistentes de investigaci√≥n de la clase 2025, por su colaboraci√≥n en la revisi√≥n de los contenidos y la edici√≥n del libro. Tambi√©n a los alumnos de la clase 2024 y 2025 por sus comentarios y sugerencias durante el desarrollo del libro.",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#contacto",
    "href": "index.html#contacto",
    "title": "Dise√±os experimentales y cuasiexperimentales",
    "section": "Contacto",
    "text": "Contacto\nAnte cualquier duda pueden contactarme v√≠a e-mail a ispiousas@udesa.edu.ar.",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#licencia",
    "href": "index.html#licencia",
    "title": "Dise√±os experimentales y cuasiexperimentales",
    "section": "Licencia",
    "text": "Licencia\nEste sitio web es y siempre ser√° gratuito, licencia bajo [CC BY-NC-ND 3.0 License]{https://creativecommons.org/licenses/by-nc-nd/3.0/us/}.",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "var_instrumentales.html",
    "href": "var_instrumentales.html",
    "title": "9¬† Variables instrumentales",
    "section": "",
    "text": "9.1 Historia de las Variables Instrumentales: Padre e Hijo\nLa historia de las variables instrumentales est√° entrelazada con la vida de Philip Wright (nacido en 1861, fallecido en 1934) y su hijo, Sewall Wright (nacido en 1889). Philip fue un prol√≠fico autor en econom√≠a, publicando en revistas destacadas como Quarterly Journal of Economics y American Economic Review. Un tema recurrente en sus publicaciones fue el problema de identificaci√≥n, que busc√≥ resolver intensamente.\nEn 1928, Philip estaba escribiendo un libro sobre aceites animales y vegetales, motivado por la creencia de que los recientes aumentos arancelarios estaban da√±ando las relaciones internacionales. Este libro se convertir√≠a en un cl√°sico, no por su contenido sobre aranceles, sino por contener la primera prueba de la existencia de un estimador de variables instrumentales. El c√°lculo del estimador de variables instrumentales se desarroll√≥ en un ap√©ndice (Ap√©ndice B) de este libro. Philip agradeci√≥ a su hijo por sus valiosas contribuciones, refiri√©ndose al an√°lisis de rutas que Sewall le hab√≠a ense√±ado, el cual jug√≥ un papel clave en el Ap√©ndice B.\nSewall Wright, por su parte, revolucionaba el campo de la gen√©tica, inventando el an√°lisis de rutas, precursor de los modelos gr√°ficos ac√≠clicos dirigidos de Pearl. Historiadores han debatido la autor√≠a del Ap√©ndice B, ya que pudo haber sido escrito por cualquiera de los dos, dado que el libro era de econom√≠a (Philip) pero usaba el an√°lisis de rutas (Sewall). Stock y Trebbi (2003) utilizaron un an√°lisis estilom√©trico para determinar la autor√≠a, un m√©todo similar a las t√©cnicas contempor√°neas de aprendizaje autom√°tico. Recopilaron escritos conocidos de ambos hombres, y analizaron la frecuencia de 70 palabras de funci√≥n y 18 construcciones gramaticales en bloques de 1,000 palabras. Sus resultados, basados en un an√°lisis de regresi√≥n, atribuyeron todos los bloques del Ap√©ndice B y el cap√≠tulo 1 a Philip, no a Sewall.\nAunque la redacci√≥n y la soluci√≥n del problema de identificaci√≥n son t√©cnicamente distintas, esta historia destaca que un estimador econom√©trico tan importante como las variables instrumentales tiene sus ra√≠ces en la econom√≠a. Tambi√©n resalta la posibilidad de superar diferencias a trav√©s de colaboraciones intelectuales entre padre e hijo.",
    "crumbs": [
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Variables instrumentales</span>"
    ]
  },
  {
    "objectID": "reg_discontinua.html",
    "href": "reg_discontinua.html",
    "title": "8¬† Regresi√≥n discontinua",
    "section": "",
    "text": "8.1 El problema de controlar por variables no observables\nEn la mayor√≠a de los cap√≠tulos anteriores, vimos formas de controlar por confusores observables. Cuando hablamos de DAGs y agregar variables como covariables a un modelo de regresi√≥n o cuando usamos alg√∫n estimador de subclasificaci√≥n o matching, lo que estamos haciendo es aislar la variabilidad debida a confusores observados y sustraerla de nuestra relaci√≥n causal. Pero, ¬øQu√© pasa cuando los confusores por los que queremos controlar no son observables? Una respuesta a esta pregunta la tuvimos en el cap√≠tulo de diferencias en diferencias en el que vimos que, para un problema de una forma en particular1, la soluci√≥n era estimar el contraf√°ctico con un grupo comparable.\nLa soluci√≥n que vamos a proponer en este cap√≠tulo, al igual que en diferencias en diferencias, utiliza el contexto de mi cuasiexperimento para aislar el efecto causal.",
    "crumbs": [
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Regresi√≥n discontinua</span>"
    ]
  },
  {
    "objectID": "diff_in_diff.html",
    "href": "diff_in_diff.html",
    "title": "7¬† Diferencias en diferencias",
    "section": "",
    "text": "En construcci√≥n üöß",
    "crumbs": [
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Diferencias en diferencias</span>"
    ]
  },
  {
    "objectID": "intro_stat.html",
    "href": "intro_stat.html",
    "title": "2¬† Repaso de probabilidad y estad√≠stica",
    "section": "",
    "text": "2.1 Variables aleatorias\nWasserman(Wasserman 2004) nos dice que una variable aleatoria es un mapeo entre el espacio de eventos y los n√∫meros reales (\\(X:\\Omega \\rightarrow \\mathbb{R}\\)). Momento cerebrito ¬øEsto que quiere decir? En t√©rminos pr√°cticos, lo que implica esta definici√≥n es que una variable aleatoria nos da un n√∫mero para cada evento del posible espacio de eventos.\nVamos con un ejemplo. Supongan que tiramos una moneda justa dos veces y tenemos la variabla aleatoria \\(X\\) que cuenta la cantidad de caras (H)1. Los posibles eventos \\(\\omega\\) del espacio de eventos \\(\\Omega\\) son \\(\\Omega = \\{ TT, TH, HT, HH \\}\\). En este caso, la variable aleatoria \\(X\\) va a tomar los valores \\(X = \\{ 0, 1, 1, 2\\}\\) para cada \\(\\omega\\). Esto, en resumidas cuentas, es lo que hace una variable aleatoria.\nEl ejemplo anterior se trata de una variable aleatoria discreta, es decir, que s√≥lo puede tomar algunos valores posibles, pero tambi√©n existen variables aleatorias continuas como por ejemplo la altura de una nueva persona que nace.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Repaso de probabilidad y estad√≠stica</span>"
    ]
  },
  {
    "objectID": "exp_aleatorios.html#falta-de-cumplimiento-del-tratamiento-asignado",
    "href": "exp_aleatorios.html#falta-de-cumplimiento-del-tratamiento-asignado",
    "title": "5¬† Experimentos aleatorios",
    "section": "5.6 Falta de cumplimiento del tratamiento asignado",
    "text": "5.6 Falta de cumplimiento del tratamiento asignado\nEn este cap√≠tulo vimos como los experimentos aleatorios deber√≠an ser idealmente pero que la realidad a veces tiene otros planes. Hasta ahora hemos visto que los sujetos pueden no distribuirse aleatoriamente a trav√©s de una variable, por ejemplo, temporal (y debemos solucionarlo con una aletorizaci√≥n por bloques), puede ser que interpretemos inadecuadamente la cadena causal (el reverse causation bias) e incluso puede pasar que los sujetos del grupo control se contamine indirectamente con la intervenci√≥n (el spillover). Pero ninguno de estos escenarios explica un tercer problema, ¬øqu√© pasa si los individuos no siguen la intervencion que se le propone (la del grupo tratamiento o del grupo control)? Esta situaci√≥n se llama ‚Äúincumplimiento‚Äù (o no adherencia) a la asignaci√≥n del tratamiento\nHay dos tipos de no-adherencia:\n\nParticipantes no-shows: esta condici√≥n sucede cuando los participantes asignados aleatoriamente a la condici√≥n de tratamiento podr√≠an negarse a recibir el tratamiento, no presentarse a la sesi√≥n de tratamiento o preferir el tratamiento de comparaci√≥n y buscarlo en lugar del tratamiento experimental al que hab√≠an sido asignados. En otras palabras son sujetos que siguiendo la notaci√≥n de potential outcomes,s er√≠an: \\(D_0 T_1\\) 14\nParticipantes crossovers: en estos casos la condici√≥n es opuesta, algunos participantes asignados aleatoriamente a la condici√≥n de comparaci√≥n podr√≠an enterarse del tratamiento y, de alguna manera, conseguir entrar a la condici√≥n de tratamiento o recibir un tratamiento similar fuera del √°mbito del estudio. O bien, los investigadores (motivados por otras causas externas al dise√±o) podr√≠an violar el protocolo de asignaci√≥n aleatoria y exponer a algunos participantes a la condici√≥n de tratamiento que originalmente estaban asignados a la condici√≥n de comparaci√≥n. O sea \\(D_1 T_0\\)\n\n\n14¬†Recordemos que en la notacion de potential outcomes definiamos \\(D\\) a recibir el tratamiento y \\(T\\) al grupo que estaba asignados.\n\n\n\n\n\nCrossovers vs spillovers\n\n\n\nEn este punto es probable que esten confundiendo estos dos t√©rminos. Clarifiquemos. La diferencia puede parecer sutil pero en el spillover se vulnera la separaci√≥n entre los grupos, por lo que la intervenci√≥n contamina sujetos del grupo control pero este efecto es indirecto (es posible que el sujeto reciba la intervenci√≥n parcial, o si la condici√≥n de control es otro tratamiento, termine con recibiendo dos intervenciones -la de su grupo y aquella con la que se contamino-). En cambio en el crossover hay una reasignaci√≥n no intencionada o violaci√≥n del protocolo, un sujeto asignado al grupo control, pasa al grupo de tratamiento.\nTratemos de resumir las diferencias en esta tabla:\n\n\n\n\n\n\n\n\n\nCrossover\nSpillover\n\n\n\n\n¬øQui√©n cambia?\nEl participante recibe otra condici√≥n, es el equivalente a cambiar de grupo\nEl participante no cambia de grupo\n\n\n¬øQu√© falla?\nLa adherencia al grupo asignado\nEl aislamiento entre grupos\n\n\n¬øPor qu√© se produce?\nViolaci√≥n del protocolo\nInfluencias indirectas entre participantes\n\n\n\n\n\nComo habiamos visto anteriormente los spillovers comprometen la condicion SUTVA sobre la que se asienta la estimaci√≥n del ATE como una diferencia entre los outcomes de ambos grupos. En este caso la no adherencia compromete la validez interna, ya que puede sesgar las estimaciones de los efectos del tratamiento. Para mantener la comparabilidad de los participantes en las condiciones de tratamiento, lo mejor es tratar de minimizar el incumplimiento de los protocolos de tratamiento.\nSe pueden implementar varias estrategias para impedir que esto ocurra, por ejemplo:\n\nHacer ambos grupos atractivos. La tentaci√≥n inicial a la hora de dise√±ar un experimento es que el grupo control no reciba absolutamente nada. Esto hace que los individuos en el grupo control r√°pidamente se sientan a disgusto ya que esperan algo de beneficio en el participar y busquen moverse al grupo tratamiento.\nTratar de hacer ambos grupos ‚Äúf√°ciles de seguir‚Äù para los participantes. En ocasiones el grupo tratamiento tiene que seguir un mont√≥n de tareas, mientras que el grupo control s√≥lo unas pocas. Este escenario hace que muchos sujetos se desanimen en el grupo tratamiento y se conviertan en no-shows.\nAsegurarse antes de la asignacion que los individuos ser√°n capaces de cumplir con cualquiera de las intervenciones. Es importante hacer el compromiso expl√≠cito con los sujetos que van a completar la intervenci√≥n, no obstante los criterios de exclusi√≥n deben dise√±arse concienzudamente para eliminar a aquellos sujetos que no van a poder cumplir con ella. Por ejemplo, es poco probable que un sujeto con un trabajo de \\(8\\) horas diarias pueda cumplir con una intervencion de \\(6\\) horas de caminata diaria.\n\nDijimos que vamos a tratar de evitar la falta de cumplimiento, no obstante trabajamos con seres humanos y es muy probable que podamos minimizar este hecho pero vaya a seguir ocurriendo. En estas condiciones el ATE no puede ser estimado como SDO porque no todos los sujetos asignados a cada grupo cumpli√≥ a rajatabla. Pero no desesperen que hay alternativas.\n\n5.6.1 Estrategias para estimar el ATE en no cumplimiento\n\n5.6.1.1 An√°lisis tratamiento como recibido\nPensemos en los escenarios planteados previamente, cuando se dan no-shows y crossovers decimos que los sujetos ‚Äúse cambian de grupo‚Äù al recibir o no recibir el tratamiento. Si eso ocurre ¬øno ser√≠a l√≥gico analizar a los sujetos de acuerdo al tratamiento recibido en el grupo que corresponde?\nA ver formalicemos un poco el escenario. En los an√°lisis por tratamiento recibido, se conforman dos nuevos grupos: a) un grupo tratamiento que contiene a los \\(D_1 T_1\\) (asignados al tratamiento y que recibieron el tratamiento) y a los \\(D_1 T_0\\) (los asignados a la condicion control que recibieron el tratamiento, los crossover) y b) un grupo control conformado por los \\(D_0 T_0\\) y por los \\(D_0 T_1\\) (los asignados al grupo tratamiento que decidieron no hacerla o se pasaron al control, es decir los no-shows)\nParece l√≥gico pero cual es el problema. Bueno el problema radical de este enfoque es que ocurre despu√©s de la asignaci√≥n aleatoria, entonces pueden existir diferencias sistem√°ticas entre los grupos.\nPensemos esto con un ejemplo. Supongamos que un estudio quiere probar el efecto de una nueva droga contra el c√°ncer de pulm√≥n. Al asignar aleatoriamente a los grupos existen sujetos con distinto grado de severidad de la enfermedad en ambos grupos. No obstante los sujetos con mayor severidad del grupo control est√°n muy preocupados por su enfermedad y deciden buscar el tratamiento por su cuenta (se pasan al grupo tratamiento), creando una diferencia sistem√°tica. Ahora el grupo tratamiento tiene sujetos con cuadros cl√≠nicos m√°s severos. Sabemos que los sujetos con cuadros m√°s severos progresan peor, entonces, si el tratamiento es efectivo, esta an√°lisis tiende a subestimar el efecto de la droga. Tambi√©n este an√°lisis es suceptible de incluir un sesgo de causalidad reversa (revisen la secci√≥n correspondiente).\n\n\n5.6.1.2 An√°lisis por protocolo\nEste an√°lisis es otro enfoque que, aunque puede parecer atractivo a simple vista, no se recomienda. Este an√°lisis compara √∫nicamente a quienes completaron los protocolos de tratamiento tal como les fueron asignados originalmente o sea a los \\(D_1 T_1\\) (en el grupo tratamiento) y \\(D_0 T_0\\) (en el grupo control),los sujetos \\(D_1 T_0\\) y los \\(D_0 T_1\\) son directamente exclu√≠dos de todo an√°lisis.\nEste an√°lisis tiene el mismo problema que el enfoque anterior. ¬øPor qu√©?, porque vuelve a generar diferencias sistem√°ticas entre los grupos. Hay que pensar que los sujetos no abandonan uno u otro grupo de forma aleatoria (como la que gener√≥ los grupos) sino por condiciones claves (muchas veces relacionadas con la misma asignaci√≥n al grupo) como vimos en el ejemplo anterior. De esta manera los grupos controles pueden perder a por ejemplo sujetos con cuadros m√°s severos, porque estos deciden pasarse a tratamiento, o el grupo tratamiento perder a sujetos con poca respuesta al tratamiento, porque ante la baja respuesta deciden abandonar y pasarse al grupo control. De esta forma y dependiendo el caso este enfoque tiene a subestimar o sobrestimar el efecto. No se aconseja su uso.\n\n\n\n5.6.2 Enfoque por intencion de tratamiento\nTambi√©n llamado intention-to-treat este enfoque es el que se prefiere por encima de cualquier otro. En los otros dos vimos que la asignaci√≥n o la exclusion de un grupo post-aleatorizacion genera errores sistem√°ticos que contaminan la estimaci√≥n del efecto y pueden abrir una puerta al sesgo de causalidad reversa. Entonces la mejor soluci√≥n es sencillamente no modificar la situaci√≥n de los sujetos post aletorizaci√≥n, o sea este enfoque. El lema de este enfoque es anal√≠zalos como los aleatorizaste es decir en el grupo control se incluyen a todos los sujetos asignados aleatoriamente al grupo control (\\(T_0\\)) independiente si recibieron la intervenci√≥n o no (cualquier estado de \\(D\\)) y en el grupo tratamiento todas los \\(T_1\\) igualmente.\nCuando hacemos este enfoque, la estimaci√≥n del efecto cobra otra realidad y la llamamos estimaci√≥n de la intenci√≥n de tratamiento (o estimate ITT) y tiene la siguiente forma:\n\\[ \\text{ITT estimate} = \\bar{Y}_T - \\bar{Y}_C \\ \\]\ndonde \\(\\bar{Y}_T\\) es el resultado medio para el grupo de tratamiento seg√∫n fue originalmente asignado, y \\(\\bar{Y}_C\\) es el resultado medio para el grupo de comparaci√≥n seg√∫n fue originalmente asignado.\nLa estimaci√≥n ITT tiene la ventaja de comparar participantes que son aleatoriamente equivalentes. Pero puede ser dif√≠cil de interpretar, dado que es el efecto promedio de haber ofrecido el tratamiento en comparaci√≥n con no haberlo ofrecido, m√°s que el efecto promedio del tratamiento si todos hubieran recibido el protocolo de tratamiento asignado.\nPongamos un ejemplo, se asigna a sujetos a comer salm√≥n tres veces por semana para bajar el colesterol, esta intervenci√≥n tiene un efecto real de reducir el colesterol en un \\(20%\\) (este ser√≠a el ATE en un mundo ideal). Pero sucede que al aplicar la intervenci√≥n la mitad de los sujetos no consumen el salm√≥n (o sea que son no-shows), ellos no tienen un efecto, o sea que tienen un \\(0%\\) de cambio. Si hacemos un an√°lisis de ITT; la media de cambio en los sujetos asignados al grupo tratamiento (\\(\\bar{Y}_T\\) ) es del \\(10%\\) (la mitad cambio un \\(20%\\) y la otra mitad \\(0%\\)) y la media de cambio del otro grupo (el control,\\(\\bar{Y}_C\\) ) es \\(0%\\) (no incluimos crossover en este ejemplo para no complicarnos). O sea que el estimador ITT es del \\(10%\\). El efecto es menor, ¬øpor qu√© este enfoque es mejor?\nBueno por un par de razones:\n\nNo hay errores en la direccion de la cadena causal, nuestro objetivo es evaluar como un tratamiento (causa) genera un efecto. Como vimos en los enfoques anteriores, al ocurrir un cambio de grupo despu√©s de la aletorizaci√≥n es frecuente que este cambio est√© motivado por el efecto mismo de la intervenci√≥n (una intervenci√≥n que no funciona motiva a que los sujetos se pasen al grupo control, o una intervenci√≥n muy eficaz seduce al grupo control a pasarse a la intervenci√≥n) de esta manera la cadena causal se invierte y es el efecto el que genera el tratamiento o no de los sujetos. Al analizar los sujetos como fueron asignados no existe una puerta de atr√°s abierta a la reversi√≥n de la causalidad.\nPuede ser m√°s relevante calcular el ITT que el ATE, sobretodo en pol√≠ticas p√∫blicas o en intervenciones con humanos, el grupo investigador (y el grupo que aplicar√° los resultados) s√≥lo pueden llegar al grado de una recomendaci√≥n, es decir por ejemplo, le dicen a un grupo de personas que coman salm√≥n tres veces por semana, no se lo meten en la boca. Pensemos en nuestro ejemplo anterior, el gobierno de Bolivia quiere iniciar una campa√±a de concientizaci√≥n de la dieta y quiere reducir el colesterol de la poblaci√≥n indic√°ndole comer salm√≥n. En el pa√≠s es muy caro el salm√≥n asi que pese a la sugerencia la mitad de la poblaci√≥n no puede comprarlo, el efecto de esta campa√±a se parecer√° m√°s al ITT o al ATE. Exacto, el ITT es un mejor estimador de los escenarios del mundo real (que al fin al cabo es lo qu√© queremos explicar) porque si una intervenci√≥n es muy buena pero no la pueden recibir todos los sujetos a los que se la asignan (por que es muy cara, o porque da efectos adversos, o miles de causas m√°s), bueno no es tan buena.",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Experimentos aleatorios</span>"
    ]
  },
  {
    "objectID": "matching.html#subclasificaci√≥n",
    "href": "matching.html#subclasificaci√≥n",
    "title": "6¬† Subclasificaci√≥n y matching",
    "section": "",
    "text": "6.1.1 ¬øPor qu√© subclasificar? Motivaci√≥n y objetivo\nEn estudios observacionales la asignaci√≥n al ‚Äútratamiento‚Äù muchas veces ocurre de forma completamente no aleatoria. Por ejemplo, supongamos que queremos medir el efecto de ofrecer un descuento en la cantidad de ventas de tiendas, pero el descuento se aplic√≥ principalmente en aquellas regiones donde las ventas siempre fueron m√°s bajas.\nSi s√≥lo comparamos el promedio de ventas de tiendas con descuento frente a las que no lo recibieron, el resultado estar√° sesgado, porque la asignaci√≥n del ‚Äútratamiento‚Äù (el descuento) no fue aleatoria. Es decir, el efecto reflejar√° tanto el descuento como las caracter√≠sticas de la regi√≥n.\nEl objetivo de la subclasificaci√≥n es, entonces, estimar el efecto causal del descuento como si la asignaci√≥n hubiera sido aleatoria dentro de cada regi√≥n. Para ello, se divide el conjunto de tiendas en estratos seg√∫n la regi√≥n, se calcula la diferencia de ventas entre tiendas con y sin descuento en cada estrato, y luego se combinan esos efectos de forma ponderada. De este modo, se logra balancear la comparaci√≥n y acercarse a un estimador no sesgado del efecto promedio del descuento.\n\n\n6.1.2 Independencia vs.¬†independencia condicional\nHablamos de independencia, cuando tenemos un experimento con asignaci√≥n completamente aleatoria:\n\\[\nD \\perp (Y_0,Y_1)\n\\]\nEs decir, la decisi√≥n de asignar a tratamiento o no (D) es independiente de los potential outcomes, y por lo tanto la diferencia de medias entre tratados y controles ofrece una estimaci√≥n v√°lida del ATE.\nSin embargo, en muchos cuasiexperimentos la ‚Äúaleatorizaci√≥n‚Äù s√≥lo ocurre condicional a alguna caracter√≠stica observable X. Esto nos lleva a la asunci√≥n de independencia condicional (CIA1), que podemos escribir como:\n1¬†Del ingl√©s Conditional Independence Assumption.\\[\nD \\perp (Y_0,Y_1) | X\n\\]\nO sea, una vez que fijamos X, la asignaci√≥n al tratamiento se comporta como si fuera aleatoria.\nEn estudios observacionales como el de las tiendas y descuentos, la regi√≥n (X) influye tanto en la probabilidad de recibir descuento (\\(D\\)) como en las ventas (\\(Y\\)), lo que genera un camino en el que \\(X\\) es confusor (\\(D \\leftarrow X \\rightarrow Y\\)). Si ignoramos esa ruta, la comparaci√≥n global de medias mezclar√° el efecto real del descuento con las diferencias regionales, produciendo un sesgo.\nPara entender por qu√© la subclasificaci√≥n corrige esto, podemos representar el problema en un DAG:\n\n\n\n\n\nDAG que representa la relaci√≥n entre D e Y teniendo a A como confusor.\n\n\n\n\nAl condicionar en \\(X\\) (es decir, subclasificar o estratificar por regi√≥n), cerramos el backdoor \\(D \\leftarrow X \\rightarrow Y\\). Dentro de cada regi√≥n, la asignaci√≥n del descuento ya no est√° correlacionada con las ventas antes del tratamiento.\n\n\n6.1.3 El estimador de subclasificaci√≥n: Un ejemplo con descuento\n¬øC√≥mo aplicamos esta idea de la subclasificaci√≥n a un ejemplo real? Bueno, empecemos con un ejemplo ‚Äúreal‚Äù.\nSupongamos que tenemos una distribuidora de gaseosas en el Gran Buenos Aires. Queremos medir el efecto de ofrecer un descuento a los clientes en las ventas. Este es un descuento que se le da s√≥lo a algunos clientes, pero sabemos que la asignaci√≥n del descuento es aleatoria, pero s√≥lo dentro de cada regi√≥n. Esto pas√≥ porque el jefe, muy astutamente dijo ‚Äú¬øY si les ofrecemos m√°s descuentos a la regi√≥n que menos compra?‚Äù. Los clientes que menos compran son los del oeste(compra promedio $\\(2000\\)), y por eso tienen una \\(p=0.8\\) de recibir el descuento. Los del norte (compra promedio $\\(3500\\)) tienen una \\(p=0.2\\) y los del este (compra promedio $\\(3000\\)) una \\(p=0.5\\). Tambi√©n es relevante para el problema que algunas zonas tienen m√°s clientes que otras, por ejemplo, el oeste tiene \\(220\\) clientes, el norte \\(500\\) y el este s√≥lo \\(130\\).\nComo todas las simulaciones que hicimos a lo largo del libro (si es que a esto se le puede llamar libro) conocemos el tama√±o del efecto que queremos estimar y tiene como valor medio $\\(300\\). Otra cosa a la que vamos a poder ecceder es a ambos potential outcomes, es decir, tanto al observado como al contraf√°ctico (si es que a esto se le puede llamar contraf√°ctico). Estos son lujos que nos podemos dar (si es que a esto se le puede llamar un lujo). Veamos \\(5\\) filas al azar de los datos simulados.\n\n\nVer el c√≥digo\n# Simulaci√≥n de los datos ####\nset.seed(1989)\n\nn_este &lt;- 130\nn_oeste &lt;- 220\nn_norte &lt;- 500\nn_total &lt;- n_este + n_oeste + n_norte\n\ncustomers &lt;-\n  tibble(\n    customer_id = seq(n_total),\n    region = c(rep(\"Este\", n_este),\n               rep(\"Oeste\", n_oeste),\n               rep(\"Norte\", n_norte)),\n    # El efecto del tratamiento es 300USD + ruido [N(300,200)]\n    treatment_effect = rnorm(n_total, mean = 300, sd = 200),\n    # Ventas por cliente cuando no se ofrece ning'un descuento (no tratado)\n    y0 = c(\n      rnorm(n_este, mean = 3000, sd = 200),\n      rnorm(n_oeste, mean = 2000, sd = 200),\n      rnorm(n_norte, mean = 3500, sd = 200)\n    ),\n    # Ventas cuando se ofrece un descuento\n    y1 = y0 + treatment_effect,\n    # El vector de asignaci√≥n de tratamiento D\n    d = c(\n      rbinom(n_este, 1, 0.5),\n      rbinom(n_oeste, 1, 0.8),\n      rbinom(n_norte, 1, 0.2)\n    ),\n    # Switching equation\n    y = y0 + treatment_effect*d\n  ) %&gt;%\n  mutate(tratamiento = if_else(d == 0, \"Control\", \"Tratamiento\"))\n\nsample_n(customers, 5) %&gt;%\n  gt::gt() %&gt;%\n  gt::tab_header(\n    title = \"Datos de clientes con descuento (5 filas al azar)\"\n  )\n\n\n\n\n\n\n\n\nDatos de clientes con descuento (5 filas al azar)\n\n\ncustomer_id\nregion\ntreatment_effect\ny0\ny1\nd\ny\ntratamiento\n\n\n\n\n241\nOeste\n338.1579\n1841.329\n2179.487\n1\n2179.487\nTratamiento\n\n\n585\nNorte\n113.7443\n3323.805\n3437.550\n0\n3323.805\nControl\n\n\n845\nNorte\n599.7978\n3735.531\n4335.329\n0\n3735.531\nControl\n\n\n347\nOeste\n468.4059\n2004.665\n2473.071\n0\n2004.665\nControl\n\n\n732\nNorte\n371.6284\n3544.635\n3916.264\n0\n3544.635\nControl\n\n\n\n\n\n\n\nLo primero que uno pensar√≠a en estos casos (aunque cualquier lector o lectora de este libro podr√≠a intuir por qu√© es incorrecto) es en tomar los sujetos del grupo tratamiento y los del control y calcular la diferencia simple entre medias (SDO). Veamos que pinta tiene eso gr√°ficamente y despu√©s calculemoslo.\n\n\nVer el c√≥digo\ncustomers %&gt;%\n  ggplot(aes(x = tratamiento, \n             y = y, \n             color = tratamiento)) +\n  geom_jitter(alpha = .3, width = .1, size = 1) + \n  stat_summary(color = \"black\", width = .4) +\n  scale_color_brewer(palette = \"Dark2\") +\n  labs(x = NULL, y = \"Ventas por mes por cliente\", color = NULL) +\n  theme_bw() +\n  theme(legend.position = \"top\")\n#&gt; Warning in stat_summary(color = \"black\", width = 0.4): Ignoring unknown\n#&gt; parameters: `width`\n#&gt; No summary function supplied, defaulting to `mean_se()`\n\n\n\n\n\n\n\n\n\n¬øPero no era que el tratamiento ten√≠a un efecto conocido de $\\(300\\)? A ver, tomemos un respiro y calculemos el SDO, recordemos c√≥mo calcularlo:\n\\[\nSDO = \\frac{1}{N_t} \\sum_{i=1}^n (y_i | d_i=1) - \\frac{1}{N_t} \\sum_{i=1}^n (y_i | d_i=0),\n\\]\no, en lenguaje computacional:\nSDO &lt;- mean(customers$y[customers$d==1]) - mean(customers$y[customers$d==0]).\nSi lo calculamos nos da efectivamente $-334. Es decir, no s√≥lo no vale $\\(300\\) sino que su valor es negativo, o sea, ofrecer un descuento disminuye las ventas. ¬øAlguna sospecha de qu√© est√° pasando? Como vimos en el cap√≠tulo [#sec-pot-outcomes], cuando las asignaciones NO son aleatorias, no podemos asegurar que el SDO sea un buen estimador del ATE. En este caso no tenemos sesgo de efecto heterog√©neo (lo sabemos porque simulamos los datos) pero qu√© opinan del sesgo de selecci√≥n. ¬øDepende acaso al asignaci√≥n al grupo tratamiento de alguno de los outcome potenciales? La respuesta es un rotundo S√ç, ya que el genio del jefe, que se ve que no sabe nada de inferencia causal, decidi√≥ condicionar la asignaci√≥n justamente a las ventas esperadas.\nVeamos ahora las ventas para grupo tratamiento y control pero por regi√≥n.\n\n\nVer el c√≥digo\ncustomers %&gt;%\n  ggplot(aes(x = tratamiento, \n             y = y, \n             color = tratamiento)) +\n  geom_jitter(alpha = .3, width = .1, size = 1) + \n  stat_summary(color = \"black\", width = .4) +\n  scale_color_brewer(palette = \"Dark2\") +\n  labs(x = NULL, y = \"Ventas por mes por cliente\", color = NULL) +\n  facet_wrap(~region) +\n  theme_minimal() +\n  theme(legend.position = \"top\")\n#&gt; Warning in stat_summary(color = \"black\", width = 0.4): Ignoring unknown\n#&gt; parameters: `width`\n#&gt; No summary function supplied, defaulting to `mean_se()`\n#&gt; No summary function supplied, defaulting to `mean_se()`\n#&gt; No summary function supplied, defaulting to `mean_se()`\n\n\n\n\n\n\n\n\n\nApa, la cosa ahora es distinta. Tal como lo esper√°bamos, en cada grupo el efecto del tratamiento es un aumento en las ventas. Lo que ocurre es una combinaci√≥n de sesgo de selecci√≥n con el tama√±o de las regiones. La regi√≥n del norte, que es la m√°s grande, tiene m√°s sujetos asignados a control, por lo tanto, los controles tienen una sobrerepresentaci√≥n de clientes que tienden a comprar m√°s. Por el contrario, la regi√≥n del oeste, que es la m√°s chica, tiene m√°s sujetos asignados al grupo tratamiento, lo cual genera una sobrerepresentaci√≥n de ratone‚Ä¶ clientes que gastan menos en el grupo tratamiento.\n¬øSe les ocurre alguna soluci√≥n elegante üé©? Claro, podemos calcular el efecto del tratamiento dentro de cada grupo (una especie de SDO local) y despu√©s vemos qu√© hacemos. Empecemos por eso.\n\n\nVer el c√≥digo\nSDO_este &lt;- mean(customers$y[customers$region==\"Este\" & customers$d==1]) - \n  mean(customers$y[customers$region==\"Este\" & customers$d==0])\n\nSDO_norte &lt;- mean(customers$y[customers$region==\"Norte\" & customers$d==1]) - \n  mean(customers$y[customers$region==\"Norte\" & customers$d==0])\n\nSDO_oeste &lt;- mean(customers$y[customers$region==\"Oeste\" & customers$d==1]) - \n  mean(customers$y[customers$region==\"Oeste\" & customers$d==0])\n\ntibble(Regi√≥n = c(\"Este\", \"Norte\", \"Oeste\"),\n       SDO = c(SDO_este, SDO_norte, SDO_oeste)) %&gt;%\n  gt()\n\n\n\n\n\n\n\n\nRegi√≥n\nSDO\n\n\n\n\nEste\n320.3419\n\n\nNorte\n303.3541\n\n\nOeste\n327.8227\n\n\n\n\n\n\n\nEfectivamente el efecto en cada regi√≥n se acerca a los $\\(300\\). Pero para hacer una √∫nica estimaci√≥n del efecto vamos a usar el estimador de subclasifiaci√≥n, que no es otra cosa que un promedio ponderado de estos SDOs por regi√≥n. Formalmente ser√≠a algo as√≠:\n\\[\n\\hat\\delta_{ATE} = \\sum_{k=1}^K SDO_k \\times \\frac{N_k}{N}  \n\\]\ndonde \\(k\\) es un √≠ndice que codifica al grupo, \\(K\\) es la cantidad total de grupos, \\(SDO_k\\) la diferencia de medias para el grupo \\(k\\), \\(N_k\\) la cantidad de individuos del grupo \\(k\\) y \\(N_t\\) la cantidad total de individuos. Un promedio pesado, bah. En lenguaje de R ser√≠a algo como:\nsubclas_estimator &lt;- SDO_este * (n_este/n_total) +   SDO_norte * (n_norte/n_total) +   SDO_oeste * (n_oeste/n_total)\nEn nuestro caso el estimador vale $312. Bastante bien, ¬øno?\nPero ¬øpor qu√© pas√≥ esto? Veamos algunas figuritas que nos ayuden a entender un poco. Para esto vamos a echar mano a la ventaja de haber generado los datos y vamos a graficar tanto el observable (\\(Y_0\\) si son grupo control o \\(Y_1\\) si son grupo tratamiento) como el contraf√°ctico (\\(Y_1\\) si son grupo control o \\(Y_0\\) si son grupo tratamiento).\n\n\nVer el c√≥digo\n# Plots de independencia ####\n# Armo un tibble para plotear\ncustomers_4_plot &lt;- customers %&gt;% \n  select(region, d, y1, y0, tratamiento) %&gt;% \n  pivot_longer(cols = c(y1, y0),\n               names_to = \"potential_outcome\",\n               values_to = \"value\")\n\n\n\n\nVer el c√≥digo\n# Independencia\nggplot(customers_4_plot) +\n  aes(potential_outcome, value, colour = tratamiento) +\n  geom_boxplot() +\n  labs(x = \"Potential Outcome\",\n       y = \"Ventas por mes por cliente\",\n       colour = \"Treatment status\",) +\n  scale_color_brewer(palette = \"Dark2\") +\n  theme_minimal() +\n  labs(color = NULL) +\n  theme(legend.position = \"top\")\n\n\n\n\n\n\n\n\n\nEn esta figura lo que estamos viendo es que la asignaci√≥n a los grupos depende fuertemente del outcome ya que podemos ver que los del grupo control tienden a tener outcomes m√°s altos tanto observado como contraf√°ctico. O sea, no se cumple la independencia (\\(D \\perp (Y_0,Y_1)\\)). Ke sad bro üôç. Ahora, ¬øQu√© pasa si vemos esto mismo pero para cada regi√≥n?\n\n\nVer el c√≥digo\n# Independencia condicional a la regi√≥n\nggplot(customers_4_plot) +\n  aes(potential_outcome, value, colour = tratamiento) +\n  geom_boxplot() +\n  facet_wrap(~region) +\n  labs(x = \"Potential Outcome\",\n       y = \"Ventas por mes por cliente\",\n       colour = \"Treatment status\",) +\n  scale_color_brewer(palette = \"Dark2\") +\n  theme_minimal() +\n  labs(color = NULL) +\n  theme(legend.position = \"top\")\n  \n\n\n\n\n\n\n\n\n\nEt voil√°, ac√° la cosa cambia. Que significa esto, que si bien el problema no tiene independencia, s√≠ podemos obtener la independencia condicional controlando por regi√≥n (\\(D \\perp (Y_0,Y_1) | Grupo\\)).\nTodo esto es muy lindo, pero que pasa si en lugar de tener grupos tenemos que esta dependencia en la asignaci√≥n depende de una variable continua o, peor a√∫n, de varias. Tranquilos amigos, matching es el camino.",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Subclasificaci√≥n y *matching*</span>"
    ]
  },
  {
    "objectID": "matching.html#matching",
    "href": "matching.html#matching",
    "title": "6¬† Subclasificaci√≥n y matching",
    "section": "6.2 Matching",
    "text": "6.2 Matching\nUna forma alternativa de lidiar con la independencia condicional y el cierre de backdoors es el matching. La idea central es f√°cil: en vez de comparar el promedio de las unidades tratadas con el promedio de todas las unidades no tratadas, buscamos comparar cada unidad tratada con una unidad no tratada que se le parezca lo m√°s posible en funci√≥n de ciertas caracter√≠sticas observables (como la edad, la regi√≥n, los ingresos, etc.) que sean confusoras de nuestra relaci√≥n causal.\nEntonces, con matching, en lugar de usar el promedio del grupo control como contrafactual, usamos un individuo que se parezca al que fue tratado.\nEsto nos permite construir un estimador que sea m√°s cre√≠ble. Es intuitivo: si queremos estimar el efecto de un curso sobre los ingresos, tiene m√°s sentido comparar a una persona de 25 a√±os que hizo el programa con otra tambi√©n de 25 a√±os que no lo hizo, en lugar de con el promedio de todas las personas que no lo hicieron. De esta manera, el matching busca que cada comparaci√≥n sea m√°s consistente, emparejando unidades comparables.\nPara esto, vamos a poder usar exact matching o approximate matching, dependiendo de cada caso.\nPensemos en un caso simple en el que tenemos s√≥lo una confusora observable \\(X\\).\nPero, ¬øpor qu√© antes compar√°bamos cada unidad tratada con el promedio de todas las unidades no tratadas?\nPara entenderlo, recordemos que en el anterior enfoque cada unidad tratada compara su resultado con la media del control. Esto ser√≠a:\n\\[\n\\widehat{\\delta}_i = Y_i - Y_{j(i)}\n\\] donde \\(Y_i\\) es el resultado observado de la unidad tratada \\(i\\), y \\(Y_{j(i)}\\) es una unidad control \\(j\\) que comparte el mismo valor de \\(X\\) que la \\(i\\) (representada por el √≠ndice \\(j(i)\\)).\nPero luego, promediamos esas diferencias individuales, y llegamos al efecto total.\n\n6.2.1 Exact Matching\nHablamos de emparejar o matchear unidades tratadas con controles lo m√°s parecidos posibles. Lo primero que uno piensa es: Si quiero comparar el efecto de una pol√≠tica p√∫blica en las apuestas online y la edad es un confusor, es razonable comparar el monto que apost√≥ una persona de \\(25\\) a√±os que estuvo expuesta a esa pol√≠tica con el monto que apost√≥ otra persona de \\(25\\) a√±os que no estuvo expuesta. Cuando buscamos una unidad control que tenga exactamente el mismo nivel de la variable confusora hablamos de exact matching. Entonces, el exact matching consiste en emparejar unidades tratadas y no tratadas que compartan exactamente los mismos valores de ciertas covariables, supongamos \\(X\\).\nEn este caso, podemos decir que el efecto en la unidad tratada \\(i\\) es la diferencia entre su resultado observado \\(Y_i\\) y el resultado contrafactual de la unidad control \\(Y_{j(i)}\\) que comparte el mismo valor de \\(X_i\\):\n\\[\n\\widehat{\\delta}_i = Y_i(D_i=1) - Y_{j(i)}\n\\] Entonces, podr√≠amos decir que el efecto promedio de las unidades tratadas [^ATT] ser√≠a lo siguiente:\n[^ATT] Que se llama ATT, ¬øse acuerdan?\n\\[\n\\widehat{\\delta}_{ATT} = \\dfrac{1}{N_T} \\sum_{i=1}^{N_T}(Y_i(D_i=1) - Y_{j(i)})\n\\]\nDonde \\(N_T\\) es el n√∫mero de unidades tratadas e \\(Y_{j(i)}\\) es el resultado de la unidad control que comparte el mismo valor de \\(X_i\\) que la unidad tratada \\(i\\).\nHasta ac√° muy lindo, pero la cosa no va a estar linda por mucho tiempo. Por ejemplo, una pregunta que alguien puede tener es: ¬øY si tenemos m√°s de un control de \\(25\\) a√±os qu√© hacemos? ¬øNos quedamos con uno de los dos? Bueno, lo m√°s razonable que podemos hacer es tomar el promedio de los resultados de los controles que coinciden con la unidad tratada. Entonces, si tenemos \\(m\\) controles que comparten el mismo valor de \\(X_i\\), el efecto individual del tratado \\(i\\) ser√≠a:\n\\[\n\\widehat{\\delta}_i = Y_i(D_i=1) - \\sum_{m=1}^{m_i} \\dfrac{1}{m_i} Y_{jm}\n\\]\nEntonces, el ATT con exact matching podemos decir que tiene esta forma:\n\\[\n\\widehat{\\delta}_{ATT} = \\dfrac{1}{N_T} \\sum_{i=1}^{N_T} \\left( Y_i(D_i=1) - \\sum_{m=1}^{m_i} \\dfrac{1}{m_i} Y_{jm} \\right)\n\\tag{6.1}\\]\ndonde \\(m_i\\) es el n√∫mero de controles que comparten el mismo valor de \\(X_i\\) que la unidad tratada \\(i\\).\n¬øSe puede calcular el ATE? Vamos a ver brevemente que s√≠, pero tambi√©n los problemas que ello conlleva.\nMiremos un ejemplo y veamos c√≥mo se calculan estas cosas. Vamos a usar los datos de un programa de capacitaci√≥n que se realiz√≥ en una empresa ficticia. En este caso, lo que queremos no es otra cosa que estimar el efecto de una capacitaci√≥n laboral en el ingreso de los empleados. Para eso, tenemos la edad del empleado, si particip√≥ o no en el programa de capacitaci√≥n y su salario. Veamos unos datos de ejemplo.\n\n\nVer el c√≥digo\ntrainees_df &lt;- read_csv(\"https://github.com/matheusfacure/python-causality-handbook/raw/master/causal-inference-for-the-brave-and-true/data/trainees.csv\",\n                        show_col_types=FALSE) %&gt;% \n  rename(Capacitaci√≥n = trainees,\n         Edad = age,\n         Unidad = unit,\n         Salario = earnings)\n\ntrainees_df %&gt;%\n  mutate(Capacitaci√≥n = factor(Capacitaci√≥n,\n                               levels = c(0, 1),\n                               labels = c(\"S√≠\", \"No\"))) %&gt;%\n  sample_n(5) %&gt;%\n  gt::gt() %&gt;%\n  gt::tab_header(\n    title = \"Datos de participantes en un programa de capacitaci√≥n (5 filas al azar)\"\n  )\n\n\n\n\n\n\n\n\nDatos de participantes en un programa de capacitaci√≥n (5 filas al azar)\n\n\nUnidad\nCapacitaci√≥n\nEdad\nSalario\n\n\n\n\n14\nNo\n24\n19700\n\n\n38\nS√≠\n35\n30200\n\n\n7\nNo\n33\n21900\n\n\n25\nS√≠\n48\n29800\n\n\n39\nS√≠\n32\n17800\n\n\n\n\n\n\n\nSi uno no hubiera le√≠do nada de este libro, se sentir√≠a tentado a calcular la diferencia entre las medias entre los que participaron y los que no. Pero, como ya sabemos, eso no es correcto porque la asignaci√≥n al tratamiento no es aleatoria. De hecho, podemos calcular ese efecto y da $-4297. Pero, ¬øqu√© pasa si vemos la relaci√≥n entre la edad, el salario y la capacitaci√≥n? ¬øPodemos ver si hay alg√∫n confusor?\n\n\nVer el c√≥digo\n# Vemos las distribuciones marginales\ntrainees_df %&gt;%\n  mutate(Capacitaci√≥n = factor(Capacitaci√≥n,\n                               levels = c(0, 1),\n                               labels = c(\"S√≠\", \"No\"))) %&gt;%\n  ggplot() +\n  aes(Edad, Salario, color = Capacitaci√≥n) +\n  geom_jitter() +\n  geom_xsidedensity(\n    aes(\n      y = after_stat(density),\n      fill = Capacitaci√≥n\n    ),\n    alpha = 0.5,\n    size = 1,\n    position = \"identity\"\n  ) +\n  geom_ysidedensity(\n    aes(\n      x = after_stat(density),\n      fill = Capacitaci√≥n\n    ),\n    alpha = 0.5,\n    size = 1,\n    position = \"identity\"\n  ) + \n  theme(\n    ggside.panel.scale.x = 0.3,\n    ggside.panel.scale.y = 0.3,\n    ggside.axis.text.y = element_blank(),\n    ggside.axis.ticks.y = element_blank(),\n    ggside.axis.text.x = element_blank(),\n    ggside.axis.ticks.x = element_blank()\n  ) +\n  scale_color_brewer(palette = \"Dark2\") +\n  scale_fill_brewer(palette = \"Dark2\") +\n  theme_minimal() +\n  labs(color = \"Capacitaci√≥n\", fill = \"Capacitaci√≥n\") +\n  theme(legend.position = \"top\")\n#&gt; Warning: `is.ggproto()` was deprecated in ggplot2 3.5.2.\n#&gt; ‚Ñπ Please use `is_ggproto()` instead.\n\n\n\n\n\n\n\n\n\nAl parecer, la gente de m√°s edad (y que naturalemte tiene m√°s salario) tiende a estar mayormente en el grupo que recibi√≥ la capacitaci√≥n. Esto es una gran red flag metodol√≥gica, ¬øno?. Bueno, lo que parece sugerir es que la edad es un confusor en la relaci√≥n causal entre la capacitaci√≥n y el salario. Entonces, bajo la suposici√≥n casi rid√≠cula pero √∫til de que el √∫nico confusor en nuestro problema es la edad. Usemos exact matching para emparejar a los participantes tratados con controles que tengan la misma edad y estimemos el ATT.\nEscribamos una funci√≥n a mano para calcular el ATT2:\n2¬†B√°sicamente es una funci√≥n que busca los puntos iguales en la covariable, calcula el promedio, los efectos individuales y el promedio final. Es decir, lo que aparece en la Ecuaci√≥n¬†6.1.\n\nVer el c√≥digo\n# Funci√≥n para estimar el ATT con matching ####\n# Extact Matching Estimator of the ATT\nexact_matching_estimator_att &lt;- function(df, #dataframe\n                                         outcome, # nombre de la variable outcome\n                                         treatment, # nombre de la variable donde est√° el tratamiento\n                                         covariates # string o vector de strings\n) {\n  \n  # Renombro la columna como outcome\n  df &lt;- df %&gt;%\n    rename(outcome := {{ outcome }}) %&gt;% \n    mutate(id = 1:n())\n  \n  # Creo un dataset s√≥lo con las unidades tratadas\n  treated_df &lt;- df %&gt;% \n    filter({{ treatment }} == 1)\n  \n  # Creo un dataset s√≥lo con las unidades NO tratadas\n  control_df &lt;- df %&gt;% \n    filter({{ treatment }} == 0)\n  \n  # Matcheo las tratadas y no tratadas para iguales valores de las covariates\n  treated_matched &lt;- treated_df %&gt;% \n    left_join(control_df, by = covariates,\n              suffix = c(\"_i\", \"_j\"))\n  \n  # El estimador\n  estimate_att &lt;- \n    treated_matched %&gt;% \n    # Promedio si hay m√°s de un match\n    group_by(id_i) %&gt;%\n    summarise(outcome_j = mean(outcome_j),\n              outcome_i = first(outcome_i)) %&gt;%\n    # Calculo las diferencias de cada unidad con su match\n    mutate(treat_effect = outcome_i - outcome_j) %&gt;% \n    # Promedio las diferencias\n    summarise(estimate_att = mean(treat_effect)) %&gt;% \n    # Me quedo con la variable\n    pull(estimate_att)\n  \n  estimate_att\n}\n\n\nY ahora lo calculamos con el siguiente c√≥digo:\n\nATT &lt;- \n  exact_matching_estimator_att(\n    trainees_df,\n    outcome = Salario,\n    treatment = Capacitaci√≥n,\n    covariates = \"Edad\")\n\n\n\nVer el c√≥digo\ntibble(M√©todo = c(\"SDO\", \"Exact Matching\"),\n       Estimaci√≥n = c(\n         round(mean(trainees_df$Salario[trainees_df$Capacitaci√≥n==1]) - \n                 mean(trainees_df$Salario[trainees_df$Capacitaci√≥n==0])),\n         round(ATT, 2))) %&gt;%\n  gt() %&gt;%\n  tab_header(\n    title = \"Estimaci√≥n del efecto de la capacitaci√≥n\"\n  )\n\n\n\n\n\n\n\n\nEstimaci√≥n del efecto de la capacitaci√≥n\n\n\nM√©todo\nEstimaci√≥n\n\n\n\n\nSDO\n-4297\n\n\nExact Matching\n2450\n\n\n\n\n\n\n\nVemos que utilizar s√≥lo la diferencia de las medias no s√≥lo era una estimaci√≥n sesgada sino que suger√≠a una direcci√≥n del efecto contraria a la obtenida con Exact Matching.\nVamos a aventurarnos a calcular el ATE. Para esto vamos a buscar controles matcheados para cada unidad tratada, y unidades tratadas matcheadas para cada control. Es decir, vamos a hacer un exact matching en ambos sentidos. Luego, vamos a calcular el efecto individual de cada unidad y vamos a calcular el promedio3. Primero definimos la funci√≥n para calcular el ATE:\n3¬†Ni me gasto en poner ecuaciones porque nos vamos a confundir m√°s de lo que ya estamos pero si quieren la pueden ver en el libro de Cunningham.\n\nVer el c√≥digo\n# Funci√≥n para estimar el ATE con matching ####\n# Extact Matching Estimator of the ATE\nexact_matching_estimator_ate &lt;- function(df, #dataframe\n                                         outcome, # nombre de la variable outcome\n                                         treatment, # nombre de la variable donde est√° el tratamiento\n                                         covariates # string o vector de strings\n) {\n  df &lt;- df %&gt;%\n    # Renombro outcome y tratemiento\n    rename(outcome := {{ outcome }},\n           treatment := {{ treatment }}) %&gt;% \n    mutate(id = 1:n())\n  \n  treated_df &lt;- df %&gt;% \n    filter(treatment == 1)\n  \n  control_df &lt;- df %&gt;% \n    filter(treatment == 0)\n  \n  treated_matched &lt;- treated_df %&gt;% \n    left_join(control_df, by = covariates,\n              suffix = c(\"_i\", \"_j\"))\n  \n  # Ahora matcheo tambi√©n los controles\n  control_matched &lt;- control_df %&gt;% \n    left_join(treated_df, by = covariates,\n              suffix = c(\"_i\", \"_j\"))\n  \n  estimate_ate &lt;- \n    # Juntamos las dos muestras matcheadas\n    bind_rows(\n      treated_matched,\n      control_matched\n    ) %&gt;% \n    group_by(id_i) %&gt;%\n    summarise(outcome_j = mean(outcome_j),\n              outcome_i = first(outcome_i),\n              treatment_i = first(treatment_i)) %&gt;%\n    mutate(treat_effect = outcome_i - outcome_j,\n           # Multiplicamos por -1 la diferencia entre controles\n           # y sus matches. Porque es como el \"anti tratamiento\"\n           treat_effect = ifelse(\n             treatment_i == 1,\n             yes = treat_effect,\n             no = -1*treat_effect\n           )) %&gt;%\n    summarise(estimate_ate = mean(treat_effect)) %&gt;% \n    pull(estimate_ate)\n  \n  estimate_ate\n}\n\n\nY ahora lo calculamos con esta l√≠nea de c√≥digo:\n\nATE &lt;- \n  exact_matching_estimator_ate(\n    trainees_df,\n    outcome = Salario,\n    treatment = Capacitaci√≥n,\n    covariates = \"Edad\")\n\n\n\nVer el c√≥digo\ntibble(M√©todo = c(\"SDO\", \"Exact Matching ATT\", \"Exact Matching ATE\"),\n       Estimaci√≥n = c(\n         round(mean(trainees_df$Salario[trainees_df$Capacitaci√≥n==1]) - \n                 mean(trainees_df$Salario[trainees_df$Capacitaci√≥n==0])),\n         round(ATT, 2),\n         ATE)) %&gt;%\n  gt() %&gt;%\n  tab_header(\n    title = \"Estimaci√≥n del efecto de la capacitaci√≥n\"\n  )\n\n\n\n\n\n\n\n\nEstimaci√≥n del efecto de la capacitaci√≥n\n\n\nM√©todo\nEstimaci√≥n\n\n\n\n\nSDO\n-4297\n\n\nExact Matching ATT\n2450\n\n\nExact Matching ATE\nNA\n\n\n\n\n\n\n\nPero el ATE nos da NA. ¬øPor qu√©? Bueno, porque no hay controles que coincidan exactamente con los tratados. En este caso, el ATE no se puede estimar con exact matching porque no hay suficientes controles que compartan el mismo valor de la covariable \\(X\\) (en este caso, la edad) que las unidades tratadas. Es por eso que de ac√° en adelante vamos a hablar m√°s del ATT que del ATE. No s√≥lo porque es m√°s f√°cil de estimar sino porque es lo que se calcula en la mayor√≠a de los casos. Recuerden que si tenemos motivos razonables para creer que no existen sesgos de efecto heterog√©neo, el ATT y el ATE son iguales.\nLa ventaja del exact matching es que asegura que las comparaciones se hagan entre unidades id√©nticas en las covariables \\(X\\). Sin embargo, cuando queremos emparejar seg√∫n muchas caracter√≠sticas al mismo tiempo, encontrar controles con valores id√©nticos se vuelve muy dif√≠cil. Por ejemplo, si emparejamos solo por edad hay pocas categor√≠as y es f√°cil encontrar controles; pero si agregamos otras variables como regi√≥n, nivel de ingreso o tama√±o de la tienda, las combinaciones posibles crecen exponencialmente. A esto √∫ltimo se lo conoce como la maldici√≥n de la dimensionalidad y tiene que ver con el hecho que los datos se vuelven m√°s dispersos a medida que aumentamos el n√∫mero de dimensiones (o covariables) en nuestro espacio de an√°lisis. Imaginen que tenemos 5 datos en una l√≠nea de largo \\(10\\). Bueno, ¬øqu√© pasa si los pasamos a un cuadrado de \\(10\\) x \\(10\\)? ¬øY a un cubo de \\(10\\) x \\(10\\) x \\(10\\)? Los datos empiezan a estar m√°s lejos. Es por eso que para encontrar controles iguales deber√≠amos aumentar mucho el tama√±o de nuestra muestra.\nAlgo que se deben estar preguntando es ¬øy si en lugar de buscar un control de \\(25\\) a√±os para el caso anterior buscamos uno que est√© ‚Äúbastante‚Äù cerca? Buenos, perm√≠tanme decirles que no son nada originales, eso existe y se llama Approximate Matching.\n\n\n6.2.2 Approximate Matching\nComo dijimos en la secci√≥n anterior, cuando no encontramos controles que coincidan exactamente en todas las covariables \\(X\\)4, recurrimos al approximate matching. En lugar de exigir valores id√©nticos, buscamos en el grupo de control al individuo cuyos valores de \\(X\\) sean m√°s parecidos a la de cada unidad tratada, y usamos su resultado como contrafactual.\n4¬†Cuando hablamos de \\(X\\) nos referimos a un vector de covariables por las que queremos controlar, que puede incluir variables categ√≥ricas y continuas. Por ejemplo, si tenemos una variable categ√≥rica como ‚Äúregi√≥n‚Äù y una continua como ‚Äúedad‚Äù, el vector \\(X\\) podr√≠a ser algo as√≠ como: \\(X = (regi√≥n, edad)\\).5¬†B√°sicamente el m√≥dulo del vector que une los dos puntos en el espacio de covariables (ahre).Pero, ¬øqu√© significa ‚Äúparecida‚Äù? Si tenemos una sola covariable ser√° la m√°s cercana en n√∫mero, pero como discutimos, el espacio de covariables puede ser (y normalmente es) de m√°s de una dimensi√≥n. En este caso, para cuantificar la similitud entre dos unidades definimos una distancia en el espacio de covariables. Una opci√≥n es usar la distancia euclidiana, esta medida suma las diferencias al cuadrado en cada dimensi√≥n y luego toma ra√≠z, indicando qu√© tan ‚Äúlejos‚Äù est√°n los dos puntos en el espacio5. Por ejemplo, si tenemos que que las covariables son edad y salario, la distancia euclidiana entre dos puntos \\((edad_1, salario_1)\\) y \\((edad_2, salario_2)\\) ser√≠a:\n\\[\ndistancimatch_medicine &lt;- match.data(nearest_control)a_{euclidea} = \\sqrt{(edad_1 - edad_2)^2 + (salario_1 - salario_2)^2}\n\\]\n¬øPero esto es siempre as√≠? Veamos un ejemplo y reflexionemos un poco.\n\n\nVer el c√≥digo\n# La mitad son asignados al grupo tratamiento y la mitad al grupo control\nset.seed(12)\nempleados_tbl &lt;- tibble(Grupo = c(rep(\"tratamiento\", 10), rep(\"control\", 10)),\n                        Edad = rnorm(n = 20, mean = 35, sd = 5),\n                        Salario = Edad*1500 + rnorm(n = 20, mean = 0, sd = 5000))\n\nempleados_tbl |&gt; ggplot(aes(x = Edad,\n                            y = Salario,\n                            color = Grupo)) +\n  geom_point(alpha = .2) + \n  geom_point(data = empleados_tbl[c(9, 10, 18),]) + \n  scale_color_brewer(palette = \"Dark2\") +\n  labs(color = NULL) +\n  theme_bw() +\n  theme(legend.position = \"top\")\n\n\n\n\n\n\n\n\n\nImaginen que queremos encontrar al empleado m√°s cercano al empleado verde lleno (el empleado \\(18\\)). Los candidatos ser√≠an los dos naranjas (los empleados \\(9\\) el de la izquierda y \\(10\\) el de la derecha) ¬øno? Y estamos de acuerdo que el que est√° hacia la derecha es el m√°s cercano (o sea el empleado \\(10\\)), ¬øno? Bueno, calculemos las distancias y veamos qu√© pasa.\n\n\nVer el c√≥digo\n# Defino una funci√≥n para calcular la distancia euclidiana entre dos puntos en el espacio de covariables de dos dimensiones. \ndistancia_euclidea &lt;- function(x_i, x_j) {\n  dist &lt;- sqrt((x_i[1]-x_j[1])^2 + (x_i[2]-x_j[2])^2)\n  dist\n}\n\ndistancia_a_9 &lt;- distancia_euclidea(empleados_tbl[9, c(\"Edad\", \"Salario\")],\n                                    empleados_tbl[18, c(\"Edad\", \"Salario\")])\n\ndistancia_a_10 &lt;- distancia_euclidea(empleados_tbl[10, c(\"Edad\", \"Salario\")],\n                                     empleados_tbl[18, c(\"Edad\", \"Salario\")])\n\ntibble(Empleado = c(\"9\", \"10\"),\n       Distancia = c(distancia_a_9, distancia_a_10)) %&gt;%\n  gt() %&gt;%\n  tab_header(\n    title = \"Distancias euclidianas entre el empleado 18 y los empleados 9 y 10\"\n  )\n\n\n\n\n\n\n\n\nDistancias euclidianas entre el empleado 18 y los empleados 9 y 10\n\n\nEmpleado\nDistancia\n\n\n\n\n9\n225.7699\n\n\n10\n4864.155\n\n\n\n\n\n\n\nEsto dice que el m√°s cercano es el \\(9\\), pero si lo miramos en el gr√°fico, claramente el \\(10\\) es el m√°s cercano. ¬øPor qu√© pasa esto? Bueno, porque las covariables no tienen la misma escala. La edad est√° en un rango de \\(20\\) a \\(50\\) y el salario en un rango de \\(10,000\\) a \\(100,000\\). Entonces, la distancia euclidiana est√° siendo dominada por la variable salario. Es decir, que si bien el el empleado \\(10\\) est√° m√°s cerca en general, el empleado \\(9\\) est√° m√°s cerca en t√©rminos de salario, que es una magnitud con un rango m√°s amplio.\n¬øC√≥mo resolvemos esto? Pues estandarizando las covariables6. Veamos la misma figura pero estandarizada:\n6¬†Es decir, le restamos la media y dividimos por la desviaci√≥n est√°ndar.\n\nVer el c√≥digo\n# Estandarizamos las covariables\nempleados_tbl_estandarizado &lt;- empleados_tbl |&gt; \n  mutate(Edad_st = (Edad - mean(Edad)) / sd(Edad),\n         Salario_st = (Salario - mean(Salario)) / sd(Salario))\n\nempleados_tbl_estandarizado %&gt;% \n  ggplot(aes(x = Edad_st,\n             y = Salario_st,\n             color = Grupo)) +\n  geom_point(alpha = .2) + \n  geom_point(data = empleados_tbl_estandarizado[c(9, 10, 18),]) + \n  scale_color_brewer(palette = \"Dark2\") +\n  labs(color = NULL, x = \"Edad estandarizada\", y = \"Salario estandarizado\") +\n  theme_bw() +\n  theme(legend.position = \"top\")\n\n\n\n\n\n\n\n\n\nPero se ve igual. ¬øEMOSIDO ENGA√ëADO? No, la relaci√≥n geom√©trica va a seguir siendo la misma y est√° perfecto que as√≠ sea, pero calculemos de nuevo las distancias y veamos qu√© punto es el m√°s cercano.\n\n\nVer el c√≥digo\ndistancia_a_9_st &lt;- distancia_euclidea(empleados_tbl_estandarizado[9, c(\"Edad_st\", \"Salario_st\")],\n                                        empleados_tbl_estandarizado[18, c(\"Edad_st\", \"Salario_st\")])\n\ndistancia_a_10_st &lt;- distancia_euclidea(empleados_tbl_estandarizado[10, c(\"Edad_st\", \"Salario_st\")],\n                                         empleados_tbl_estandarizado[18, c(\"Edad_st\", \"Salario_st\")])\n\ntibble(Empleado = c(\"9\", \"10\"),\n       Distancia = c(distancia_a_9_st, distancia_a_10_st)) %&gt;%\n  gt() %&gt;%\n  tab_header(\n    title = \"Distancias euclidianas entre el empleado 18 y los empleados 9 y 10 (estandarizado)\"\n  )\n\n\n\n\n\n\n\n\nDistancias euclidianas entre el empleado 18 y los empleados 9 y 10 (estandarizado)\n\n\nEmpleado\nDistancia\n\n\n\n\n9\n0.5162689\n\n\n10\n0.5684286\n\n\n\n\n\n\n\nAhora s√≠ el m√°s cercano es el empleado \\(9\\).\nOtra opci√≥n es la distancia de Mahalanobis, adem√°s de ver ‚Äúqu√© tan lejos‚Äù est√°n dos puntos en cada variable, tambi√©n ajusta por la forma en que esas variables se relacionan entre s√≠. Es decir, si las variables est√°n correlacionadas, la distancia de Mahalanobis las considera m√°s cercanas que la distancia euclidiana 7.\n7¬†NSi tienen inter√©s en entender un poco m√°s profundamente qu√© es la distancia de Mahalanobis les recomiendo este video.Siempre que podamos vamos a usar la distancia de Mahalanobis, porque es la que refleja mejor las relaciones entre las dimensiones y, en caso de que no haya correlaci√≥n, va a terminar siendo la distancia euclideana (es f√°cil de demostrar si tienen ganas y, claro, tiempo).\nUna √∫ltima aclaraci√≥n, en esta distancia no es necesario estandarizar las covariables porque la distancia de Mahalanobis ya lo hace por nosotros. Entonces, si tenemos dos puntos \\((edad_1, salario_1)\\) y \\((edad_2, salario_2)\\), la distancia de Mahalanobis ser√≠a:\n\\[\ndistancia_{mahalanobis} = \\sqrt{(edad_1 - edad_2, salario_1 - salario_2) \\cdot S^{-1} \\cdot (edad_1 - edad_2, salario_1 - salario_2)^T}\n\\]\nDonde \\(S\\) es la matriz de covarianzas de las variables \\(edad\\) y \\(salario\\). Esta distancia nos dice qu√© tan lejos est√°n los puntos considerando no solo sus diferencias individuales, sino tambi√©n c√≥mo se relacionan entre s√≠.\nDejemos un poquito las comparaciones entre m√©tricas de distancia para m√°s adelante y veamos c√≥mo podemos usar estas distancias para hacer matching.\nEn este caso vamos a analizar un ejemplo en el que queremos evaluar la efectividad en la recuperaci√≥n de una determinada medicina. En este caso (supongamos que hicimos el DAG, identificamos los backdoors, etc.) queremos controlar por tres variables: Edad, Sexo y Severidad (el famoso vector \\(X\\)). Veamos \\(5\\) datos la azar.\n\n\nVer el c√≥digo\nmedicine_impact_recovery &lt;- \n  read_csv(\"https://raw.githubusercontent.com/matheusfacure/python-causality-handbook/master/causal-inference-for-the-brave-and-true/data/medicine_impact_recovery.csv\",\n           show_col_types = FALSE) %&gt;%\n  rename(Recuperaci√≥n = recovery,\n         Medicina = medication,\n         Sexo = sex,\n         Edad = age,\n         Severidad = severity)\n\nset.seed(1)\nmedicine_impact_recovery |&gt; \n  sample_n(5) |&gt; \n  gt::gt() |&gt; \n  gt::tab_header(\n    title = \"Datos de un experimento sobre el impacto de una medicina en la recuperaci√≥n\"\n  )\n\n\n\n\n\n\n\n\nDatos de un experimento sobre el impacto de una medicina en la recuperaci√≥n\n\n\nSexo\nEdad\nSeveridad\nMedicina\nRecuperaci√≥n\n\n\n\n\n0\n47.67569\n0.43410184\n0\n37\n\n\n0\n19.89644\n0.24021836\n0\n15\n\n\n1\n26.93100\n0.09442637\n0\n13\n\n\n1\n11.63124\n0.33707949\n0\n24\n\n\n0\n58.04307\n0.91946590\n1\n45\n\n\n\n\n\n\n\nY ahora veamos c√≥mo se distribuyen los datos en las variables Edad y Severidad.\n\n\nVer el c√≥digo\nmedicine_impact_recovery |&gt; \n  ggplot(aes(x = Edad,\n             y = Severidad,\n             color = factor(Medicina))) +\n  geom_point(size = .2) +\n  scale_color_brewer(palette = \"Dark2\") +\n  labs(color = \"Medicina\") +\n  theme_bw() +\n  theme(legend.position = \"top\")\n\n\n\n\n\nComo se distribuyen los datos en las variables edad y severidad.\n\n\n\n\nVemos que claramente calcular el SDO no es una buena idea porque la asignaci√≥n al tratamiento no es aleatoria (igual dejemos anotado que vale 16.9). Tambi√©n podemos ver qu√© pasa con el sexo.\n\n\nVer el c√≥digo\nmedicine_impact_recovery |&gt; \n  group_by(Sexo) |&gt;\n  summarise(No_Medicina = sum(Medicina == 0),\n            Medicina = sum(Medicina == 1)) |&gt;\n  gt()\n\n\n\n\n\n\n\n\nSexo\nNo_Medicina\nMedicina\n\n\n\n\n0\n7134\n2896\n\n\n1\n5942\n4028\n\n\n\n\n\nTratados por sexo.\n\n\nY aqu√≠ vemos dos cosas. Que en sexo \\(0\\) la mayor√≠a son controles y en sexo \\(1\\) no es tan as√≠. Y que, en general hay m√°s controles que tratados8.\n8¬†Algo que va a hacer que sea m√°s f√°cil encontrarle controles matcheados a los tratados y no viceverse.9¬†Para m√°s detalles de c√≥mo funciona el paquete MatchIt pueden ver la documentaci√≥n oficial.Vamos a estimar el ATT utilizando la funci√≥n matchit del paquete MatchIt9. Esta funci√≥n nos permite hacer matching de forma sencilla y r√°pida. Vamos a usar la distancia de Mahalanobis para emparejar los tratados con los controles.\n\nnearest_control &lt;- matchit(Medicina ~ Sexo + Edad + Severidad, \n                           data = medicine_impact_recovery,\n                           method = \"nearest\", \n                           distance = \"mahalanobis\",\n                           replace = T,\n                           ratio = 1)\n\nsummary(nearest_control, un = F)$nn[4:5,]\n#&gt;           Control Treated\n#&gt; Matched       733    6924\n#&gt; Unmatched   12343       0\n\nVemos que de los \\(20000\\) datos originales, los \\(6924\\) individuos tratados fueron emparejados con \\(733\\) controles. ¬øC√≥mo pueden ser menos controles que tratados? Bueno, resumidamente, porque al decirle replace = T le estamos diciendo que puede usar el mismo control m√°s de una vez. Es decir, que un control puede ser emparejado con m√°s de un tratado. Esto es √∫til cuando tenemos pocos controles y muchos tratados, como en este caso.\nAhora calculemos el tama√±o del efecto:\n\n\nVer el c√≥digo\nmatch_medicine &lt;- match.data(nearest_control)\n\nmatching_model_medicine &lt;- lm(Recuperaci√≥n ~ Medicina + Sexo + Edad + Severidad, \n                              data = match_medicine, \n                              weights = weights)\n\nmodelsummary(list(\"Matching\"= matching_model_medicine),\n             statistic = \"p.value\", \n             gof_omit = \".*\",\n             output = \"gt\") |&gt;\n  gt_highlight_rows(rows = c(3,4), \n                    fill = \"lightyellow\",\n                    font_weight = \"bold\")\n\n\n\n\n\n\n\n\n\nMatching\n\n\n\n\n(Intercept)\n-3.831\n\n\n\n(&lt;0.001)\n\n\nMedicina\n-9.944\n\n\n\n(&lt;0.001)\n\n\nSexo\n12.946\n\n\n\n(&lt;0.001)\n\n\nEdad\n0.554\n\n\n\n(&lt;0.001)\n\n\nSeveridad\n29.696\n\n\n\n(&lt;0.001)\n\n\n\n\n\n\n\nVemos que hay un efecto negativo de la medicaci√≥n en la recuperaci√≥n, algo que hubi√©ramos malinterpretado totalmente si hubi√©ramos usado el SDO. Recordemos que:\n\n\nVer el c√≥digo\ntibble(M√©todo = c(\"SDO\", \"Matching\"),\n       Estimaci√≥n = c(round(mean(medicine_impact_recovery$Recuperaci√≥n[medicine_impact_recovery$Medicina==1]) - \n                 mean(medicine_impact_recovery$Recuperaci√≥n[medicine_impact_recovery$Medicina==0]), 2),\n                 round(coef(matching_model_medicine)[\"Medicina\"], 2))) %&gt;%\n  gt() %&gt;%\n  tab_header(\n    title = \"Estimaci√≥n del efecto de la medicina en la recuperaci√≥n\"\n  )\n\n\n\n\n\n\n\n\nEstimaci√≥n del efecto de la medicina en la recuperaci√≥n\n\n\nM√©todo\nEstimaci√≥n\n\n\n\n\nSDO\n16.90\n\n\nMatching\n-9.94\n\n\n\n\n\n\n\nRecordemos que la estimaci√≥n de approximate matching en este caso es una estimaci√≥n del ATT, ya que lo que hicimos fue encontrar controles matcheados para los sujetos tratados. Es decir, que estamos estimando el efecto de la medicina en la recuperaci√≥n de los pacientes que recibieron la medicina y que tienen un perfil similar a los controles. Podemos tener buenas razones para creer que el ATT es igual al ATE en este caso‚Ä¶ O no.\n\n\n6.2.3 La queso(porte com√∫n)\nEn la secci√≥n anterior vimos c√≥mo hacer matching con la distancia de Mahalanobis y c√≥mo calcular el ATT. Pero, ¬øqu√© pasa si queremos hacer matching con m√°s de una covariable? Como adelantamos cuando mencionamos la maldici√≥n de la dimensionalidad, la cosa se puede complicar, y mucho. Es por eso que una de las condiciones necesarias para hacer matching es que los datos tengan soporte com√∫n.\nPero, ¬øde qu√© hablamos cuando hablamos de soporte com√∫n? B√°sicamente, nos referimos a que las covariables \\(X\\) deben tener valores que se superpongan entre los grupos de tratamiento y control. Es decir, que debe haber sujetos tratados y no tratados con valores similares en las covariables que estamos usando para emparejar. Suena a algo b√°sico, pero no siempre es el caso (en la secci√≥n @#sec-matching_vs_reg discutimos un poquito esto).\n\n\n6.2.4 Euclideana vs.¬†Mahalanobis, la batalla final\nEn mi experiencia, entender claramente la diferencia entre estas dos distancia no es cosa sencilla y, si bien no es vital para entender matching, es una excelente excusa pensar un poco en qu√© significa ser parecido. Vamos al lio.\nSupongamos que queremos estudiar el efecto de la entrega de un bono en la satisfacci√≥n con la empresa. Para esto identificamos dos confusores y vamos a matchear a los sujetos del grupo tratamiento (recibieron un bono) con sus controles correspondientes (no recibieron bono). Los confusores que identificamos son la edad y el salario de los empleados. Vamos a generar una base de datos con \\(200\\) empleados, \\(100\\) del grupo tratamiento y \\(100\\) del grupo control y ver algunos datos tomados al azar.\n\n\nVer el c√≥digo\n# Generamos los datos\nset.seed(12)\nempleados_tbl &lt;- tibble(Grupo = c(rep(\"tratamiento\", 100), rep(\"control\", 100)),\n                        Edad = rnorm(n = 200, mean = 35, sd = 5),\n                        Salario = Edad*1500 + rnorm(n = 200, mean = 0, sd = 5000))\n\nset.seed(12)\nempleados_tbl |&gt; \n  mutate(Salario = round(Salario, 2),\n         Edad = round(Edad, 2)) |&gt;\n  sample_n(6) |&gt; \n  gt()\n\n\n\n\n\n\n\n\nGrupo\nEdad\nSalario\n\n\n\n\ncontrol\n37.59\n48814.57\n\n\ntratamiento\n30.18\n50000.95\n\n\ntratamiento\n34.11\n59497.67\n\n\ntratamiento\n36.88\n55811.62\n\n\ncontrol\n33.29\n61942.17\n\n\ntratamiento\n39.86\n68503.98\n\n\n\n\n\nDatos de seis filas tomadas al azar.\n\n\nComo es de esperarse (y lo esperamos mucho porque los datos los generamos nosotros), la edad y el salario est√°n correlacionados (r=0.83). Vamos a graficar los datos.\n\n\nVer el c√≥digo\n# Y los graficamos\n# El texto de la correlaci√≥n\ntext_tbl &lt;- tibble(x = min(empleados_tbl$Edad, na.rm = T),\n                   y = max(empleados_tbl$Salario, na.rm = T),\n                   label = paste(\"r pearson =\", round(cor(empleados_tbl$Edad, empleados_tbl$Salario, use=\"complete.obs\"), 2)))\n\nempleados_tbl |&gt; ggplot(aes(x = Edad,\n                            y = Salario)) +\n  geom_point(aes(color = Grupo)) +\n  geom_smooth(method = \"lm\", color = \"black\", se = F) +\n  scale_color_brewer(palette = \"Dark2\") +\n  labs(color = NULL) +\n  geom_text(data = text_tbl, aes(x = x, y = y, label = label), hjust = 0) +\n  theme_bw() +\n  theme(legend.position = \"top\")\n#&gt; `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nEdad y salario de los empleados.\n\n\n\n\nAhora, qu√© pasa si queremos emparejar a un empleado del grupo tratamiento (el que tiene el ID \\(I_{emp} = 2\\)) con uno del grupo control. Si usamos la distancia euclidiana, vamos a calcular la distancia entre cada empleado del grupo tratamiento y todos los del grupo control, y luego elegimos el m√°s cercano.\n\n\nVer el c√≥digo\nI_emp &lt;- 2 # Al que le queremos encontrar la distancia m√°s cercana\n\nempleados_tbl |&gt; ggplot(aes(x = Edad,\n                            y = Salario)) +\n  geom_point(aes(color = Grupo), alpha = 0.2) +\n  geom_point(data = empleados_tbl[I_emp,], color = \"black\", size = 3) +\n  geom_magnify(from = c(empleados_tbl$Edad[I_emp]*.98, empleados_tbl$Edad[I_emp]*1.01, \n                        empleados_tbl$Salario[I_emp]*.98, empleados_tbl$Salario[I_emp]*1.01), \n               to = c(35, 45, 3E4, 5E4)) +\n  theme_bw() +\n  scale_color_brewer(palette = \"Dark2\") +\n  labs(color = NULL) +\n  theme(legend.position = \"top\")\n\n\n\n\n\nEdad y salario de los empleados. En oscuro el punto al que le queremos buscar el m√°s cercano.\n\n\n\n\n\n\nVer el c√≥digo\n# Calculamos las distancias\nmatriz_varianzas &lt;- matrix(c(var(empleados_tbl$Edad), 0, 0, var(empleados_tbl$Salario)),\n                           ncol = 2)\nmatriz_varianzas_inv &lt;- solve(matriz_varianzas)\n\nmatriz_covarianzas &lt;- var(as.matrix(empleados_tbl[,2:3]))\nmatriz_covarianzas_inv &lt;- solve(matriz_covarianzas)\n\neuclidean &lt;- rep(NA, nrow(empleados_tbl))\nmahalanobis &lt;- rep(NA, nrow(empleados_tbl))\n\nfor (i in 1:nrow(empleados_tbl)) {\n  resta &lt;- as.matrix(empleados_tbl[I_emp,2:3])-as.matrix(empleados_tbl[i,2:3])\n  euclidean[i] &lt;- resta %*% matriz_varianzas_inv %*% t(resta)\n  mahalanobis[i] &lt;- resta %*% matriz_covarianzas_inv %*% t(resta)\n}\nmin_euclidean &lt;- which.min(euclidean[101:200]) + 100\nmin_mahalab &lt;- which.min(mahalanobis[101:200]) + 100\n\n# Las vizualizamos\nempleados_tbl |&gt; ggplot(aes(x = Edad,\n                            y = Salario)) +\n  geom_point(aes(color = Grupo), alpha = 0.2) +\n  geom_point(data = empleados_tbl[I_emp,], color = \"black\", size = 3) +\n  geom_point(data = empleados_tbl[min_euclidean,], size = 3, color = \"darkred\") +\n  geom_point(data = empleados_tbl[min_mahalab,], size = 3, color = \"steelblue\") +\n  theme_bw() +\n  geom_magnify(from = c(empleados_tbl$Edad[I_emp]*.98, empleados_tbl$Edad[I_emp]*1.01, \n                        empleados_tbl$Salario[I_emp]*.98, empleados_tbl$Salario[I_emp]*1.01), \n               to = c(35, 45, 3E4, 5E4)) +\n  scale_color_brewer(palette = \"Dark2\") +\n  labs(color = NULL) +\n  theme(legend.position = \"top\")\n\n\n\n\n\nEdad y salario de los empleados. En oscuro el punto al que le queremos buscar el m√°s cercano y sus candidatos.\n\n\n\n\n¬øCu√°l dir√≠an que es el m√°s cercano? ¬øEl punto rojo o el punto azul? Bueno, si calculamos la distancia eucl√≠dea efectivamente el punto m√°s cercano es el rojo, pero si lo hacemos utilizando la distancia de Mahalanobis, el m√°s cercano es el azul. ¬øPor qu√©? Bueno, en este caso, la distancia de Mahalanobis considera que el punto azul est√° m√°s cerca porque tiene en cuenta que la edad y el salario est√°n correlacionados. Es decir son m√°s ‚Äúparecidas‚Äù dos personas con una relaci√≥n entre edad y salario similar.\nDicho esto, vuelvo sobre la idea de que siempre conviene utilizar la distancia de Mahalanobis para hacer matching porque es la que mejor refleja las relaciones entre las covariables. Adem√°s, en el caso de que no tengamon correlaci√≥n entre las covariables, la distancia de Mahalanobis se reduce a la distancia eucl√≠dea.",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Subclasificaci√≥n y *matching*</span>"
    ]
  },
  {
    "objectID": "matching.html#matching-vd.-regresi√≥n",
    "href": "matching.html#matching-vd.-regresi√≥n",
    "title": "6¬† Subclasificaci√≥n y matching",
    "section": "6.3 Matching vd. regresi√≥n",
    "text": "6.3 Matching vd. regresi√≥n",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Subclasificaci√≥n y *matching*</span>"
    ]
  },
  {
    "objectID": "matching.html#matching-vs.-regresi√≥n",
    "href": "matching.html#matching-vs.-regresi√≥n",
    "title": "6¬† Subclasificaci√≥n y matching",
    "section": "6.3 Matching vs.¬†regresi√≥n",
    "text": "6.3 Matching vs.¬†regresi√≥n\n\n\nVer el c√≥digo\n# Genero la data ####\ndf &lt;- tibble(\n  # x es un confusor\n  x = runif(1000, -1, 4),\n  # Afecta la probabilidad de recibir el tratamiento de forma NO LINEAL (funci√≥n escal√≥n)\n  prob_d = ifelse(x &gt; 0.5 & x &lt; 2.5, 0.1, 0.9),\n  d = rbinom(1000, 1, prob_d),\n  noise = rnorm(1000, sd = 0.1),\n  # Pra simplificar, el ATE es homogeneo y vale 1\n  treat_effect = 1,\n  # x afecta al outcome de manera no lineal (una funci√≥n seno)\n  outcome = sin(x) + d*treat_effect + noise\n) %&gt;% \n  mutate(d_factor = factor(d,\n                           levels=c(0,1), labels=c(\"No tratado\",\n                                                   \"Tratado\")))\n\n\n\n\nVer el c√≥digo\nggplot(df,\n       aes(x, outcome, color = d_factor)) +\n  geom_point() + \n  scale_color_brewer(palette = \"Dark2\") +\n  labs(color = \"Estado del tratamiento\") +\n  theme_bw() +\n  theme(legend.position = \"top\")\n\n\n\n\n\n\n\n\n\n\n\nVer el c√≥digo\n# Ajustemos un modelo lineal ####\nlinear_model1 &lt;- lm(outcome ~ d + x, data = df)\n\n# Con matching ####\nlibrary(MatchIt)\nnearest_control &lt;- matchit(d ~ x, \n                           data = df,\n                           method = \"nearest\", \n                           distance = \"mahalanobis\",\n                           replace = T,\n                           ratio = 1)\n\nmatch_df &lt;- match.data(nearest_control)\n\nmatching_model1 &lt;- lm(outcome ~ d + x, \n                      data = match_df, \n                      weights = weights)\n\n# Comparamos los modelos\nmodelsummary(list(\"Regresi√≥n\"= linear_model1,\n                  \"Matching\" = matching_model1),\n             coef_rename = c(\"d\" = \"Tratamiento\",\n                             \"x\" = \"Covariable\"),\n             statistic = NULL, \n             gof_omit = 'DF|Deviance|R2|AIC|BIC|Log.Lik|F|RMSE',\n             output = \"gt\") |&gt;\n  gt_highlight_rows(rows = 2, \n                    fill = \"lightyellow\",\n                    font_weight = \"bold\")\n\n\n\n\n\n\n\n\n\nRegresi√≥n\nMatching\n\n\n\n\n(Intercept)\n0.629\n-0.130\n\n\nTratamiento\n0.220\n0.992\n\n\nCovariable\n0.042\n0.033\n\n\nNum.Obs.\n1000\n643\n\n\n\n\n\nDAG que representa la relaci√≥n causal entre las vitaminas y los defectos de nacimiento.",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Subclasificaci√≥n y *matching*</span>"
    ]
  },
  {
    "objectID": "matching.html#matching-vs.-regresi√≥nfuente",
    "href": "matching.html#matching-vs.-regresi√≥nfuente",
    "title": "6¬† Subclasificaci√≥n y matching",
    "section": "6.3 Matching vs.¬†regresi√≥n7",
    "text": "6.3 Matching vs.¬†regresi√≥n7\nEn el ejemplo anterior, vimos c√≥mo el matching busca emparejar unidades tratadas y no tratadas bas√°ndose en sus caracter√≠sticas observables. Pero, ¬øqu√© pasa si en lugar de emparejar, simplemente ajustamos un modelo de regresi√≥n que incluya esas mismas covariables? ¬øNo era la forma en la que control√°bamos por los confusores antes de este cap√≠tulo? Bueno, s√≠ y no. La regresi√≥n y el matching son dos enfoques diferentes para obtener la tan ansiada independencia condicional, pero cada uno tiene sus propias ventajas y desventajas. Vamos con un ejemplo paradigm√°tico para que podamos entender un poquito m√°s de que estamos hablando.\nVamos a generar un conjunto de datos donde \\(x\\) es un confusor, el tratamiento \\(d\\) se asigna de forma no lineal en funci√≥n de \\(x\\), y el outcome tambi√©n depende de \\(x\\) de forma no lineal, y el efecto del tratamiento es homog√©neo y vale \\(1\\).\n\n\nVer el c√≥digo\n# Genero la data ####\ndf &lt;- tibble(\n  # x es un confusor\n  x = runif(1000, -1, 4),\n  # Afecta la probabilidad de recibir el tratamiento de forma NO LINEAL (funci√≥n escal√≥n)\n  prob_d = ifelse(x &gt; 0.5 & x &lt; 2.5, 0.1, 0.9),\n  d = rbinom(1000, 1, prob_d),\n  noise = rnorm(1000, sd = 0.1),\n  # Pra simplificar, el ATE es homogeneo y vale 1\n  treat_effect = 1,\n  # x afecta al outcome de manera no lineal (una funci√≥n seno)\n  outcome = sin(x) + d*treat_effect + noise\n) %&gt;% \n  mutate(d_factor = factor(d,\n                           levels=c(0,1), labels=c(\"No tratado\",\n                                                   \"Tratado\")))\n\nggplot(df,\n       aes(x, outcome, color = d_factor)) +\n  geom_point(size = 1) + \n  scale_color_brewer(palette = \"Dark2\") +\n  labs(color = \"Estado del tratamiento\") +\n  theme_bw() +\n  theme(legend.position = \"top\")\n\n\n\n\n\nCada uno de los sujetos pertenecientes al grupo control y tratamiento con sus respectivos valores de outcome y covariable x.\n\n\n\n\nDe estos datos podemos ver dos cosas claras: 1) \\(x\\) es claramente un confusor, ya que el valor de \\(x\\) no solo afecta al outcome sino tambi√©n a la probabilidad de recibir el tratamiento (los sujetos del medio son m√°s ‚ÄúNo tratados‚Äù), y 2) la relaci√≥n entre \\(x\\) y el outcome es no lineal. El efecto del tratamiento es homog√©neo y vale \\(1\\), y esto lo sabemos porque generamos los datos nosotros mismos.\nAhora probemos dos cosas: Estimar el efecto del tratamiento usando una regresi√≥n lineal y luego usando matching aproximado con la librer√≠a MatchIt(para detalles pueden ver el c√≥digo). A continuaci√≥n tenemos los efectos estimados con los dos m√©todos:\n\n\nVer el c√≥digo\n# Ajustemos un modelo lineal ####\nlinear_model1 &lt;- lm(outcome ~ d + x, data = df)\n\n# Con matching ####\nlibrary(MatchIt)\nnearest_control &lt;- matchit(d ~ x, \n                           data = df,\n                           method = \"nearest\", \n                           distance = \"mahalanobis\",\n                           replace = T,\n                           ratio = 1)\n\nmatch_df &lt;- match.data(nearest_control)\n\nmatching_model1 &lt;- lm(outcome ~ d + x, \n                      data = match_df, \n                      weights = weights)\n\n# Comparamos los modelos\nmodelsummary(list(\"Regresi√≥n\"= linear_model1,\n                  \"Matching\" = matching_model1),\n             coef_rename = c(\"d\" = \"Tratamiento\"),\n             statistic = NULL, \n               gof_omit = 'DF|Deviance|R2|AIC|BIC|Log.Lik|F|RMSE',\n             output = \"gt\") |&gt;\n  gt_highlight_rows(rows = 2, \n                    fill = \"lightyellow\",\n                    font_weight = \"bold\")\n\n\n\n\n\n\n\n\n\nRegresi√≥n\nMatching\n\n\n\n\n(Intercept)\n0.630\n-0.139\n\n\nTratamiento\n0.247\n1.004\n\n\nx\n0.036\n0.044\n\n\nNum.Obs.\n1000\n665\n\n\n\n\n\nEstimaciones del efecto del tratamiento utilizando regresi√≥n y matching.\n\n\nComo era de esperarse, la regresi√≥n lineal nos da un estimador del efecto del tratamiento de \\(0.220\\), mientras que el matching nos da un estimador de \\(0.992\\). Pero ¬øPor qu√© era esperable? La regresi√≥n lineal asume una relaci√≥n lineal entre \\(x\\) y el outcome, lo que no es cierto en nuestros datos. Por lo tanto, el modelo no captura correctamente la relaci√≥n entre \\(x\\) y el outcome, lo que sesga el estimador del efecto del tratamiento8.\n8¬†Otra cosa interesante que podemos observar, es que al estimar el efecto con matching, el tama√±o de la muestra efectivo es menor que al estimar con regresi√≥n lineal. Esto se debe a que el matching elimina las unidades que no tienen un par cercano en el grupo de control, lo que reduce el tama√±o de la muestra efectiva.Veamos qu√© forma tiene el modelo lineal ajustado con estos datos:\n\n\nVer el c√≥digo\n# Regression\ndf_linear &lt;- df %&gt;%\n  modelr::add_predictions(linear_model1, var = \"pred_linear\")\n\nplot_linear &lt;-\n  ggplot(df_linear) +\n  aes(x = x, color = d_factor) +\n  geom_point(aes(y = outcome), alpha = 0.3, size = 1) +\n  geom_line(aes(y = pred_linear), size = 1) +\n  labs(color = \"Treatment status\") +\n  scale_color_brewer(palette = \"Dark2\") +\n  labs(color = \"Estado del tratamiento\") +\n  theme_bw() +\n  theme(legend.position = \"top\")\n#&gt; Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n#&gt; ‚Ñπ Please use `linewidth` instead.\nplot_linear\n\n\n\n\n\nLa regresi√≥n lineal ajustada.\n\n\n\n\nEntonces esto es esperable porque los datos son claramente no lineales. Ahora, usemos un suavizado de los datos para reflejar, m√°s o menos, qu√© es lo que est√° haciendo el algoritmo de matching para estimar el efecto.\n\n\nVer el c√≥digo\n# Matching\nknn1 &lt;- knn.reg(\n  train = dplyr::select(df, x, d),\n  y = df$outcome,\n  test = dplyr::select(df, x, d),\n  k = 10,\n  algorithm = \"brute\"\n)\n\ndf_knn &lt;- df %&gt;% \n  mutate(pred_knn = knn1$pred)\n\nplot_matching &lt;- \n  ggplot(df_knn) +\n  aes(x = x, color = d_factor) +\n  geom_point(aes(y = outcome), alpha = 0.3, size = 1) +\n  geom_line(aes(y = pred_knn), linewidth = 1) +\n  labs(color = \"Treatment status\") +  \n  scale_color_brewer(palette = \"Dark2\") +\n  labs(color = \"Estado del tratamiento\") +\n  theme_bw() +\n  theme(legend.position = \"top\")\nplot_matching\n\n\n\n\n\nAlgo parecido a lo que usa el matching para estimar el efecto.\n\n\n\n\nPodemos ver a todas luces que esto tiene mucho sentido. Ahora, ¬øUsamos siempre matching o alguna vez puede no convenirnos?\nUno de los supuestos de los modelos lineales es la linealidad de la relaci√≥n entre, en este caso, x y el outcome. Si esto no se cumple, el modelo lineal no va a capturar bien la relaci√≥n y, por lo tanto, el estimador del efecto del tratamiento va a estar sesgado. En cambio, el matching no asume una relaci√≥n lineal entre las covariables y el outcome, por lo que puede ser m√°s robusto en estos casos. Sin embargo, recordemos que uno de los supuestos del matching es la necesidad de soporte com√∫n. En el ejemplo anterior hab√≠a soporte com√∫n, es decir, en el mismo rango de \\(x\\) hab√≠a tanto tratados como no tratados. Veamos un ejemplo donde esto no es as√≠.\n\n\nVer el c√≥digo\n# Datos sin soporte com√∫n ####\ndf_wo_common_support &lt;- tibble(\n  # x es un confusor\n  x = runif(1000, -1, 4),\n  # No hay m√°s prob_d, es determin√≠stico\n  d = ifelse(x &gt; 0.5 & x &lt; 2.5, 0, 1),\n  noise = rnorm(1000, sd = 0.1),\n  # Pra simplificar, el ATE es homogeneo y vale 1\n  treat_effect = 1,\n  # x afecta al outcome de manera no lineal (una funci√≥n seno)\n  outcome = sin(x) + d*treat_effect + noise\n) %&gt;% \n  mutate(d_factor = factor(d,\n                           levels=c(0,1), labels=c(\"No tratado\",\n                                                   \"Tratado\")))\n\nggplot(df_wo_common_support,\n       aes(x, outcome, color = d_factor)) +\n  geom_point(size = 1) + \n  scale_color_brewer(palette = \"Dark2\") +\n  labs(color = \"Estado del tratamiento\") +\n  theme_bw() +\n  theme(legend.position = \"top\")\n\n\n\n\n\nDatos pero ahora sin soporte com√∫n.\n\n\n\n\nEn este ejemplo podemos ver claramente que todos los sujetos del grupo tratamiento tienen valores de \\(x\\) mayores a \\(0.5\\) y menores a \\(2.5\\). Es decir, ya no hay m√°s soporte com√∫n.\nA estos datos le vamos a ajustar dos modelos, uno de matching usando MatchIt y otro de regresi√≥n lineal pero con un peque√±o truquito dado que sabemos la forma funcional. Lo que vamos a ajustar es el siguiente modelo:\n\\[\nY_i = \\beta_{0i} + \\beta_{di} D + \\beta_{xi} \\sin(X) + \\epsilon_i\n\\]\nEs decir, estamos asumiendo que la relaci√≥n entre \\(x\\) y el outcome es una funci√≥n seno, y no lineal9. Vamos a ver qu√© pasa.\n9¬†Recordemos que, a pesar de que aparece \\(\\sin(X)\\), la regresi√≥n lineal sigue siendo lineal en los par√°metros, por lo que no estamos violando ning√∫n supuesto de la regresi√≥n lineal.\n\nVer el c√≥digo\n# Modelo lineal sin soporte comun ####\nreg_wo_common_support &lt;- lm(outcome ~ d + sin(x), data = df_wo_common_support)\n\n# Matching sin soporte com√∫n ####\nnearest_control &lt;- matchit(d ~ x, \n                           data = df_wo_common_support,\n                           method = \"nearest\", \n                           distance = \"mahalanobis\",\n                           replace = T,\n                           ratio = 1)\n\nmatch_df_wo_common_support &lt;- match.data(nearest_control)\n\nmathing_wo_common_support &lt;- lm(outcome ~ d + x, \n                     data = match_df_wo_common_support, \n                     weights = weights)\n\n# Comparamos los modelos\nmodelsummary(list(\"Regresi√≥n\"= reg_wo_common_support,\n                  \"Matching\" = mathing_wo_common_support),\n             coef_rename = c(\"d\" = \"Tratamiento\"),\n             statistic = NULL, \n             gof_omit = 'DF|Deviance|R2|AIC|BIC|Log.Lik|F|RMSE',\n             output = \"gt\") |&gt;\n  gt_highlight_rows(rows = 2, \n                    fill = \"lightyellow\",\n                    font_weight = \"bold\")\n\n\n\n\n\n\n\n\n\nRegresi√≥n\nMatching\n\n\n\n\n(Intercept)\n-0.018\n0.437\n\n\nTratamiento\n1.022\n0.367\n\n\nsin(x)\n1.015\n\n\n\nx\n\n0.020\n\n\nNum.Obs.\n1000\n590\n\n\n\n\n\nEstimaciones del efecto del tratamiento utilizando regresi√≥n y matching para los datos sin soporte com√∫n.\n\n\nLo que pasa ahora es que, gracias a la capacidad de extrapolar de la regresi√≥n lineal, la falta de doporte com√∫n no es un problema y el estimador del efecto del tratamiento es bastante bueno, \\(1.022\\). En cambio, el matching no puede extrapolar y, por lo tanto, el estimador del efecto del tratamiento es \\(0.02\\), es decir, un efecto casi nulo.\nVolvamos a ver las cosas gr√°ficamente a ver si esto nos echa un poco de luz sobre lo que est√° ocurriendo. Primero veamos la regresi√≥n lineal ajustada:\n\n\nVer el c√≥digo\n# Esto es s√≥lo una cosa para plotar los datos\ndf_wo_common_support &lt;- df_wo_common_support %&gt;%\n  mutate(group = case_when(\n    x &lt; 0.5 ~ \"segment1\",\n    x &gt; 2.5 ~ \"segment3\",\n    TRUE ~ \"segment2\"\n  ))\n\n# Los labels a una funci√≥n\ncreating_factor_d &lt;- function(x) factor(x,\n                                        levels = c(0, 1),\n                                        labels = c(\"No tratado\",\n                                                   \"Tratado\"))\n\ndf_wo_cs_treated &lt;- df_wo_common_support %&gt;% \n  mutate(extrapolation = ifelse(d == 1, \"No\", \"Yes\"),\n         d = 1,\n         d_factor = creating_factor_d(d)) %&gt;% \n  modelr::add_predictions(reg_wo_common_support, var = \"pred_treated\")\n\ndf_wo_cs_untreated &lt;- df_wo_common_support %&gt;% \n  mutate(extrapolation = ifelse(d == 0, \"No\", \"Yes\"),\n         d = 0,\n         d_factor = creating_factor_d(d)) %&gt;% \n  modelr::add_predictions(reg_wo_common_support, var = \"pred_untreated\")\n\nplot_wo_cs_reg &lt;- \n  ggplot() +\n  aes(x, outcome, color = d_factor) +\n  geom_point(data= df_wo_common_support, alpha = 0.3, size = 1) +\n  geom_line(data = df_wo_cs_untreated,\n            aes(y = pred_untreated,\n                alpha = extrapolation,\n                linetype = extrapolation,\n                group = group), size = 1) +\n  geom_line(data = df_wo_cs_treated,\n            aes(y = pred_treated,\n                alpha = extrapolation,\n                linetype = extrapolation,\n                group = group), size = 1) +\n  scale_alpha_manual(values = c(\"Yes\" = 0.5, \"No\" = 1)) +\n  scale_linetype_manual(values = c(\"Yes\" = \"dashed\", \"No\" = \"solid\")) +\n  scale_color_brewer(palette = \"Dark2\") +\n  labs(color = \"Estado del tratamiento\",\n       linetype = \"Extrapolaci√≥n\") +\n  guides(alpha = FALSE,\n         linetype = FALSE) +\n  theme_bw() +\n  theme(legend.position = \"top\")\n#&gt; Warning: The `&lt;scale&gt;` argument of `guides()` cannot be `FALSE`. Use \"none\" instead\n#&gt; as of ggplot2 3.3.4.\n\nplot_wo_cs_reg\n\n\n\n\n\nLa regresi√≥n lineal ajustada conociendo la forma de la relaci√≥n entre x y el outcome (seno). La l√≠nea punteada representa la fracci√≥n de x que es extrapolada por el modelo para estos datos sin soporte com√∫n.\n\n\n\n\nEn este caso podemos ver que al ajustar la regresi√≥n lineal, el modelo extrapola los valores de \\(x\\) y la distancia entre ambas curvas es, efectivamente cercana a \\(1\\) (que es el valor del par√°metro poblacional). ¬øY si vemos la estimaci√≥n de matching?\n\n\nVer el c√≥digo\nx_values &lt;- df_wo_common_support %&gt;% dplyr::select(x)\n\nknn_wo_cs_treated &lt;- knn.reg(\n  train = df_wo_common_support %&gt;% \n    filter(d == 1) %&gt;% \n    dplyr::select(x),\n  y = df_wo_common_support %&gt;% \n    filter(d == 1) %&gt;% \n    dplyr::pull(outcome),\n  test = x_values,\n  k = 15,\n  algorithm = \"brute\"\n)\n\nknn_wo_cs_untreated &lt;- knn.reg(\n  train = df_wo_common_support %&gt;% \n    filter(d == 0) %&gt;% \n    dplyr::select(x),\n  y = df_wo_common_support %&gt;% \n    filter(d == 0) %&gt;% \n    dplyr::pull(outcome),\n  test = x_values,\n  k = 15,\n  algorithm = \"brute\"\n)\n\ndf_untr_matching_wo_cs &lt;-\n  tibble(\n    y_pred = knn_wo_cs_untreated$pred,\n    x = df_wo_common_support$x,\n    d = 0\n  ) %&gt;%\n  mutate(d_factor = creating_factor_d(d))\n\ndf_tr_matching_wo_cs &lt;-\n  tibble(\n    y_pred = knn_wo_cs_treated$pred,\n    x = df_wo_common_support$x,\n    d = 1\n  ) %&gt;%\n  mutate(d_factor = creating_factor_d(d),\n         group = case_when(\n           x &lt; 0.5 ~ \"segment1\",\n           x &gt; 2.5 ~ \"segment3\",\n           TRUE ~ \"segment2\"\n         ))\n\nplot_matching_wo_cs &lt;- \n  ggplot() +\n  aes(x, outcome, color = d_factor) +\n  geom_point(data= df_wo_common_support, alpha = 0.3, size = 1) +\n  geom_line(data = df_untr_matching_wo_cs,\n            aes(y = y_pred), size = 1) +\n  geom_line(data = df_tr_matching_wo_cs,\n            aes(y = y_pred, group = group), size = 1) +\n  scale_color_brewer(palette = \"Dark2\") +\n  labs(color = \"Estado del tratamiento\") +\n  theme_bw() +\n  theme(legend.position = \"top\")\n\nplot_matching_wo_cs\n\n\n\n\n\nAlgo parecido a lo que usa el matching para estimar el efecto pero ahora sin soporte com√∫n.\n\n\n\n\nPodemos ver que para los valores de \\(x\\) donde no hay soporte com√∫n, el matching hace una estimaciones que est√°n muy lejos del valor real del par√°metro poblacional, \\(1\\). Esto se debe a que el matching no puede extrapolar y, por lo tanto, no puede estimar el efecto del tratamiento en esos valores de \\(x\\) donde no hay unidades tratadas.\nEn resumen, la regresi√≥n lineal puede ser una herramienta conveniente para obtener la independencia condicional, pero si la relaci√≥n entre las covariables y el outcome no es lineal (y no la conocemos) , el estimador del efecto del tratamiento puede estar sesgado. En cambio, el matching no asume una relaci√≥n lineal y puede ser m√°s robusto en estos casos, pero requiere soporte com√∫n para poder extrapolar. Si no hay soporte com√∫n, el matching no puede estimar el efecto del tratamiento en esos valores de las covariables donde no hay unidades tratadas.",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Subclasificaci√≥n y *matching*</span>"
    ]
  },
  {
    "objectID": "reg_discontinua.html#el-problema-de-controlar-por-variables-no-observables",
    "href": "reg_discontinua.html#el-problema-de-controlar-por-variables-no-observables",
    "title": "8¬† Regresi√≥n discontinua",
    "section": "8.1 El problema de controlar por variables no observables",
    "text": "8.1 El problema de controlar por variables no observables\nEn la mayor√≠a de los cap√≠tulos anteriores, vimos formas de controlar por confusores observables. Cuando hablamos de DAGs y agregar variables como covariables a un modelo de regresi√≥n o cuando usamos alg√∫n estimador de subclasificaci√≥n o matching, lo que estamos haciendo es aislar la variabilidad debida a confusores observados y sustraerla de nuestra relaci√≥n causal. Pero, ¬øQu√© pasa cuando los confusores por los que queremos controlar no son observables? Una respuesta a esta pregunta la tuvimos en el cap√≠tulo de diferencias en diferencias en el que vimos que, para un problema de una forma en particular1, la soluci√≥n era estimar el contraf√°ctico con un grupo comparable.1¬†Un problema con un tratamiento que se aplica en el tiempo y para el cual tenemos una medici√≥n antes y despu√©s para un grupo al que se le aplic√≥ el tratamiento y una medici√≥n para los mismos puntos temporales pero para un grupo comparable (para m√°s detalles ver el Cap√≠tulo¬†7).\nLa soluci√≥n que vamos a proponer en este cap√≠tulo, al igual que en diferencias en diferencias, utiliza el contexto de mi cuasiexperimento para aislar el efecto causal."
  },
  {
    "objectID": "reg_discontinua.html#c√≥mo-se-estima-el-efecto-causal",
    "href": "reg_discontinua.html#c√≥mo-se-estima-el-efecto-causal",
    "title": "8¬† Regresi√≥n discontinua",
    "section": "8.4 ¬øC√≥mo se estima el efecto causal?",
    "text": "8.4 ¬øC√≥mo se estima el efecto causal?\nSi vemos la Figura¬†8.1, podemos ver que la diferencia entre las dos rectas es el efecto del programa de tutor√≠as. Pero, ¬øc√≥mo se estima? Bueno, la forma m√°s sencilla de hacerlo es ajustar un modelo lineal a los datos y calcular la diferencia entre las ordenadas al origen de las rectas ajustadas a cada grupo. Pero esta no es la √∫nica forma de calcular el LATE. En lo que sigue vamos a explorar variantes de esta estimaci√≥n y ver c√≥mo afectan en el efecto estimado.\n\n8.4.1 Estimaci√≥n param√©trica\nUna de las alternativas que tenemos es hacer una estimaci√≥n param√©trica o no param√©trica. Pero, ¬øa qu√© nos referimos con esto? En una estimaci√≥n param√©trica, como la que vimos en el ejemplo anterior, ajustamos un modelo a los datos que est√° definido por par√°metros, como podr√≠a ser un modelo lineal.\nEl primer modelo que vamos a ajustar es el siguiente:\n\\[\ny = \\beta_0 + \\beta_1 \\text{Running variable (centrada)} + \\beta_2 \\text{indicadora del tratamiento}\n\\]\nQue en nuestro caso ser√≠a m√°s bien:\n\\[\nnota_{salida} = \\beta_0 + \\beta_1 (nota_{entrada}-70) + \\beta_2 \\mathbb{I}_{tutoria}\n\\]\ndonde \\(\\mathbb{I}_{tutoria}\\) es una variable indicadora que toma el valor de \\(1\\) si el estudiante particip√≥ del programa de tutor√≠as y \\(0\\) si no, \\(nota_{entrada}\\) es la nota del examen de entrada y \\(nota_{salida}\\) es la nota del examen de salida. Pero ¬øpor qu√© le restamos \\(70\\) a la nota de entrada? Bueno, porque queremos centrar la running variable en el umbral. Es decir, queremos que el umbral sea \\(0\\) y que los valores a la izquierda del umbral sean negativos y los valores a la derecha sean positivos. Esto nos va a permitir interpretar mejor los coeficientes del modelo6.6¬†En realidad, no es necesario centrar la running variable cuando el ajuste es una recta, pero cuando no lo es, queremos que la diferencia en ordenadas al origen (cuando la running variable vale \\(0\\)) sea el LATE. Igualmente es una buena pr√°ctica centrar la running variable.\n\n\nVer el c√≥digo\nmodelsummary(list(\"Lineal\"= modelo_lm),\n             coef_rename = c(\"entrance_centered\" = \"Nota inicial centrada\",\n                             \"tutoringS√≠\" = \"Particip√≥ en la tutor√≠a\"),\n             statistic = NULL, \n             gof_omit = \".*\",\n             output = \"gt\") |>\n  gt_highlight_rows(rows = 3, \n                    fill = \"lightyellow\",\n                    font_weight = \"bold\")\n\n\n\n\n\n\n  \n    \n       \n      Lineal\n    \n  \n  \n    (Intercept)\n59.411\n    Nota inicial centrada\n0.510\n    Particip√≥ en la tutor√≠a\n10.800\n  \n  \n  \n\n\nEstimaciones del LATE utilizando un modelo lineal.\n\n\nEl coeficiente de la variable indicadora del tratamiento es el LATE. En este caso, el modelo nos dice que el programa de tutor√≠as aumenta en 10.8 puntos la nota del examen de salida, en promedio, para los estudiantes que est√°n cerca del umbral. Si vemos la Figura¬†8.1, podemos ver que esta estimaci√≥n tiene sentido.\nTambi√©n podr√≠amos ajustar otro modelo lineal7, en el que suponemos que la relaci√≥n entre la running variable y el resultado es cuadr√°tica. No vamos a escribir el modelo porque se complica un poco ya que ajustamos una par√°bola a cada lado de la discontinuidad. Pero la idea es la misma: ajustamos un modelo lineal a los datos y calculamos la diferencia entre las estimaciones de los modelos para el umbral (la running variable centrada igual a 0)8.7¬†¬øPor qu√© esto sigue siendo un modelo lineal?8¬†Para detalles del ajuste pueden ver el c√≥digo que acompa√±a a la Figura¬†8.2.\n\n\nVer el c√≥digo\ntutoring_centered <- tutoring_centered |> \n  mutate(entrance_centered_2 = entrance_centered^2,\n         entrance_centered_3 = entrance_centered^3)\n\nmodelo_sq_1 <- lm(exit_exam ~ entrance_centered_2, \n                  data = tutoring_centered %>%\n                    filter(entrance_centered <= 0))\n\nmodelo_sq_2 <- lm(exit_exam ~ entrance_centered_2,\n                  data = tutoring_centered %>%\n                    filter(entrance_centered > 0))\n\nmodelo_cub_1 <- lm(exit_exam ~ entrance_centered_3, \n                  data = tutoring_centered %>%\n                    filter(entrance_centered <= 0))\n\nmodelo_cub_2 <- lm(exit_exam ~ entrance_centered_3,\n                  data = tutoring_centered %>%\n                    filter(entrance_centered > 0))\n\ntutoring_centered <- tutoring_centered %>%\n  add_predictions(modelo_lm, var = \"exit_pred_lm\") %>%\n  add_predictions(modelo_sq_1, var = \"exit_pred_sq1\") %>%\n  add_predictions(modelo_sq_2, var = \"exit_pred_sq2\") %>%\n  add_predictions(modelo_cub_1, var = \"exit_pred_cub1\") %>%\n  add_predictions(modelo_cub_2, var = \"exit_pred_cub2\")\n\ncolors <- c(\"Lineal\" = \"darkgreen\", \n            \"Cuadr√°tico\" = \"darkred\", \n            \"C√∫bico\" = \"darkorange\")\n\nggplot(tutoring_centered, aes(x = entrance_centered, \n                     y = exit_exam)) +\n  geom_point(size = 1.5, alpha = .2) + \n  # Agregamos una linea basada en un modelo lineal para la running variable centrada menor a 0\n  geom_line(aes(y = exit_pred_lm, color = \"Lineal\"), linewidth = 1) +\n  # Agregamos una linea basada en un modelo lineal para la running variable centrada al cuadrado menor a 0\n  geom_line(data = filter(tutoring_centered, entrance_centered <= 0), aes(y = exit_pred_sq1, color = \"Cuadr√°tico\"), \n            linewidth = 1) +\n  # Agregamos una linea basada en un modelo lineal para la running variable centrada al cuadrado mayor a 0\n  geom_line(data = filter(tutoring_centered, entrance_centered > 0), aes(y = exit_pred_sq2, color = \"Cuadr√°tico\"), \n            linewidth = 1) +\n    # Agregamos una linea basada en un modelo lineal para la running variable centrada al cubo menor a 0\n  geom_line(data = filter(tutoring_centered, entrance_centered <= 0), aes(y = exit_pred_cub1, color = \"C√∫bico\"), \n            linewidth = 1) +\n  # Agregamos una linea basada en un modelo lineal para la running variable centrada al cubo mayor a 0\n  geom_line(data = filter(tutoring_centered, entrance_centered > 0), aes(y = exit_pred_cub2, color = \"C√∫bico\"), \n            linewidth = 1) +\n  # Ponemos una l√≠nea vertical en el umbral\n  geom_vline(xintercept = 0, color = \"steelblue\", linetype = \"dashed\") + \n  # Las lables\n  labs(x = \"Puntaje en el examen de entrada (centrado)\", \n       y = \"Puntaje en el examen de salida\",\n       color = NULL,\n       fill = \"Particip√≥ en la tutor√≠a\") + \n  # Colores m√°s chetos\n  scale_color_manual(values = colors) +\n  #scale_color_brewer(palette = \"Dark2\") +\n  scale_fill_brewer(palette = \"Dark2\") +\n  # Theme sin fondo gris\n  theme_minimal() +\n  theme(legend.position = \"top\")\n\n\n\n\n\nFigura¬†8.2: Notas de entrada vs.¬†notas de salida con ajuste lineal, cuadr√°tico y c√∫bico para cada grupo.\n\n\n\n\nComo vemos en la Figura¬†8.2, depende c√≥mo ajustemos el modelo, el efecto del programa de tutor√≠as cambia. En este caso, el ajuste lineal nos da un efecto de 3.6, el cuadr√°tico de 5.7 y el c√∫bico de 3.6. Es decir, la elecci√≥n de c√≥mo ajustamos a los datos a cada lado del umbral afecta mi LATE.\nEntonces: ¬øC√≥mo decidimos qu√© ajuste usar? Esto, como vamos a ver m√°s adelante no tiene una respuesta concreta, hay que ver los datos y, m√°s importante a√∫n, ver cu√°n sensibles son nuestros resultados a estas elecciones. Por ejemplo, si al pasar de una recta a una par√°bola el efecto pasa de \\(100\\) a \\(0\\), entonces es probable que la elecci√≥n de la forma de ajuste sea importante y debamos justificarla. Si, por el contrario, el efecto no cambia mucho, entonces podemos estar m√°s tranquilos.\n\n\nVer el c√≥digo\n# Armo una tabla con los valores de los ajustes\ntutoring_centered %>%\n  summarise(\"Lineal\" = round(predict(modelo_lm, newdata = tibble(entrance_centered = 0, tutoring = \"S√≠\")) - predict(modelo_lm, newdata = tibble(entrance_centered = 0, tutoring = \"No\")), 1),\n            \"Cuadr√°tico\" = round(predict(modelo_sq_1, newdata = tibble(entrance_centered_2 = 0)) - \n                                   predict(modelo_sq_2, newdata = tibble(entrance_centered_2 = 0)), 1),\n            \"C√∫bico\" = round(predict(modelo_cub_1, newdata = tibble(entrance_centered_3 = 0)) - \n                               predict(modelo_cub_2, newdata = tibble(entrance_centered_3 = 0)), 1)) %>%\n  pivot_longer(everything(), names_to = \"Modelo\", values_to = \"LATE\") %>%\n  gt() |>\n  tab_header(title = \"Estimaciones del LATE para distintos ajustes\") %>%\n  fmt_number(columns = vars(LATE), decimals = 1) %>%\n  gt_highlight_cols(columns = 2, \n                    fill = \"lightyellow\",\n                    font_weight = \"bold\")\n#> Warning: Since gt v0.3.0, `columns = vars(...)` has been deprecated.\n#> ‚Ä¢ Please use `columns = c(...)` instead.\n\n\n\n\n\n\n  \n    \n      Estimaciones del LATE para distintos ajustes\n    \n    \n    \n      Modelo\n      LATE\n    \n  \n  \n    Lineal\n10.8\n    Cuadr√°tico\n5.7\n    C√∫bico\n3.6\n  \n  \n  \n\n\nTabla con las estimaciones de los distintos ajustes.\n\n\n\n\n8.4.2 Ancho de banda\nVolvamos a la idea de por qu√© usamos todos los datos si en realidad queremos comparar a un lado y otro del umbral. Bueno, una forma de lidiar con esto es limitar el an√°lisis a un cierto rango de la running variable. Es decir, podemos decidir que s√≥lo vamos a comparar a los estudiantes que est√°n dentro de un cierto rango del umbral. Por ejemplo, podr√≠amos decidir que s√≥lo vamos a comparar a los estudiantes que est√°n entre \\(65\\) y \\(75\\) puntos en el examen de entrada. Esto se conoce como ancho de banda y es una forma de limitar el an√°lisis a los estudiantes que est√°n m√°s cerca del umbral.\nRepitamos el ajuste lineal de los estudiantes de cada lado del umbral pero limitando el ancho de banda. Primero con ancho de banda total, luego con ancho de banda de \\(10\\) punto (es decir, s√≥lo analizando los datos entre \\(60\\) y \\(80\\) puntos) y finalmente con un ancho de banda de \\(5\\) puntos (es decir, s√≥lo analizando los datos entre \\(65\\) y \\(75\\) puntos).\n\n\nVer el c√≥digo\n# Ahora probemos bajando el bandwidth\n# BW = 10\nmodel_bw_10 <- lm(exit_exam ~ entrance_centered + tutoring,\n                  data = filter(tutoring_centered,\n                                entrance_centered >= -10 & \n                                  entrance_centered <= 10))\ntidy(model_bw_10)\n#> # A tibble: 3 √ó 5\n#>   term              estimate std.error statistic   p.value\n#>   <chr>                <dbl>     <dbl>     <dbl>     <dbl>\n#> 1 (Intercept)         60.4       0.752     80.3  2.99e-249\n#> 2 entrance_centered    0.388     0.114      3.40 7.45e-  4\n#> 3 tutoringS√≠           9.27      1.31       7.09 6.27e- 12\n\n# BW = 5\nmodel_bw_5 <- lm(exit_exam ~ entrance_centered + tutoring,\n                 data = filter(tutoring_centered,\n                               entrance_centered >= -5 & \n                                 entrance_centered <= 5))\ntidy(model_bw_5)\n#> # A tibble: 3 √ó 5\n#>   term              estimate std.error statistic   p.value\n#>   <chr>                <dbl>     <dbl>     <dbl>     <dbl>\n#> 1 (Intercept)         60.6       1.12      54.3  4.78e-118\n#> 2 entrance_centered    0.380     0.331      1.15 2.53e-  1\n#> 3 tutoringS√≠           9.12      1.91       4.77 3.66e-  6\n\n# Veamos el ajuste de cada uno de estos modelos\n# Full BW\np_full <- ggplot(tutoring, aes(x = entrance_exam, \n                               y = exit_exam, \n                               color = tutoring,\n                               fill = tutoring)) +\n  geom_point(size = 1.5, alpha = 0.5) + \n  # Add a line based on a linear model for the people scoring 70 or less\n  geom_segment(x = min(tutoring$entrance_exam), xend = 70,\n               y = modelo_lm$coefficients[1]+min(tutoring_centered$entrance_centered)*modelo_lm$coefficients[2] +\n                 modelo_lm$coefficients[3],\n               yend = modelo_lm$coefficients[1] + modelo_lm$coefficients[3],\n               color = \"gray30\", linewidth = 1) +\n  # Add a line based on a linear model for the people scoring more than 70\n  geom_segment(x = 70, xend = max(tutoring$entrance_exam),\n               y = modelo_lm$coefficients[1],\n               yend = modelo_lm$coefficients[1] + modelo_lm$coefficients[2]*max(tutoring_centered$entrance_centered),\n               color = \"gray30\", linewidth = 1) +\n  # Ponemos una l√≠nea vertical en el umbral\n  geom_vline(xintercept = 70, color = \"darkblue\", linetype = \"dashed\") + \n  # Las labels\n  labs(x = NULL, \n       y = NULL,\n       color = \"Particip√≥ en la tutor√≠a\",\n       fill = \"Particip√≥ en la tutor√≠a\") + \n  # Colores m√°s chetos\n  scale_color_brewer(palette = \"Dark2\") +\n  scale_fill_brewer(palette = \"Dark2\") +\n  # Theme sin fondo gris\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n\n# BW = 10\np_bw10 <- tutoring_centered |>\n  dplyr::filter(between(entrance_centered, -10, 10)) |>\n  ggplot(aes(x = entrance_exam, \n             y = exit_exam, \n             color = tutoring,\n             fill = tutoring)) +\n  geom_point(size = 1.5, alpha = 0.5) + \n  geom_point(data = tutoring_centered |>\n               dplyr::filter(!between(entrance_centered, -10, 10)), \n             size = 1.5, alpha = 0.3, color = \"gray\") + \n  # Add a line based on a linear model for the people scoring 70 or less\n  geom_segment(x = 60, xend = 70,\n               y = model_bw_10$coefficients[1]-10*model_bw_10$coefficients[2] +\n                 model_bw_10$coefficients[3],\n               yend = model_bw_10$coefficients[1] + model_bw_10$coefficients[3],\n               color = \"gray30\", linewidth = 1) +\n  # Add a line based on a linear model for the people scoring more than 70\n  geom_segment(x = 70, xend = 80,\n               y = model_bw_10$coefficients[1],\n               yend = model_bw_10$coefficients[1] + model_bw_10$coefficients[2]*10,\n               color = \"gray30\", linewidth = 1) +\n  # Ponemos una l√≠nea vertical en el umbral\n  geom_vline(xintercept = 70, color = \"darkblue\", linetype = \"dashed\") + \n  # Las labels\n  labs(x = NULL, \n       y = \"Puntaje en el examen de salida\",\n       color = \"Particip√≥ en la tutor√≠a\",\n       fill = \"Particip√≥ en la tutor√≠a\") + \n  # Colores m√°s chetos\n  scale_color_brewer(palette = \"Dark2\") +\n  scale_fill_brewer(palette = \"Dark2\") +\n  # Theme sin fondo gris\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n# BW = 5\np_bw5 <- tutoring_centered |>\n  dplyr::filter(between(entrance_centered, -5, 5)) |>\n  ggplot(aes(x = entrance_exam, \n             y = exit_exam, \n             color = tutoring,\n             fill = tutoring)) +\n  geom_point(size = 1.5, alpha = 0.5) + \n  geom_point(data = tutoring_centered |>\n               dplyr::filter(!between(entrance_centered, -5, 5)), \n             size = 1.5, alpha = 0.3, color = \"gray\") + \n  # Add a line based on a linear model for the people scoring 70 or less\n  geom_segment(x = 65, xend = 70,\n               y = model_bw_5$coefficients[1]-5*model_bw_5$coefficients[2] +\n                 model_bw_5$coefficients[3],\n               yend = model_bw_5$coefficients[1] + model_bw_5$coefficients[3],\n               color = \"gray30\", linewidth = 1) +\n  # Add a line based on a linear model for the people scoring more than 70\n  geom_segment(x = 70, xend = 75,\n               y = model_bw_5$coefficients[1],\n               yend = model_bw_5$coefficients[1] + model_bw_5$coefficients[2]*5,\n               color = \"gray30\", linewidth = 1) +\n  # Ponemos una l√≠nea vertical en el umbral\n  geom_vline(xintercept = 70, color = \"darkblue\", linetype = \"dashed\") + \n  # Las labels\n  labs(x = \"Puntaje en el examen de entrada\", \n       y = NULL,\n       color = \"Particip√≥ en la tutor√≠a\",\n       fill = \"Particip√≥ en la tutor√≠a\") + \n  # Colores m√°s chetos\n  scale_color_brewer(palette = \"Dark2\") +\n  scale_fill_brewer(palette = \"Dark2\") +\n  # Theme sin fondo gris\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\nlibrary(patchwork)\np_full / p_bw10 / p_bw5 + plot_layout(guides = \"collect\")\n\n\n\n\n\nEstimaciones del LATE utilizando un modelo lineal con distintos anchos de banda.\n\n\n\n\nEn la figura vemos que los ajustes son ligeramente distintos, pero no se llega a ver una difrencia. Qu√© pasa si vemos las estimaciones del modelo:\n\n\nVer el c√≥digo\n# Las estimaciones y el sample size\nmodelsummary(list(\"Full data\" = modelo_lm, \n                  \"Bandwidth = 10\" = model_bw_10, \n                  \"Bandwidth = 5\" = model_bw_5), \n             coef_rename = c(\"entrance_centered\" = \"Nota inicial centrada\",\n                             \"tutoringS√≠\" = \"Particip√≥ en la tutor√≠a\"),\n             gof_omit = 'DF|Deviance|R2|AIC|BIC|Log.Lik|F|RMSE',\n             statistic = \"p = {p.value}\", \n             output = \"gt\") |>\n  gt_highlight_rows(rows = 5, \n                    fill = \"lightyellow\",\n                    font_weight = \"bold\") |>\n  gt_highlight_rows(rows = 7, \n                    fill = \"lightyellow\",\n                    font_weight = \"bold\")\n\n\n\n\n\n\n  \n    \n       \n      Full data\n      Bandwidth = 10\n      Bandwidth = 5\n    \n  \n  \n    (Intercept)\n59.411\n60.377\n60.631\n    \np = <0.001\np = <0.001\np = <0.001\n    Nota inicial centrada\n0.510\n0.388\n0.380\n    \np = <0.001\np = <0.001\np = 0.253\n    Particip√≥ en la tutor√≠a\n10.800\n9.273\n9.122\n    \np = <0.001\np = <0.001\np = <0.001\n    Num.Obs.\n1000\n404\n194\n  \n  \n  \n\n\n\n\nHay tres cosas que quiero que vean. Primero, que el LATE es bastante similar en los tres casos pero se ve afectado por el ancho de banda. Segundo, el ancho de banda afecta el tama√±o de la muestra y, por lo tanto, la potencia estad√≠stica. Y tercero, algo de lo que no hab√≠amos hablado hasta el momento era de la variabilidad de las estimaciones. Por ejemplo, en este caso que el LATE es un par√°metro de un modelo lineal como los que ya conocemos, podemos utilizar las herramientas usuales de inferencia estad√≠stica (como el p-valor que ven abajo de la estimaci√≥n en la tabla) para sacar conclusiones al respecto.\n\n\n8.4.3 Kernels\nComo vimos, achicar el ancho de banda mejorar√≠a la estimaci√≥n (porque estamos considerando a los sujetos m√°s ‚Äúparecido‚Äù) pero disminuye el tama√±o de muestra efectivo. Una alternativa a esto es conservar el ancho de banda pero darle m√°s peso a los puntos que est√°n cerca del umbral. Por ejemplo, podr√≠amos darle m√°s peso a los puntos que est√°n a \\(1\\) punto del umbral que a los que est√°n a \\(10\\) puntos. Esto se hace utilizando un kernel. Un kernel es una funci√≥n que asigna un peso a cada punto en funci√≥n de su distancia al umbral. Los kernels pueden tener diversas formas, como triangular o gaussiano9.9¬†Cuando achicamos el ancho de banda en la secci√≥n anterior podemos considerar como si hubi√©ramos utilizado un kernel rectangular, es decir, que todos los puntos dentro del ancho de banda tienen el mismo peso.\nDejenme mostrarles la forma de algunos kernels que vamos a probar:\n\n\nVer el c√≥digo\nkernels <- tibble(x = seq(-1.5, 1.5, length.out = 200)) %>%\n  mutate(rectangular = ifelse(abs(x) <= 1, 1, 0),\n         triangular = ifelse(abs(x) <= 1, 1 - abs(x), 0),\n         epanechnikov = ifelse(abs(x) <= 1, 0.75 * (1 - x^2), 0))\n\nggplot(kernels, aes(x = x)) +\n  geom_line(aes(y = rectangular, color = \"Rectangular\"), size = 1) +\n  geom_line(aes(y = triangular, color = \"Triangular\"), size = 1) +\n  geom_line(aes(y = epanechnikov, color = \"Epanechnikov\"), size = 1) +\n  labs(x = \"Distancia al umbral\", y = \"Peso\", color = NULL) +\n  scale_color_brewer(palette = \"Dark2\") +\n  theme_minimal() +\n  theme(legend.position = \"top\")\n#> Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n#> ‚Ñπ Please use `linewidth` instead.\n\n\n\n\n\nKernel rectancular, triangular y Epanechnikov.\n\n\n\n\nPodemos ver que cada kernel pesa los puntos de forma distinta. El kernel rectangular le da el mismo peso a todos los puntos dentro del ancho de banda, el triangular le da m√°s peso a los puntos que est√°n cerca del umbral y el Epanechnikov es un poco menos √°gudo que el triangular.\nLa elecci√≥n del kernel, al igual que en el caso del ancho de banda, afecta la estimaci√≥n del LATE.\n\n\n8.4.4 Ajustes no param√©tricos\nFinalmente, una alternativa bastante usual es la de estimar el LATE utilizando un ajuste no param√©trico. Esto significa que no vamos a asumir una forma funcional espec√≠fica para la relaci√≥n entre la running variable y el outcome. En cambio, vamos a utilizar t√©cnicas como los splines o los Locally estimated/weighted scatterplot smoothing (LOESS) para ajustar una curva a los datos.\nPor ejemplo, veamos c√≥mo se ve la estimaci√≥n del LATE en este caso.\n\n\nVer el c√≥digo\nggplot(tutoring_centered, aes(x = entrance_centered, \n                              y = exit_exam, \n                              color = tutoring,\n                              fill = tutoring)) +\n  geom_point(size = 1.5, alpha = .3) + \n  # Agregamos una linea basada en un modelo lineal para la running variable menor a 70\n  geom_smooth(data = filter(tutoring_centered, tutoring == \"S√≠\")) +\n  # Agregamos una linea basada en un modelo lineal para la running variable mayor a 70\n  geom_smooth(data = filter(tutoring_centered, tutoring == \"No\")) +\n  # Ponemos una l√≠nea vertical en el umbral\n  geom_vline(xintercept = 0, color = \"darkblue\", linetype = \"dashed\") + \n  # Las lables\n  labs(x = \"Puntaje en el examen de entrada (centrado)\", \n       y = \"Puntaje en el examen de salida\",\n       color = \"Particip√≥ en la tutor√≠a\",\n       fill = \"Particip√≥ en la tutor√≠a\") + \n  # Colores m√°s chetos\n  scale_color_brewer(palette = \"Dark2\") +\n  scale_fill_brewer(palette = \"Dark2\") +\n  # Theme sin fondo gris\n  theme_minimal() +\n  theme(legend.position = \"top\")\n#> `geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n#> `geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\nEn este caso estamos usando la funci√≥n de regresi√≥n local geom_smooth() de ggplot2 para ajustar una curva a los datos. Esta funci√≥n utiliza un ajuste LOESS por defecto, pero tambi√©n podemos especificar otros m√©todos de ajuste. Podemos ver que no se trata de una curva suave sino m√°s bien de una especie de promedio m√≥vil pesado que va siguiendo a los puntos.\nEn la estimaci√≥n no param√©trica como en la param√©trica vamos a calcular el LATE como la diferencia entre las estimaciones del modelo de cada lado del umbral, y como en el caso anterior, la elecci√≥n del ancho de banda y del kernel afecta la estimaci√≥n del LATE.\nAc√° ya no es tan f√°cil obtener la estimaci√≥n del efecto ajustando modelos lineales as√≠ que vamos a hechar mano de un paquete para esto: rdrobust. Este paquete nos permite ajustar modelos de regresi√≥n discontinua de forma sencilla y r√°pida, y nos da una serie de opciones para ajustar el ancho de banda y el kernel. Empecemos utilizando los valores por defecto.\n\nfull <- rdrobust(y = tutoring$exit_exam, x = tutoring$entrance_exam, c = 70) \n#> Warning in rdrobust(y = tutoring$exit_exam, x = tutoring$entrance_exam, :\n#> Mass points detected in the running variable.\nsummary(full)\n#> Sharp RD estimates using local polynomial regression.\n#> \n#> Number of Obs.                 1000\n#> BW type                       mserd\n#> Kernel                   Triangular\n#> VCE method                       NN\n#> \n#> Number of Obs.                  237          763\n#> Eff. Number of Obs.             144          256\n#> Order est. (p)                    1            1\n#> Order bias  (q)                   2            2\n#> BW est. (h)                   9.969        9.969\n#> BW bias (b)                  14.661       14.661\n#> rho (h/b)                     0.680        0.680\n#> Unique Obs.                     155          262\n#> \n#> =============================================================================\n#>         Method     Coef. Std. Err.         z     P>|z|      [ 95% C.I. ]       \n#> =============================================================================\n#>   Conventional    -8.578     1.601    -5.359     0.000   [-11.715 , -5.441]    \n#>         Robust         -         -    -4.352     0.000   [-12.101 , -4.587]    \n#> =============================================================================\n\nVemos que hay mucha informaci√≥n, como el kernel (triangular), el ancho de banda (\\(9.969\\))10, el n√∫mero de observaciones, etc. M√°s interesante, al final podemos ver la estimaci√≥n del LATE que en este caso, el LATE es de 8.6 puntos.10¬†La estimaci√≥n del ancho de banda utiliza un algoritmo data-drive al que no vamos a entrar en detalle, pero que se basa en la idea de que el ancho de banda √≥ptimo es aquel que minimiza el error cuadr√°tico medio de la estimaci√≥n del LATE. Si quieren ver m√°s detalles pueden consultar la documentaci√≥n del paquete rdrobust.\nVamos a ver el ajuste qu√© pinta tiene utilizando la funci√≥n rdplot() del mismo paquete. Esta funci√≥n nos permite visualizar el ajuste de la regresi√≥n discontinua y ver c√≥mo se ve la estimaci√≥n del LATE.\n\n\nVer el c√≥digo\nrdplot(y = tutoring$exit_exam, x = tutoring$entrance_exam, c = 70) \n#> [1] \"Mass points detected in the running variable.\"\n\n\n\n\n\nEstimaci√≥n del LATE utilizando un ajuste no param√©trico.\n\n\n\n\n¬øC√≥mo cambia esta estimaci√≥n si duplicamos el ancho de banda?\n\n\nVer el c√≥digo\ndoble <- rdrobust(y = tutoring$exit_exam, x = tutoring$entrance_exam, c = 70, h = 9.969 * 2)\nrdplot(y = tutoring$exit_exam, x = tutoring$entrance_exam, c = 70, h = 2*9.969)\n#> [1] \"Mass points detected in the running variable.\"\n\n\n\n\n\nEstimaci√≥n del LATE utilizando un ajuste no param√©trico con el doble del ancho de banda estimado de los datos.\n\n\n\n\nVeamos las estimaciones del LATE para el ancho de banda completo, el doble y la mitad del ancho de banda estimado.\n\n\nVer el c√≥digo\n# Un approach posible es usar el recomendado, el doble y la mitad\nmitad <- rdrobust(y = tutoring$exit_exam, x = tutoring$entrance_exam, c = 70, h = 9.969 * 0.5) \n\ntibble(BW = c(\"Full = 9.97\", \"Doble = 19.94\", \"Mitad = 4.99\"),\n       Estimate = -round(c(full$Estimate[1], doble$Estimate[1], mitad$Estimate[1]), 3)) |> \n  gt()\n\n\n\n\n\n\n  \n    \n      BW\n      Estimate\n    \n  \n  \n    Full = 9.97\n8.578\n    Doble = 19.94\n9.151\n    Mitad = 4.99\n8.201\n  \n  \n  \n\n\n\n\nSi bien hay diferencias, podemos ver que la estimaci√≥n es bastante consistente, algo que es deseable y que nos indica que, al menos en esa regi√≥n, el efecto es relativamente constante.\nAlgo que podemos modificar tambi√©n es el kernel utilizado. Cambiemos de triangular a uniforme y veamos el ajuste.\n\n\nVer el c√≥digo\nrdplot(y = tutoring$exit_exam, x = tutoring$entrance_exam, c = 70, h = 9.969, kernel = \"uniform\")\n#> [1] \"Mass points detected in the running variable.\"\n\n\n\n\n\nEstimaci√≥n del LATE utilizando un ajuste no param√©trico con kernel uniforme.\n\n\n\n\nY veamos c√≥mo esta elecci√≥n afecta a la estimaci√≥n del LATE.\n\n\nVer el c√≥digo\ntriangular <- rdrobust(y = tutoring$exit_exam, x = tutoring$entrance_exam, c = 70, kernel = \"triangular\")\n#> Warning in rdrobust(y = tutoring$exit_exam, x = tutoring$entrance_exam, :\n#> Mass points detected in the running variable.\nepanechnikov <- rdrobust(y = tutoring$exit_exam, x = tutoring$entrance_exam, c = 70, kernel = \"epanechnikov\")\n#> Warning in rdrobust(y = tutoring$exit_exam, x = tutoring$entrance_exam, :\n#> Mass points detected in the running variable.\nuniforme <- rdrobust(y = tutoring$exit_exam, x = tutoring$entrance_exam, c = 70, kernel = \"uniform\")\n#> Warning in rdrobust(y = tutoring$exit_exam, x = tutoring$entrance_exam, :\n#> Mass points detected in the running variable.\n\ntibble(Kernel = c(\"Triangular\", \"Epanechnikov\", \"Uniforme\"),\n       Estimate = -round(c(triangular$Estimate[1], epanechnikov$Estimate[1], uniforme$Estimate[1]), 3)) |> \n  gt()\n\n\n\n\n\n\n  \n    \n      Kernel\n      Estimate\n    \n  \n  \n    Triangular\n8.578\n    Epanechnikov\n8.389\n    Uniforme\n8.175\n  \n  \n  \n\n\n\n\nDe nuevo, vemos que no hay grandes cambios.\n\n\n8.4.5 ¬øC√≥mo tomamos decisiones?\nCreo que de la secci√≥n anterior ya queda un poco claro c√≥mo es la mano: Hay que probar y ver que pasa. Es muy importante que las estimaciones del LATE sean robustas a las decisiones que tomamos. Por ejemplo, si al cambiar el ancho de banda o el kernel la estimaci√≥n del LATE cambia dr√°sticamente, entonces tenemos que pensar por qu√© y justificar nuestra elecci√≥n. Si, por el contrario, la estimaci√≥n es bastante consistente, entonces podemos estar m√°s tranquilos.\nMiremos que hacen, por ejemplo, en Schafer y Holbein (2020). En la siguiente figura se estima el efecto para distintos valores de la running variable (en este caso, la diferencia de horas entre el horario de verano y el horario est√°ndar) y se ve que la estimaci√≥n del LATE es bastante consistente11.11¬†BONUS: ¬øPor qu√© creen que la estimaci√≥n del ancho de banda m√°s chico tiene el error m√°s grande?\n\n\n\nTama√±o del efecto estimado en Schafer y Holbein (2020) en funci√≥n del ancho de banda.\n\n\nEn nuestro ejemplo de juguete podemos hacer algo parecido, comparar todas las estimaciones que fuimos haciendo a lo largo del cap√≠tulo:\n\n\nVer el c√≥digo\ntabla_results <- tibble(M√©todo = c(rep(\"Param√©trico\", 3), rep(\"No param√©trico\", 5)),\n                        Kernel = c(rep(\"No pesado\",3), rep(\"Triangular\",3), \"Epanechnikov\", \"Uniforme\"),\n                        BW = c(\"Full\", 10, 5, round(c(full$bws[1,1], doble$bws[1,1], mitad$bws[1,1], epanechnikov$bws[1,1], uniforme$bws[1,1]), 3)),\n                        Estimate = round(c(modelo_lm$coefficients[3], model_bw_10$coefficients[3], model_bw_5$coefficients[3], \n                                           -full$Estimate[1], -doble$Estimate[1], -mitad$Estimate[1], -epanechnikov$Estimate[1], -uniforme$Estimate[1]), 3))\n\ntabla_results |> \n  gt() |>\n  gt_highlight_rows(rows = 4, \n                    fill = \"lightyellow\",\n                    font_weight = \"bold\")\n\n\n\n\n\n\n  \n    \n      M√©todo\n      Kernel\n      BW\n      Estimate\n    \n  \n  \n    Param√©trico\nNo pesado\nFull\n10.800\n    Param√©trico\nNo pesado\n10\n9.273\n    Param√©trico\nNo pesado\n5\n9.122\n    No param√©trico\nTriangular\n9.969\n8.578\n    No param√©trico\nTriangular\n19.938\n9.151\n    No param√©trico\nTriangular\n4.984\n8.201\n    No param√©trico\nEpanechnikov\n8.201\n8.389\n    No param√©trico\nUniforme\n7.346\n8.175\n  \n  \n  \n\n\n\n\nVemos que, en general, no hay grandes diferencias entre las estimaciones del efecto. La l√≠nea resaltada es tal vez el efecto que elegir√≠a si tuviera que quedarme con uno, ya que el ancho de banda est√° elegido basado en los datos, el ajuste es no param√©trico y el kernel le da m√°s importancia a los datos cerca del umbral. Pero, como vimos en Schafer y Holbein (2020), tal vez sea una buena idea presentar todas las estimaciones y discutirlas.\n\nSchafer, Jerome, y John B Holbein. 2020. ¬´When time is of the essence: A natural experiment on how time constraints influence elections¬ª. The Journal of Politics 82 (2): 418-32."
  },
  {
    "objectID": "reg_discontinua.html#limitaciones-de-la-regresi√≥n-discontinua",
    "href": "reg_discontinua.html#limitaciones-de-la-regresi√≥n-discontinua",
    "title": "8¬† Regresi√≥n discontinua",
    "section": "8.5 Limitaciones de la regresi√≥n discontinua",
    "text": "8.5 Limitaciones de la regresi√≥n discontinua\nLa regresi√≥n discontinua es una herramienta muy interesante y con mucho auge en la investigaci√≥n causal, especialmente cuando tenemos confusores no observados. Pero, como vimos, requiere de algunas condiciones particulares para poder aplicarla: tener una running variable que sea continua y que tenga un umbral, y que los sujetos a uno y otro lado del umbral sean comparables (ya vamos a hablar un poco de esto). En esta secci√≥n vamos a nombrar brevemente tres de las pincipales limitacinoes de la regresi√≥n discontinua.\n\n8.5.1 Es data greedy\nUna de las principales limitaciones de la regresi√≥n discontinua es que requiere una gran cantidad de datos para poder estimar el efecto causal. Esto se debe a que los sujetos que son comparables para una estimaci√≥n confiables del LATE son aquellos que est√°n cerca del umbral. Por lo tanto, nuestra muestra puede ser grande, pero una vez que fijamos el ancho de banda se puede reducir notablemente.\n\n\n8.5.2 Es limitada en alcance\nOtra limitaci√≥n de la regresi√≥n discontinua es que el efecto estimado es local, es decir, s√≥lo es v√°lido para los sujetos que est√°n cerca del umbral. Esto significa que no debemos generalizar esta estimaci√≥n a toda la poblaci√≥n, es decir, tenemos un problema de validez externa. Esto podr√≠a ser un problema ya que normalmente queremos estimar el efecto para la poblaci√≥n de inter√©s.\nAc√° cabe una breve reflexi√≥n: ¬øNo son todos los efectos que calculamos de alg√∫n modo locales? Entonces, resulta interesante pensar cu√°les son las condiciones necesarias para que el LATE estimado sea generalizable. Por ejemplo: ¬øCreen que el ejemplo del padr√≥n electoral es generalizable? Cada problema se enfrenta con esa pregunta y cada respuesta requiere de un conocimiento del dominio y de la muestra con la que se est√° trabajando para responderla.\n\n\n8.5.3 Puede haber problemas de manipulaci√≥n\nRecordemos algo: Al asumir que los participantes de un lado y del otro de la discontinuidad son comparables, estamos asumiendo que hay continuidad en la esperanza de los potential outcomes, es decir, que si un sujeto estuviera en el grupo tratamiento tendr√≠a en el umbral el mismo outcome que tendr√≠a un miembro del grupo control si hubiera sido asignado al tratamiento. Es un trabalenguas, ¬øno? Veamos primero las cuentas y pensemos despu√©s en un ejemplo.\nCon continuidad de los potential outcomes nos referimos a que los potential outcomes no cambian abruptamente en el umbral, es decir, que la esperanza de los potential outcomes es continua en el umbral. En dif√≠cil: que \\(E[Y_i^1]\\) y \\(E[Y_i^0]\\) son continuas en el umbral. En t√©rminos de la running variable \\(X\\) y siendo su umbral \\(c\\), esto significa que:\n\\[\n\\begin{align*}\n\\lim_{x \\to c^-} E[Y_i^1] = \\lim_{x \\to c^+} E[Y_i^1] \\\\\n\\lim_{x \\to c^-} E[Y_i^0] = \\lim_{x \\to c^+} E[Y_i^0]\n\\end{align*}\n\\]\nO gr√°ficamente:\n\n\nVer el c√≥digo\nset.seed(123)\ndata <- tibble(x = runif(200, -10, 10),\n               y = x + c(rnorm(100, mean = 5, sd = 2), \n                     rnorm(100, mean = 0, sd = 2)),\n               outcome = c(rep(\"Y1\", 100), rep(\"Y0\", 100))) %>%\n  mutate(status = if_else((outcome == \"Y1\" & x>0) | (outcome == \"Y0\" & x<=0), \n                          \"Observable\", \"Contraf√°ctico\"))\n\nlines <- tibble(intercept = c(5, 0),\n                slope = c(1, 1),\n                outcome = c(\"Y1\", \"Y0\"))\n\nggplot(data, aes(x = x, y = y, color = outcome)) +\n  geom_point(aes(alpha = status), size = 2) +\n  geom_vline(xintercept = 0, linetype = \"dashed\", color = \"darkblue\") +\n  geom_abline(data = lines, aes(slope = slope, intercept = intercept, color = outcome), linewidth = 1) +\n  labs(x = \"Running variable (X)\", \n       y = \"Potential outcomes (Y)\",\n       color = NULL,\n       alpha = NULL) +\n  scale_color_brewer(palette = \"Dark2\") +\n  scale_alpha_manual(values = c(.2, 1)) +\n  theme_minimal() +\n  theme(legend.position = \"top\", legend.box=\"vertical\")\n\n\n\n\n\nContinuidad de los potential outcomes en el umbral.\n\n\n\n\nEn esta figura vemos como puntos llenos a los observables y como puntos grisados a los contraf√°cticos, las l√≠neas, son las esperanzas de estos outcomes. Lo que nos interesa pensar es que, si bien en los datos observados vemos un salto al cruzar el umbral (es decir, al pasar de no estar expuesto a estar expuesto al tratamiento), si pudi√©ramos observar los potential outcomes al cruzar el umbral ver√≠amos que son continuos. Es decir, que si un sujeto estuviera en el grupo tratamiento tendr√≠a en el umbral el mismo outcome que que tendr√≠a un miembro del grupo control si hubiera sido asignado al tratamiento.\nPensemos qu√© implicancias tiene esto. Esto significa que la running variable no puede ser manipulada por los sujetos. Es decir, que los sujetos no pueden elegir estar a un lado o del otro del umbral. Por ejemplo, si por alg√∫n motivo en nuestro ejemplo los alumnos conocieran la regla de selecci√≥n y se sacaran peor nota para tener una tutor√≠a gratuita, en ese caso estar√≠amos hablando de manipulaci√≥n y la estimaci√≥n del efecto del tratamiento estar√≠a sesgada.\nVamos con un ejemplo bien concreto. Imaginemos que queremos evaluar la pol√≠tica p√∫blica de la que hablamos al principio del cap√≠tulo, esa a la que uno califica por cobrar menos de $\\(350000\\) mensuales. Imaginen que soy un cuentapropista que tengo ese beneficio y a dos d√≠as de terminar el mes ya factur√© $\\(349999\\). De golpe me llaman para ofrecerme un trabajo de $\\(500\\), ¬øqu√© creen que voy a decir? Bueno, si la pol√≠tica es lo suficientemente beneficiosa (m√°s que $\\(499\\)) probablemente voy a decir que no. ¬øPor qu√©? Porque si acepto el trabajo, voy a perder el beneficio de la pol√≠tica p√∫blica. Entonces, en este caso, la running variable (mi ingreso mensual) fue manipulado y, por lo tanto, la continuidad de los potential outcomes no se cumple. S√© que es un ejemplo un poco irreal, pero t√≥mense el tiempo de pensar cu√°ntas veces podemos ver este tipo de manipulaci√≥n en la vida real.\nExisten diversas formas de detectar la manipulaci√≥n en los datos. Una de las m√°s comunes es la de observar la densidad de la running variable alrededor del umbral. Si hay manipulaci√≥n, deber√≠amos ver un salto en la densidad de la running variable en el umbral. Esto se debe a que los sujetos que est√°n cerca del umbral son los que tienen m√°s probabilidades de ser manipulados. Existe algo llamado test de densidad de McCrary que sirve para verificar esto (McCrary (2008)), pero no vamos a entrar en demasiado detalle. Este test est√° implementado en la funci√≥n rddensity() del paquete rddensity.\n\nMcCrary, Justin. 2008. ¬´Manipulation of the running variable in the regression discontinuity design: A density test¬ª. Journal of econometrics 142 (2): 698-714.\nVeamos c√≥mo se ve la densidad de la running variable en nuestro ejemplo de las tutor√≠as (utilizando las funciones rddensity y rdplotdensity).\n\n\nVer el c√≥digo\ntest_density <- rddensity(tutoring$entrance_exam, c = 70)\nplot_density_test <- rdplotdensity(rdd = test_density, \n                                   X = tutoring$entrance_exam, \n                                   type = \"both\")\n\n\n\n\n\nTesteamos la posible manipulaci√≥n en el ejemplo de las tutor√≠as.\n\n\n\n\nEs razonable decir que no hay manipulaci√≥n ¬øno?"
  },
  {
    "objectID": "reg_discontinua.html#un-ejemplo-to-rule-them-all-1",
    "href": "reg_discontinua.html#un-ejemplo-to-rule-them-all-1",
    "title": "8¬† Regresi√≥n discontinua",
    "section": "8.4 Un ejemplo to rule them all",
    "text": "8.4 Un ejemplo to rule them all",
    "crumbs": [
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Regresi√≥n discontinua</span>"
    ]
  },
  {
    "objectID": "reg_discontinua.html#one-rule-to-rule-them-all",
    "href": "reg_discontinua.html#one-rule-to-rule-them-all",
    "title": "8¬† Regresi√≥n discontinua",
    "section": "8.2 One rule to rule them all",
    "text": "8.2 One rule to rule them all\nLa idea b√°sica detr√°s de la regresi√≥n discontinua es que la separaci√≥n entre grupo tratamiento y control est√° dada por una discontinuidad en alguna variable2. Es decir, a partir de un cierto valor de esta variable un sujeto es asignado a un determinado grupo. Por ejemplo, a partir un valor de ingreso mensual, un individuo podr√≠a tener acceso a un programa de ayuda social. Supongamos que ese l√≠mite es $\\(350000\\) mensuales. ¬øEn qu√© se diferencian dos individuos que cobran $\\(349999\\) y $\\(350001\\) respectivamente? Probablemente en mucho, ¬øno? Pero ¬øy si comparamos \\(100\\) individuos de cada ingreso? Es bastante razonable pensar que en todas las dem√°s caracter√≠sticas, estos individuos son comparables. Es decir, que la √∫nica diferencia entre ellos es que uno de ellos accede a un programa social y el otro no. Bueno, es en esta idea en la que se cimenta (ah bueno, se puso fino el autor) la regresi√≥n discontinua. En l√≠neas generales vamos a comprar unidades experimentales cerquita de un lado del umbral de la running variable con unidades experimentales cerquita del otro lado del umbral.2¬†Que a partir de ahora llamaremos running variable.\nEmpecemos a jugar con un ejemplo con datos simulados. En este ejemplo tenemos datos de la asignaci√≥n de estudiantes de un curso de estad√≠stica a un programa de tutor√≠as. La cosa es as√≠: Los estudiantes se someten a un examen inicial y dependiendo de su puntaje, son asignados a un programa de tutor√≠as o no. El umbral para la asignaci√≥n es un puntaje de \\(70\\) puntos. Si el estudiante saca menos de \\(70\\) puntos, participa del programa de tutor√≠as. Si saca \\(70\\) o m√°s, no participa. Luego, a cada estudiante se le eval√∫a con un examen final. La pregunta que nos hacemos es: ¬øEl programa de tutor√≠as mejora el puntaje en el examen final? Veamos qu√© pinta tienen los datos viendo las primeras 5 filas del dataset.\n\n\nVer el c√≥digo\ntutoring <- read_csv(here(\"data/tutoring_program.csv\")) %>% \n  mutate(tutoring = factor(tutoring, levels = c(FALSE, TRUE), \n                           labels = c(\"No\", \"S√≠\")))\n#> Rows: 1000 Columns: 4\n#> ‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n#> Delimiter: \",\"\n#> dbl (3): id, entrance_exam, exit_exam\n#> lgl (1): tutoring\n#> \n#> ‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n#> ‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ntutoring %>%\n  head() %>%\n  gt()\n\n\n\n\n\n\n  \n    \n      id\n      entrance_exam\n      exit_exam\n      tutoring\n    \n  \n  \n    1\n92.4\n78.1\nNo\n    2\n72.8\n58.2\nNo\n    3\n53.7\n62.0\nS√≠\n    4\n98.3\n67.5\nNo\n    5\n69.7\n54.1\nS√≠\n    6\n68.1\n60.1\nS√≠\n  \n  \n  \n\n\n\n\nPor ejemplo, vemos que el estudiante de la primera fila tiene un puntaje de \\(92.4\\) puntos en el examen de entrada y, efectivamente, no participa en el programa de tutor√≠as. Por otro lado, el estudiante de la tercera fila, con sus magros \\(53.7\\) puntos en el examen de entrada, s√≠ particip√≥ del programa de tutor√≠as.\nVeamos las notas de entrada y como afecta eso a la participaci√≥n en las tutor√≠as:\n\n\nVer el c√≥digo\nrect_claro <- tibble(xmin = 65, xmax = 75, ymin = 0, ymax = 3)\n\nggplot(tutoring) +\n  # Los rect√°ngulos\n  geom_rect(data = rect_claro, aes(xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax), \n            fill = \"gray20\", color = \"white\", alpha = .2) +\n  # Hacemos los puntos semitransparentes y los movemos un poco\n  geom_point( aes(x = entrance_exam, \n                  y = tutoring, \n                  color = tutoring),\n              size = 1.5, alpha = 0.5, \n             position = position_jitter(width = 0, height = 0.25, seed = 1234)) + \n  # Ponemos una l√≠nea vertical en el umbral\n  geom_vline(xintercept = 70, color = \"yellow\", linetype = \"dashed\") + \n  # Labels\n  labs(x = \"Puntaje en el examen de entrada\", y = \"Participaci√≥n en el programa de tutor√≠as\") + \n  # Sac√≥ la leyenda de color\n  guides(color = FALSE) +\n  # Colores m√°s chetos\n  scale_color_brewer(palette = \"Dark2\") +\n  # Theme sin fondo gris\n  theme_minimal()\n#> Warning: The `<scale>` argument of `guides()` cannot be `FALSE`. Use \"none\" instead\n#> as of ggplot2 3.3.4.\n\n\n\n\n\nEfecto de las notas de entrada (la running variable) en la participaci√≥n en las tutor√≠as.\n\n\n\n\nVemos claramente que los estudiantes con m√°s de \\(70\\) puntos en el examen de entrada no participan del programa de tutor√≠as, mientras que los que sacaron menos de \\(70\\) s√≠. Parece que el umbral divide bastante bien a los grupos. Pero, pensando de nuevo en el ejemplo del ingreso, ¬øqu√© pasa con los estudiantes que sacaron puntajes cercanos a \\(70\\)? ¬øSon comparables? ¬øPodemos asumir que la √∫nica diferencia entre ellos es la participaci√≥n en el programa de tutor√≠as? Es razonable asumir que s√≠.\nRecordemos que la pregunta era ¬øc√≥mo afecta el programa de tutor√≠as a la nota del examen final de los alumnos? Vamos a ver las notas de entrada y de salida de cada individuo en un gr√°fico. En el mismo gr√°fico vamos a colorear los puntos seg√∫n si el estudiante particip√≥ o no del programa de tutor√≠as y vamos a marcar como una l√≠nea vertical el umbral de \\(70\\) puntos en el examen de entrada.\n\n\nVer el c√≥digo\n# Ahora miremos como se comporta la variable outcomes en funci√≥n de la running variable ####\nggplot(tutoring, aes(x = entrance_exam, \n                     y = exit_exam, \n                     color = tutoring,\n                     fill = tutoring)) +\n  geom_point(size = 1.5, alpha = .3) + \n  # Ponemos una l√≠nea vertical en el umbral\n  geom_vline(xintercept = 70, color = \"steelblue\", linetype = \"dashed\") + \n  # Las lables\n  labs(x = \"Puntaje en el examen de entrada\", \n       y = \"Puntaje en el examen de salida\",\n       color = \"Particip√≥ en la tutor√≠a\",\n       fill = \"Particip√≥ en la tutor√≠a\") + \n  # Colores m√°s chetos\n  scale_color_brewer(palette = \"Dark2\") +\n  scale_fill_brewer(palette = \"Dark2\") +\n  # Theme sin fondo gris\n  theme_minimal() +\n  theme(legend.position = \"top\")\n\n\n\n\n\nNotas de entrada vs.¬†notas de salida.\n\n\n\n\nPareciera que hay una relaci√≥n entre la nota de entrada y de salida. Esto tiene bastante sentido, ya que es esperable que los estudiantes a los que les fue bien a la entrada les vaya bien a la salida. Pero tambi√©n se ve otra cosa, en esta relaci√≥n entre ambas notas puede verse una discontinuidad en el umbral de \\(70\\) puntos. Es decir, parece que los estudiantes que participaron del programa de tutor√≠as tienen un puntaje m√°s alto en el examen de salida, para mismo puntaje en el examen de entrada, que los que no participaron. Tracemos unas l√≠neas y veamos si esto es as√≠.\n\n\nVer el c√≥digo\n# Ahora miremos como se comporta la variable outcomes en funci√≥n de la running variable ####\nggplot(tutoring, aes(x = entrance_exam, \n                     y = exit_exam, \n                     color = tutoring,\n                     fill = tutoring)) +\n  geom_point(size = 1.5, alpha = .3) + \n  # Agregamos una linea basada en un modelo lineal para la running variable menor a 70\n  geom_smooth(data = filter(tutoring, entrance_exam <= 70), method = \"lm\") +\n  # Agregamos una linea basada en un modelo lineal para la running variable mayor a 70\n  geom_smooth(data = filter(tutoring, entrance_exam > 70), method = \"lm\") +\n  # Ponemos una l√≠nea vertical en el umbral\n  geom_vline(xintercept = 70, color = \"steelblue\", linetype = \"dashed\") + \n  # Las lables\n  labs(x = \"Puntaje en el examen de entrada\", \n       y = \"Puntaje en el examen de salida\",\n       color = \"Particip√≥ en la tutor√≠a\",\n       fill = \"Particip√≥ en la tutor√≠a\") + \n  # Colores m√°s chetos\n  scale_color_brewer(palette = \"Dark2\") +\n  scale_fill_brewer(palette = \"Dark2\") +\n  # Theme sin fondo gris\n  theme_minimal() +\n  theme(legend.position = \"top\")\n#> `geom_smooth()` using formula = 'y ~ x'\n#> `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nNotas de entrada vs.¬†notas de salida con l√≠neas de regresi√≥n ajustadas a cada grupo.\n\n\n\n\nVemos que efectivamente, la l√≠nea de regresi√≥n para los estudiantes que participaron del programa de tutor√≠as es m√°s alta que la de los que no participaron, mostrando que hubo un efecto del programa de tutor√≠as en la relaci√≥n entre la nota de entrada y de salida. Pero, ¬øc√≥mo podemos estimar este efecto? ¬øNo dijimos que los estudiantes que eran comparables eran los que estaban cerca del umbral? Dejemos esta √∫ltima pregunta para m√°s adelante y avancemos con la estimaci√≥n del efecto del programa de tutor√≠as.\nEn la siguiente figura vemos que la diferencia en el umbral, luego de ajustar una recta a cada grupo de estudiantes, es la que nos da el efecto del programa de tutor√≠as. En este caso no deja de ser la diferencia de ordenadas al origen de las rectas ajustadas a cada grupo, pero ya vamos a ver que no siempre es as√≠.\n\n\nVer el c√≥digo\ntutoring_centered <- tutoring |> \n  mutate(entrance_centered = entrance_exam - 70)\n\nmodelo_lm <- lm(exit_exam ~ entrance_centered + tutoring, \n                data = tutoring_centered)\n\nggplot(tutoring, aes(x = entrance_exam, \n                     y = exit_exam, \n                     color = tutoring,\n                     fill = tutoring)) +\n  geom_point(size = 1.5, alpha = .3) + \n  # Agregamos una linea basada en un modelo lineal para la running variable menor a 70\n  geom_smooth(data = filter(tutoring, entrance_exam <= 70), method = \"lm\") +\n  # Agregamos una linea basada en un modelo lineal para la running variable mayor a 70\n  geom_smooth(data = filter(tutoring, entrance_exam > 70), method = \"lm\") +\n  # Ponemos una l√≠nea vertical en el umbral\n  geom_vline(xintercept = 70, color = \"steelblue\", linetype = \"dashed\") + \n  # Un segmento con el efecto del modelo\n  geom_segment(aes(x = 70, y = modelo_lm$coefficients[1], \n                   xend = 70, yend = modelo_lm$coefficients[1] + modelo_lm$coefficients[3]), \n               color = \"darkblue\", linewidth = 2) +\n  annotate(\"label\", \n           x = 75, y = modelo_lm$coefficients[1] + modelo_lm$coefficients[3]/2,\n           label = \"LATE\", \n           color = \"darkblue\", size = 4, hjust = 0.5) +\n  # Las lables\n  labs(x = \"Puntaje en el examen de entrada\", \n       y = \"Puntaje en el examen de salida\",\n       color = \"Particip√≥ en la tutor√≠a\",\n       fill = \"Particip√≥ en la tutor√≠a\") + \n  # Colores m√°s chetos\n  scale_color_brewer(palette = \"Dark2\") +\n  scale_fill_brewer(palette = \"Dark2\") +\n  # Theme sin fondo gris\n  theme_minimal() +\n  theme(legend.position = \"top\")\n#> `geom_smooth()` using formula = 'y ~ x'\n#> `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nFigura¬†8.1: Notas de entrada vs.¬†notas de salida con l√≠neas de regresi√≥n ajustadas a cada grupo. La l√≠nea azul representa el LATE.\n\n\n\n\nEn la figura llamamos al efecto LATE3, pero, ¬øqu√© tiene de local el efecto? Bueno, como vamos a desarrollar un poco m√°s adelante, ese efecto es local porque, en teor√≠a, s√≥lo tiene validez para los individuos que est√°n a un lado u otro del umbral. Es decir, no representa el efecto a individuos que est√°n lejos del umbral. Sin embargo, y como en todas estas cosas, podemos justificar que ese efecto s√≠ es v√°lido para individuos que est√°n un poco m√°s lejos del umbral, pero eso requiere que conozcamos el problema.3¬†Del ingl√©s Local Average Treatment Effect.\nCreo que, si bien se deben estar creyendo lo que les cuento, tambi√©n deben tener un mill√≥n y medio de preguntas sobre c√≥mo se calcula este hermoso LATE y qu√© condiciones debe cumplir la running variable y el sesgo. Para eso nos queda una buena parte del cap√≠tulo, pero por ahora me quedo contento con que la idea detr√°s del m√©todo es: Las unidades experimentales a uno y otro lado del umbral son, en promedio, comparables en todas las caracter√≠sticas observadas y no observadas salvo en la asignaci√≥n o no al tratamiento."
  },
  {
    "objectID": "reg_discontinua.html#un-ejemplo-to-rule-them-all",
    "href": "reg_discontinua.html#un-ejemplo-to-rule-them-all",
    "title": "8¬† Regresi√≥n discontinua",
    "section": "8.5 Un ejemplo to rule them all",
    "text": "8.5 Un ejemplo to rule them all",
    "crumbs": [
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Regresi√≥n discontinua</span>"
    ]
  },
  {
    "objectID": "reg_discontinua.html#section",
    "href": "reg_discontinua.html#section",
    "title": "8¬† Regresi√≥n discontinua",
    "section": "8.3 ",
    "text": "8.3",
    "crumbs": [
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Regresi√≥n discontinua</span>"
    ]
  },
  {
    "objectID": "reg_discontinua.html#un-ejemplo-con-los-husoshusos-horarios",
    "href": "reg_discontinua.html#un-ejemplo-con-los-husoshusos-horarios",
    "title": "8¬† Regresi√≥n discontinua",
    "section": "8.3 Un ejemplo con los husos4 horarios4¬†S√≠, es husos y no usos, no es un typo.",
    "text": "8.3 Un ejemplo con los husos4 horarios4¬†S√≠, es husos y no usos, no es un typo.\nExiten m√∫ltiples ejemplos en la literatura cient√≠fica del uso de regresi√≥n discontinua para estimar el efecto causal de un tratamiento en datos observacionales. Pol√≠ticas p√∫blicas, programas sociales, programas educativos, etc. Pero en esta secci√≥n les voy a contar un ejemplo que utiliza una running variable un tanto particular: los husos horarios.\nEste trabajo (Schafer y Holbein (2020)) analiza c√≥mo las restricciones de tiempo (horarios escolares, laborales, etc.) afectan la participaci√≥n electoral en los Estados Unidos (un tema muy relevante ya que el voto no es obligatorio), utilizando un dise√±o de regresi√≥n discontinua geogr√°fica que aprovecha las fronteras de las zonas horarias de EE. UU. como discontinuidades. En este dise√±o, el umbral es la l√≠nea divisoria de la zona horaria. La running variable es la distancia geogr√°fica bidimensional, espec√≠ficamente la distancia latitudinal y longitudinal (medida en grados) desde el centro de un condado hasta la frontera de la zona horaria m√°s cercana.\nVeamos como muestran esto gr√°ficamente en el art√≠culo:\n\n\n\nCondados utilizados en la comparaci√≥n en Schafer y Holbein (2020) a uno y otro lado del cambio de huso horario.\n\n\nEsto significa que a un lado y al otro de la zona horaria los condados son comparables en todas las caracter√≠sticas observadas y no observadas, salvo en la zona horaria y el efecto de ella en las restricciones de tiempo. Es decir, que los condados a un lado y al otro de la frontera horaria son comparables en todas las caracter√≠sticas excepto en la hora local.\nAprovechando esto, los autores estiman el efecto con un modelo de regresi√≥n discontinua5. En la figura siguiente se puede ver c√≥mo se comporta la participaci√≥n electoral en funci√≥n de la distancia a la frontera horaria:5¬†Para detalles del ajuste pueden ver el c√≥digo que acompa√±a a la Figura¬†8.2.\n\n\n\nParticipaci√≥n electoral en funci√≥n de la running variable. El 0 es el cambio de huso horario. La discontinuidad en la distancia cero es la estimaci√≥n del efecto causal. Schafer y Holbein (2020).\n\n\nEs con estas herramientas que el estudio concluye que los ciudadanos que viven en el lado inmediatamente oriental de una frontera horaria votan significativamente menos (entre \\(1.5\\) y \\(3\\) puntos porcentuales) que aquellos en el lado occidental."
  },
  {
    "objectID": "var_instrumentales.html#intuici√≥n-de-las-variables-instrumentales",
    "href": "var_instrumentales.html#intuici√≥n-de-las-variables-instrumentales",
    "title": "9¬† Variables instrumentales",
    "section": "9.2 Intuici√≥n de las Variables Instrumentales",
    "text": "9.2 Intuici√≥n de las Variables Instrumentales\n\n9.2.1 El DAG Can√≥nico de VI\nPara entender el estimador de variables instrumentales, es √∫til comenzar con un Diagrama Ac√≠clico Dirigido (DAG) que ilustra una cadena de efectos causales. Considere un camino de puerta trasera entre una variable de tratamiento (D) y una variable de resultado (Y): (D U Y), donde (U) es una variable no observada por el econometrista. Si existe este tipo de selecci√≥n en variables no observables, ninguna estrategia de condicionamiento (control) satisfar√° el criterio de puerta trasera con los datos disponibles.\nAqu√≠ es donde entra la variable instrumental (Z). El dise√±o de VI busca aislar la variaci√≥n en el tratamiento que es puramente ex√≥gena, es decir, que no est√° influenciada por factores de confusi√≥n no observados. Piense en ello como un molde que permite que solo la forma deseada (el efecto causal) se manifieste, en lugar de esculpir el m√°rmol quitando la variaci√≥n indeseable. Un buen instrumento imita un experimento aleatorizado.\nLa intuici√≥n clave es que (Z) afecta a (Y) ‚Äúsolo a trav√©s de‚Äù (D). Esto significa que si (Z) var√≠a, causa que (D) var√≠e, lo que a su vez causa que (Y) cambie, pero solo debido a la variaci√≥n en (D). En otras palabras, (Z) debe ser independiente de las variables que determinan (Y) excepto por (D). Esta es la restricci√≥n de exclusi√≥n. Adem√°s, (Z) debe estar correlacionada con (D); esta relaci√≥n se conoce como la primera etapa.\n\n\n9.2.2 Los Buenos Instrumentos Deben Parecer Extra√±os\n¬øC√≥mo saber si tiene un buen instrumento? Primero, requiere conocimiento previo. Debe poder defender te√≥rica y l√≥gicamente la restricci√≥n de exclusi√≥n, ya que es un supuesto no testeable. Los microeconomistas aplicados son cada vez m√°s esc√©pticos con las VI porque pueden contar historias ilimitadas en las que las restricciones de exclusi√≥n no se cumplen.\nUna condici√≥n necesaria (aunque no suficiente) para un instrumento v√°lido es que la gente se confunda cuando usted les explique su relaci√≥n con el resultado. Por ejemplo, a nadie le sorprender√≠a que el tama√±o de la familia reduzca la oferta laboral de las mujeres. Pero, ¬øqu√© pensar√≠an si les dijera que las madres cuyos dos primeros hijos eran del mismo sexo trabajaban menos fuera del hogar que aquellas con un ratio de sexos equilibrado?. Esto es ‚Äúextra√±o‚Äù, ya que la composici√≥n de g√©nero no parece l√≥gicamente cambiar los incentivos laborales. Sin embargo, emp√≠ricamente, las familias con dos hijos del mismo sexo son m√°s propensas a tener un tercero buscando diversidad de g√©nero, lo que afecta el tama√±o de la familia y, por ende, la oferta laboral.\nEl ‚Äúinstrumento extra√±o‚Äù (tener dos ni√±os o dos ni√±as) solo cambia el resultado (oferta laboral) al cambiar primero una variable de tratamiento end√≥gena (tama√±o de la familia). Sin conocimiento de la variable end√≥gena, la relaci√≥n entre el instrumento y el resultado no tiene sentido. Esto se debe a que el instrumento es irrelevante para los determinantes del resultado excepto por su efecto en la variable de tratamiento end√≥gena. Los buenos instrumentos suelen ser cuasi-aleatorios.\nCompare esto con un mal instrumento: si conocer a Kanye West te llevara a la fama. Esto ser√≠a un mal instrumento para el √©xito musical, ya que hay muchas formas directas en que Kanye West puede afectar el √©xito de un m√∫sico, sin pasar por una √∫nica variable de tratamiento, violando la restricci√≥n de exclusi√≥n. En resumen, los buenos instrumentos son chocantes precisamente por la restricci√≥n de exclusi√≥n; si la relaci√≥n fuera obvia, la restricci√≥n de exclusi√≥n probablemente estar√≠a violada.",
    "crumbs": [
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Variables instrumentales</span>"
    ]
  },
  {
    "objectID": "var_instrumentales.html#efectos-de-tratamiento-homog√©neos-y-los-estimadores-de-dos-etapas-de-m√≠nimos-cuadrados-2sls",
    "href": "var_instrumentales.html#efectos-de-tratamiento-homog√©neos-y-los-estimadores-de-dos-etapas-de-m√≠nimos-cuadrados-2sls",
    "title": "9¬† Variables instrumentales",
    "section": "9.3 Efectos de Tratamiento Homog√©neos y los Estimadores de Dos Etapas de M√≠nimos Cuadrados (2SLS)",
    "text": "9.3 Efectos de Tratamiento Homog√©neos y los Estimadores de Dos Etapas de M√≠nimos Cuadrados (2SLS)\nLas VI se utilizan t√≠picamente para abordar el sesgo por variables omitidas, el error de medici√≥n y la simultaneidad. Por ejemplo, en el caso de la cantidad y el precio, que se determinan por la intersecci√≥n de la oferta y la demanda, cualquier correlaci√≥n observacional entre ellos no es informativa sobre las elasticidades de la oferta o la demanda. Philip Wright entendi√≥ este problema profundamente.\nAsumiremos un efecto de tratamiento homog√©neo (), que es el mismo para cada persona. Consideremos el problema cl√°sico laboral de estimar el efecto causal de la escolaridad ((S)) en los ingresos ((Y)). La escolaridad es end√≥gena debido a la habilidad no observada ((A)). El modelo verdadero ser√≠a: [ Y_i = + S_i + A_i + _i ] Donde () es un t√©rmino de error no correlacionado con (S) o (A). Si (A) no se observa, estimamos: [ Y_i = + S_i + _i ] Donde (_i = A_i + _i). Si (S) est√° correlacionada con (A), entonces (S) est√° correlacionada con (_i), haci√©ndola end√≥gena y sesgando la estimaci√≥n de OLS.\nSi encontramos un instrumento (Z_i) que causa m√°s escolaridad pero es independiente de la habilidad ((A)) y del t√©rmino de error estructural (()), podemos estimar (). El estimador de VI se puede expresar como el cociente de la covarianza de (Y) y (Z), y la covarianza de (S) y (Z): [ = ] Esto es v√°lido siempre que (C(A,Z)=0) y (C(,Z)=0), lo cual es el contenido estad√≠stico de la restricci√≥n de exclusi√≥n: el instrumento debe ser independiente de ambas partes del t√©rmino de error compuesto.\nPero la restricci√≥n de exclusi√≥n es solo una condici√≥n necesaria, no suficiente. El instrumento debe estar altamente correlacionado con la variable end√≥gena (S) (la primera etapa debe ser fuerte). El numerador se llama a veces forma reducida (la relaci√≥n entre el instrumento y el resultado), y el denominador es la primera etapa. Si (Z) no es independiente de (), o si la correlaci√≥n entre (S) y (Z) es d√©bil, el estimador () estar√° severamente sesgado en muestras finitas.\n\n9.3.0.0.1 7.3.1 Dos Etapas de M√≠nimos Cuadrados (2SLS)\nEl estimador de Dos Etapas de M√≠nimos Cuadrados (2SLS) es uno de los estimadores de VI m√°s intuitivos. Dada la instrumentaci√≥n de (S) con (Z), se descompone en dos pasos: 1. Primera etapa: Se predice la variable de tratamiento ((S)) usando el instrumento ((Z)) y otros controles. [ S_i = + Z_i + _i ] 2. Segunda etapa: Se usan los valores predichos de (S) (denotados ()) para estimar el efecto sobre el resultado ((Y)). [ Y_i = + _i + _i ] La intuici√≥n de 2SLS es que utiliza solo la variaci√≥n en la escolaridad que es ex√≥gena, impulsada por el instrumento. Es como un experimento: al aislar la variaci√≥n de (S) impulsada por (Z), estamos identificando efectos causales de cambios ex√≥genos en (S). Sin embargo, esta variaci√≥n ex√≥gena es solo un subconjunto de la variaci√≥n total en la escolaridad, lo que reduce la informaci√≥n disponible para la identificaci√≥n y puede generar errores est√°ndar m√°s grandes.",
    "crumbs": [
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Variables instrumentales</span>"
    ]
  },
  {
    "objectID": "var_instrumentales.html#el-problema-de-los-instrumentos-d√©biles",
    "href": "var_instrumentales.html#el-problema-de-los-instrumentos-d√©biles",
    "title": "9¬† Variables instrumentales",
    "section": "9.4 El Problema de los Instrumentos D√©biles",
    "text": "9.4 El Problema de los Instrumentos D√©biles\nUn instrumento d√©bil es aquel que, aunque v√°lido, predice la variable de tratamiento de manera insuficiente. Cuando la covarianza entre (Z) y (X) ((Cov(Z,X))) es peque√±a, el estimador de IV ((Cov(Z,Y)/Cov(Z,X))) tiende a ser inestable y tener una alta variabilidad de muestreo. Adem√°s, el sesgo de 2SLS se acerca al sesgo de OLS si el instrumento es d√©bil.\nLa forma m√°s com√∫n de verificar la relevancia del instrumento es la estad√≠stica F de la primera etapa. Si esta estad√≠stica es baja, sugiere que el instrumento es d√©bil. Bound, Jaeger, y Baker (1995) demostraron que a√±adir m√°s instrumentos con poco poder predictivo puede hacer que la estad√≠stica F de la primera etapa se acerque a cero, aumentando el sesgo de 2SLS. Por ejemplo, en su replicaci√≥n del estudio de Angrist y Krueger (1991) sobre la escolaridad, mostraron que al agregar instrumentos (como las interacciones de trimestre de nacimiento con el a√±o), la estad√≠stica F de la primera etapa ca√≠a significativamente, se√±alando un problema de instrumentos d√©biles.\nNo existe un corte √∫nico para la estad√≠stica F, ya que el valor deseado depende de la cantidad de sesgo que uno est√© dispuesto a aceptar. Stock y Yogo (2005) proporcionan tablas que relacionan la estad√≠stica F con el sesgo relativo de IV respecto al sesgo de OLS. Una regla general com√∫n, aunque muy aproximada, es que la estad√≠stica F debe ser 10 o superior.\nSi se enfrenta a un problema de instrumentos d√©biles, las opciones son limitadas. Se podr√≠a usar un modelo justo identificado con el IV m√°s fuerte, o un estimador de m√°xima verosimilitud de informaci√≥n limitada (LIML), que es aproximadamente insesgado para modelos de efectos constantes sobreidentificados. Sin embargo, la verdadera soluci√≥n para un problema de instrumentos d√©biles es conseguir mejores instrumentos.",
    "crumbs": [
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Variables instrumentales</span>"
    ]
  },
  {
    "objectID": "var_instrumentales.html#efectos-de-tratamiento-heterog√©neos",
    "href": "var_instrumentales.html#efectos-de-tratamiento-heterog√©neos",
    "title": "9¬† Variables instrumentales",
    "section": "9.5 Efectos de Tratamiento Heterog√©neos",
    "text": "9.5 Efectos de Tratamiento Heterog√©neos\nRelajando el supuesto de que los efectos de tratamiento son los mismos para todos, introducimos los efectos de tratamiento heterog√©neos, donde ((Y_i^1 - Y_i^0 = _i)) var√≠a para cada individuo (i). Esto es crucial porque introduce una tensi√≥n entre la validez interna (el efecto causal se identifica para la poblaci√≥n estudiada) y la validez externa (el hallazgo se aplica a poblaciones diferentes). Bajo efectos homog√©neos no hay tensi√≥n, pero bajo heterogeneidad la tensi√≥n es enorme y puede minar la relevancia del efecto estimado.\nPara la identificaci√≥n bajo efectos heterog√©neos, se requieren cinco supuestos: 1. Supuesto de Valor de Tratamiento Unitario Estable (SUTVA): Establece que los resultados potenciales para cada persona (i) no est√°n relacionados con el estado de tratamiento de otros individuos. Rara vez se menciona o se toma en serio en estudios aplicados. 2. Supuesto de Independencia: El instrumento es independiente de los resultados potenciales y de las asignaciones de tratamiento potenciales. A menudo se describe como una asignaci√≥n ‚Äútan buena como aleatoria‚Äù. Este supuesto es suficiente para una interpretaci√≥n causal de la forma reducida. 3. Restricci√≥n de Exclusi√≥n: Cualquier efecto de (Z) sobre (Y) debe ser a trav√©s del efecto de (Z) sobre (D). Formalmente: (Y_i(D_i,0) = Y_i(D_i,1)). La aleatoriedad del instrumento (independencia) no implica autom√°ticamente la restricci√≥n de exclusi√≥n. 4. Primera Etapa: (Z) debe estar correlacionada con la variable end√≥gena (D), de modo que (E[D_i^1 - D_i^0] ). Este es el √∫nico supuesto testeable directamente a partir de los datos. 5. Monotonicidad: Requiere que la variable instrumental opere (d√©bilmente) en la misma direcci√≥n para todas las unidades individuales. Es decir, si afecta a alguien, siempre lo hace en la misma direcci√≥n (positiva o negativa, pero no ambas). Sin este supuesto, los estimadores de IV no garantizan estimar un promedio ponderado de los efectos causales subyacentes del grupo afectado. Esto es importante porque si existen ‚ÄúDefiers‚Äù (personas que se ven afectadas en la direcci√≥n opuesta a lo esperado por el instrumento), el estimador de IV pierde su interpretaci√≥n como un promedio.\nSi se satisfacen los cinco supuestos, se tiene una estrategia de VI v√°lida. Sin embargo, bajo efectos de tratamiento heterog√©neos, el estimador de VI ya no recupera el efecto de tratamiento promedio (ATE) para toda la poblaci√≥n, sino un efecto de tratamiento promedio local (LATE - Local Average Treatment Effect). [ _{IV,LATE} = E] El LATE es el efecto causal promedio de (D) sobre (Y) para aquellos cuya situaci√≥n de tratamiento fue cambiada por el instrumento (Z). Estas personas se conocen como ‚ÄúCompliers‚Äù (cumplidores). No identifica el efecto causal en los ‚ÄúAlways-takers‚Äù (siempre-tomadores, quienes siempre reciben el tratamiento independientemente del instrumento) ni en los ‚ÄúNever-takers‚Äù (nunca-tomadores, quienes nunca reciben el tratamiento). Esto es importante porque el ATE poblacional es a menudo el de mayor inter√©s, pero no siempre es posible con IV.\nEl LATE es ‚Äúlocal‚Äù en el sentido de que es el efecto de tratamiento promedio solo para los compliers. En contraste, en el dise√±o tradicional de IV con efectos homog√©neos, los compliers tienen los mismos efectos de tratamiento que los no-compliers, por lo que la distinci√≥n es irrelevante.\nAhora, exploremos algunas aplicaciones reales de las variables instrumentales.",
    "crumbs": [
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Variables instrumentales</span>"
    ]
  },
  {
    "objectID": "var_instrumentales.html#ejemplo-conscripci√≥n-y-crimen-evidencia-de-la-loter√≠a-del-servicio-militar-obligatorio-en-argentina",
    "href": "var_instrumentales.html#ejemplo-conscripci√≥n-y-crimen-evidencia-de-la-loter√≠a-del-servicio-militar-obligatorio-en-argentina",
    "title": "9¬† Variables instrumentales",
    "section": "9.6 Ejemplo: Conscripci√≥n y Crimen: Evidencia de la Loter√≠a del Servicio Militar Obligatorio en Argentina",
    "text": "9.6 Ejemplo: Conscripci√≥n y Crimen: Evidencia de la Loter√≠a del Servicio Militar Obligatorio en Argentina\nEste ejemplo se basa en el estudio de Galiani, Rossi, y Schargrodsky (2010), que busca estimar el efecto causal de la participaci√≥n obligatoria en el servicio militar en las actividades delictivas.\nContexto del Problema: Se ha afirmado que el servicio militar obligatorio (conscripci√≥n) podr√≠a tener un impacto en el comportamiento criminal de los j√≥venes. Existen hip√≥tesis contradictorias: podr√≠a tener una influencia positiva al ense√±ar disciplina, mejorar la salud y las perspectivas laborales, o incapacitar la comisi√≥n de delitos al mantener a los j√≥venes en instalaciones militares. Alternativamente, podr√≠a tener una influencia negativa al retrasar la inserci√≥n laboral, proporcionar entrenamiento con armas o crear un ambiente social propenso a respuestas violentas y efectos negativos de pares. La literatura previa se centr√≥ principalmente en veteranos de guerra (como el draft de Vietnam), lo que podr√≠a introducir sesgos por el trauma de combate. El objetivo de este estudio es estimar el efecto causal del servicio militar en tiempos de paz.\nEl Experimento Natural y el Instrumento: Para identificar el efecto causal, los autores explotan la asignaci√≥n aleatoria de j√≥venes al servicio militar en Argentina a trav√©s de una loter√≠a de conscripci√≥n. El servicio militar fue obligatorio en Argentina de 1901 a 1995. La elegibilidad se asignaba anualmente mediante una loter√≠a que emparejaba un n√∫mero (del 1 al 1,000) con los √∫ltimos tres d√≠gitos del documento de identidad nacional de los individuos. Despu√©s, se anunciaba un n√∫mero de corte: aquellos con n√∫meros de loter√≠a por encima del corte y que pasaban un examen m√©dico eran llamados a servir. El instrumento en este estudio es la variable dummy ‚ÄúDraft Eligible‚Äù (Elegible para el Servicio Militar), que toma el valor de uno si el n√∫mero de loter√≠a asignado a un individuo lo hac√≠a elegible, y cero en caso contrario. Por dise√±o, esta variable se asigna aleatoriamente.\nDatos Utilizados: Los autores utilizaron un conjunto √∫nico de datos administrativos. * Registros criminales: Informaci√≥n sobre todos los hombres con antecedentes penales en el sistema de justicia para adultos desde 1934 hasta 2005 (aproximadamente un mill√≥n de observaciones), incluyendo los √∫ltimos tres d√≠gitos del DNI y el a√±o de nacimiento. Un antecedente penal significa que el individuo fue procesado o condenado por un delito. Otro conjunto de datos, m√°s corto (2000-2005), incluye el tipo de delito (armas, propiedad, ataque sexual, etc.). * Datos de servicio militar: Resultados de la loter√≠a del servicio militar, estado del servicio militar y n√∫meros de corte del Ej√©rcito Argentino. * Datos del mercado laboral: Participaci√≥n en el mercado laboral formal (contribuciones a la seguridad social), tasas de desempleo e ingresos (derivados de la ocupaci√≥n declarada en el registro nacional de votantes de 2003).\nLa unidad de observaci√≥n principal es la combinaci√≥n de cohorte de nacimiento y los √∫ltimos tres n√∫meros de identificaci√≥n. Los autores se enfocan en las cohortes de 1958 a 1962, para las cuales tienen informaci√≥n tanto sobre la intenci√≥n de tratar como sobre el estado de tratamiento real. Tambi√©n se dispone de datos sobre caracter√≠sticas previas al tratamiento para estas cohortes, como origen y distrito de residencia.\nValidaci√≥n de la Aleatoriedad: Aunque la elegibilidad se asign√≥ aleatoriamente, los autores examinaron si las caracter√≠sticas previas al tratamiento estaban equilibradas entre los grupos elegibles y exentos. La Tabla 2 (fuente: NDL2010-055.pdf) muestra que, para la mayor√≠a de las variables, no hay diferencias estad√≠sticamente significativas, lo que sugiere que la aleatorizaci√≥n de la elegibilidad tuvo √©xito. En los pocos casos de diferencias significativas, estas eran peque√±as y no alteraban los resultados principales al incluirse como controles.\nLos autores tambi√©n analizaron los resultados de los ex√°menes m√©dicos previos a la inducci√≥n. Aunque las tasas de fracaso eran m√°s altas para el grupo elegible (Tabla 3), esto se deb√≠a a que los individuos con n√∫meros bajos (no elegibles) ten√≠an menos incentivos para falsear sus condiciones m√©dicas. Cuando se control√≥ por estas diferencias de incentivos (examinando solo a los individuos con n√∫meros de loter√≠a cercanos al corte), las tasas de fracaso se equilibraron, lo que proporciona m√°s evidencia de la exogeneidad de la elegibilidad y sugiere que los ex√°menes m√©dicos fueron manipulados. Esta manipulaci√≥n hace que el estado de servicio militar sea end√≥geno, pero no afecta la consistencia del estimador de IV.\nResultados Principales - Primera Etapa: Los resultados de la primera etapa (Tabla 4 en la fuente) muestran una fuerte relaci√≥n entre la elegibilidad para el servicio militar y la probabilidad de servir. Para los hombres de las cohortes de 1958 a 1962, la probabilidad de servir en el ej√©rcito fue 66 puntos porcentuales m√°s alta para los del grupo elegible en comparaci√≥n con los exentos. Todos los efectos de la primera etapa est√°n estimados con gran precisi√≥n y son significativamente diferentes de cero.\nResultados Principales - Efecto en la Criminalidad (LATE): El estimador de VI, bajo supuestos razonables (incluida la monotonicidad), recupera el Efecto de Tratamiento Promedio Local (LATE). En este contexto, el LATE es el efecto promedio de la participaci√≥n en el servicio militar en aquellos individuos cuyo estado de tratamiento fue inducido a cambiar por el instrumento: los ‚Äúcompliers‚Äù (cumplidores). Estos son hombres que sirvieron porque fueron asignados a un n√∫mero de loter√≠a alto, pero no habr√≠an servido de otra manera. Los resultados, por lo tanto, no necesariamente se generalizan a la poblaci√≥n de voluntarios o a aquellos que nunca habr√≠an servido.\nLos resultados de 2SLS (Tabla 5 en la fuente) indican que el servicio militar obligatorio aumenta significativamente las tasas de criminalidad. Los estimadores 2SLS preferidos en la columna (4) muestran que el servicio militar aumenta las tasas de criminalidad en un 3.96%. Esto implica que la conscripci√≥n elevar√≠a la probabilidad de ser procesado o condenado en la vida adulta en 0.27 puntos porcentuales, desde una tasa de referencia del 6.8% a un 7.07%. En t√©rminos porcentuales, esto es aproximadamente un tercio del efecto positivo de un a√±o adicional de escolaridad en la reducci√≥n de la encarcelaci√≥n.\nAn√°lisis de Heterogeneidad y Canales: * Servicio en tiempos de paz vs.¬†guerra: El efecto de la conscripci√≥n sobre el crimen es mayor para aquellos reclutas en las cohortes que participaron en la Guerra de Malvinas (1982), aunque el efecto sigue siendo significativo para las cohortes que sirvieron en tiempos de paz, que constituyen la mayor parte de la muestra (Tabla 6). Esto destaca la distinci√≥n entre el trauma de combate y los efectos generales de la conscripci√≥n. * Duraci√≥n del servicio: El efecto sobre el crimen fue mayor para quienes sirvieron en la Armada (dos a√±os) en comparaci√≥n con el Ej√©rcito o la Fuerza A√©rea (un a√±o) (Tabla 6). Este resultado es consistente con la hip√≥tesis de que las experiencias tempranas en el mercado laboral son un canal a trav√©s del cual el servicio militar afecta el comportamiento criminal. * Tipo de delito: El servicio militar aumenta la probabilidad de desarrollar un expediente criminal, especialmente para delitos pecuniarios (contra la propiedad y de cuello blanco) (Tabla 7). Esto apoya la idea de que la conscripci√≥n podr√≠a afectar negativamente las perspectivas laborales de los j√≥venes, llev√°ndolos a cometer este tipo de delitos. * Resultados en el mercado laboral: El estudio encuentra que los hombres que sirvieron en el ej√©rcito tienen una menor probabilidad de participar en el mercado laboral formal, una tasa de desempleo m√°s alta (aunque no significativa) y menores ingresos futuros (Tabla 8). Estos hallazgos de efectos perjudiciales a largo plazo en el mercado laboral respaldan la hip√≥tesis de que la conscripci√≥n aumenta la criminalidad a trav√©s de este canal.\nPruebas de Falsificaci√≥n (Experimentos Falsos): Para reforzar la exogeneidad del instrumento, los autores realizaron tres ‚Äúexperimentos falsos‚Äù: 1. Restricci√≥n a n√∫meros de loter√≠a bajos: Dividieron el grupo no elegible por la mediana y asignaron un ‚Äúfalso estatus de tratamiento‚Äù. No encontraron diferencias en las tasas de criminalidad entre estos grupos, lo que confirma la aleatoriedad de la loter√≠a. 2. Cohortes no reclutadas: Analizaron las cohortes de 1956 y 1957, que saltaron el servicio militar debido a un cambio de edad. Al imputarles resultados de loter√≠a de cohortes posteriores, no se observaron diferencias significativas en las tasas de criminalidad, como era de esperar. 3. Loter√≠a sin incorporaci√≥n: La cohorte de 1976 pas√≥ por la loter√≠a pero no fue incorporada al servicio militar. Al crear un ‚Äúfalso n√∫mero de corte‚Äù, no se encontraron diferencias en las tasas de criminalidad entre los grupos ‚Äúelegibles‚Äù y ‚Äúno elegibles‚Äù falsos. Esta prueba es importante porque aborda la preocupaci√≥n de que el resultado de la loter√≠a pudiera tener un efecto directo en la moral de los j√≥venes, independientemente de la participaci√≥n real en el servicio.\nEn conclusi√≥n, este estudio demuestra de manera convincente un efecto causal de la conscripci√≥n en tiempos de paz en el aumento de la probabilidad de desarrollar un expediente criminal. Los hallazgos sugieren que, a pesar de los posibles beneficios (disciplina, incapacitaci√≥n), los mecanismos que operan en la direcci√≥n opuesta (retraso en la inserci√≥n laboral) dominan, llevando a mayores tasas de criminalidad, especialmente en delitos pecuniarios.",
    "crumbs": [
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Variables instrumentales</span>"
    ]
  },
  {
    "objectID": "matching.html#sec-matching_vs_reg",
    "href": "matching.html#sec-matching_vs_reg",
    "title": "6¬† Subclasificaci√≥n y matching",
    "section": "6.3 Matching vs.¬†regresi√≥n10",
    "text": "6.3 Matching vs.¬†regresi√≥n10\nEn el ejemplo anterior, vimos c√≥mo el matching busca emparejar unidades tratadas y no tratadas bas√°ndose en sus caracter√≠sticas observables. Pero, ¬øqu√© pasa si en lugar de emparejar, simplemente ajustamos un modelo de regresi√≥n que incluya esas mismas covariables? ¬øNo era la forma en la que control√°bamos por los confusores antes de este cap√≠tulo? Bueno, s√≠ y no. La regresi√≥n y el matching son dos enfoques diferentes para obtener la tan ansiada independencia condicional, pero cada uno tiene sus propias ventajas y desventajas. Vamos con un ejemplo paradigm√°tico para que podamos entender un poquito m√°s de que estamos hablando.\nVamos a generar un conjunto de datos donde \\(x\\) es un confusor, el tratamiento \\(d\\) se asigna de forma no lineal en funci√≥n de \\(x\\), y el outcome tambi√©n depende de \\(x\\) de forma no lineal, y el efecto del tratamiento es homog√©neo y vale \\(1\\).\n\n\nVer el c√≥digo\n# Genero la data ####\ndf &lt;- tibble(\n  # x es un confusor\n  x = runif(1000, -1, 4),\n  # Afecta la probabilidad de recibir el tratamiento de forma NO LINEAL (funci√≥n escal√≥n)\n  prob_d = ifelse(x &gt; 0.5 & x &lt; 2.5, 0.1, 0.9),\n  d = rbinom(1000, 1, prob_d),\n  noise = rnorm(1000, sd = 0.1),\n  # Pra simplificar, el ATE es homogeneo y vale 1\n  treat_effect = 1,\n  # x afecta al outcome de manera no lineal (una funci√≥n seno)\n  outcome = sin(x) + d*treat_effect + noise\n) %&gt;% \n  mutate(d_factor = factor(d,\n                           levels=c(0,1), labels=c(\"No tratado\",\n                                                   \"Tratado\")))\n\nggplot(df,\n       aes(x, outcome, color = d_factor)) +\n  geom_point(size = 1) + \n  scale_color_brewer(palette = \"Dark2\") +\n  labs(color = \"Estado del tratamiento\") +\n  theme_bw() +\n  theme(legend.position = \"top\")\n\n\n\n\n\nCada uno de los sujetos pertenecientes al grupo control y tratamiento con sus respectivos valores de outcome y covariable x.\n\n\n\n\nDe estos datos podemos ver dos cosas claras: 1) \\(x\\) es claramente un confusor, ya que el valor de \\(x\\) no solo afecta al outcome sino tambi√©n a la probabilidad de recibir el tratamiento (los sujetos del medio son m√°s ‚ÄúNo tratados‚Äù), y 2) la relaci√≥n entre \\(x\\) y el outcome es no lineal. El efecto del tratamiento es homog√©neo y vale \\(1\\), y esto lo sabemos porque generamos los datos nosotros mismos.\nAhora probemos dos cosas: Estimar el efecto del tratamiento usando una regresi√≥n lineal y luego usando matching aproximado con la librer√≠a MatchIt(para detalles pueden ver el c√≥digo). A continuaci√≥n tenemos los efectos estimados con los dos m√©todos:\n\n\nVer el c√≥digo\n# Ajustemos un modelo lineal ####\nlinear_model1 &lt;- lm(outcome ~ d + x, data = df)\n\n# Con matching ####\nlibrary(MatchIt)\nnearest_control &lt;- matchit(d ~ x, \n                           data = df,\n                           method = \"nearest\", \n                           distance = \"mahalanobis\",\n                           replace = T,\n                           ratio = 1)\n\nmatch_df &lt;- match.data(nearest_control)\n\nmatching_model1 &lt;- lm(outcome ~ d + x, \n                      data = match_df, \n                      weights = weights)\n\n# Comparamos los modelos\nmodelsummary(list(\"Regresi√≥n\"= linear_model1,\n                  \"Matching\" = matching_model1),\n             coef_rename = c(\"d\" = \"Tratamiento\"),\n             statistic = NULL, \n               gof_omit = 'DF|Deviance|R2|AIC|BIC|Log.Lik|F|RMSE',\n             output = \"gt\") |&gt;\n  gt_highlight_rows(rows = 2, \n                    fill = \"lightyellow\",\n                    font_weight = \"bold\")\n\n\n\n\n\n\n\n\n\nRegresi√≥n\nMatching\n\n\n\n\n(Intercept)\n0.630\n-0.139\n\n\nTratamiento\n0.247\n1.004\n\n\nx\n0.036\n0.044\n\n\nNum.Obs.\n1000\n665\n\n\n\n\n\nEstimaciones del efecto del tratamiento utilizando regresi√≥n y matching.\n\n\nComo era de esperarse, la regresi√≥n lineal nos da un estimador del efecto del tratamiento de \\(0.220\\), mientras que el matching nos da un estimador de \\(0.992\\). Pero ¬øPor qu√© era esperable? La regresi√≥n lineal asume una relaci√≥n lineal entre \\(x\\) y el outcome, lo que no es cierto en nuestros datos. Por lo tanto, el modelo no captura correctamente la relaci√≥n entre \\(x\\) y el outcome, lo que sesga el estimador del efecto del tratamiento11.\n11¬†Otra cosa interesante que podemos observar, es que al estimar el efecto con matching, el tama√±o de la muestra efectivo es menor que al estimar con regresi√≥n lineal. Esto se debe a que el matching elimina las unidades que no tienen un par cercano en el grupo de control, lo que reduce el tama√±o de la muestra efectiva.Veamos qu√© forma tiene el modelo lineal ajustado con estos datos:\n\n\nVer el c√≥digo\n# Regression\ndf_linear &lt;- df %&gt;%\n  modelr::add_predictions(linear_model1, var = \"pred_linear\")\n\nplot_linear &lt;-\n  ggplot(df_linear) +\n  aes(x = x, color = d_factor) +\n  geom_point(aes(y = outcome), alpha = 0.3, size = 1) +\n  geom_line(aes(y = pred_linear), size = 1) +\n  labs(color = \"Treatment status\") +\n  scale_color_brewer(palette = \"Dark2\") +\n  labs(color = \"Estado del tratamiento\") +\n  theme_bw() +\n  theme(legend.position = \"top\")\n#&gt; Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n#&gt; ‚Ñπ Please use `linewidth` instead.\nplot_linear\n\n\n\n\n\nLa regresi√≥n lineal ajustada.\n\n\n\n\nEntonces esto es esperable porque los datos son claramente no lineales. Ahora, usemos un suavizado de los datos para reflejar, m√°s o menos, qu√© es lo que est√° haciendo el algoritmo de matching para estimar el efecto.\n\n\nVer el c√≥digo\n# Matching\nknn1 &lt;- knn.reg(\n  train = dplyr::select(df, x, d),\n  y = df$outcome,\n  test = dplyr::select(df, x, d),\n  k = 10,\n  algorithm = \"brute\"\n)\n\ndf_knn &lt;- df %&gt;% \n  mutate(pred_knn = knn1$pred)\n\nplot_matching &lt;- \n  ggplot(df_knn) +\n  aes(x = x, color = d_factor) +\n  geom_point(aes(y = outcome), alpha = 0.3, size = 1) +\n  geom_line(aes(y = pred_knn), linewidth = 1) +\n  labs(color = \"Treatment status\") +  \n  scale_color_brewer(palette = \"Dark2\") +\n  labs(color = \"Estado del tratamiento\") +\n  theme_bw() +\n  theme(legend.position = \"top\")\nplot_matching\n\n\n\n\n\nAlgo parecido a lo que usa el matching para estimar el efecto.\n\n\n\n\nPodemos ver a todas luces que esto tiene mucho sentido. Ahora, ¬øUsamos siempre matching o alguna vez puede no convenirnos?\nUno de los supuestos de los modelos lineales es la linealidad de la relaci√≥n entre, en este caso, x y el outcome. Si esto no se cumple, el modelo lineal no va a capturar bien la relaci√≥n y, por lo tanto, el estimador del efecto del tratamiento va a estar sesgado. En cambio, el matching no asume una relaci√≥n lineal entre las covariables y el outcome, por lo que puede ser m√°s robusto en estos casos. Sin embargo, recordemos que uno de los supuestos del matching es la necesidad de soporte com√∫n. En el ejemplo anterior hab√≠a soporte com√∫n, es decir, en el mismo rango de \\(x\\) hab√≠a tanto tratados como no tratados. Veamos un ejemplo donde esto no es as√≠.\n\n\nVer el c√≥digo\n# Datos sin soporte com√∫n ####\ndf_wo_common_support &lt;- tibble(\n  # x es un confusor\n  x = runif(1000, -1, 4),\n  # No hay m√°s prob_d, es determin√≠stico\n  d = ifelse(x &gt; 0.5 & x &lt; 2.5, 0, 1),\n  noise = rnorm(1000, sd = 0.1),\n  # Pra simplificar, el ATE es homogeneo y vale 1\n  treat_effect = 1,\n  # x afecta al outcome de manera no lineal (una funci√≥n seno)\n  outcome = sin(x) + d*treat_effect + noise\n) %&gt;% \n  mutate(d_factor = factor(d,\n                           levels=c(0,1), labels=c(\"No tratado\",\n                                                   \"Tratado\")))\n\nggplot(df_wo_common_support,\n       aes(x, outcome, color = d_factor)) +\n  geom_point(size = 1) + \n  scale_color_brewer(palette = \"Dark2\") +\n  labs(color = \"Estado del tratamiento\") +\n  theme_bw() +\n  theme(legend.position = \"top\")\n\n\n\n\n\nDatos pero ahora sin soporte com√∫n.\n\n\n\n\nEn este ejemplo podemos ver claramente que todos los sujetos del grupo control tienen valores de \\(x\\) mayores a \\(0.5\\) y menores a \\(2.5\\). Es decir, ya no hay m√°s soporte com√∫n.\nA estos datos le vamos a ajustar dos modelos, uno de matching usando MatchIt y otro de regresi√≥n lineal pero con un peque√±o truquito dado que sabemos la forma funcional. Lo que vamos a ajustar es el siguiente modelo:\n\\[\nY_i = \\beta_{0i} + \\beta_{di} D + \\beta_{xi} \\sin(X) + \\epsilon_i\n\\]\nEs decir, estamos asumiendo que la relaci√≥n entre \\(x\\) y el outcome es una funci√≥n seno, y no lineal12. Vamos a ver qu√© pasa.\n12¬†Recordemos que, a pesar de que aparece \\(\\sin(X)\\), la regresi√≥n lineal sigue siendo lineal en los par√°metros, por lo que no estamos violando ning√∫n supuesto de la regresi√≥n lineal.\n\nVer el c√≥digo\n# Modelo lineal sin soporte comun ####\nreg_wo_common_support &lt;- lm(outcome ~ d + sin(x), data = df_wo_common_support)\n\n# Matching sin soporte com√∫n ####\nnearest_control &lt;- matchit(d ~ x, \n                           data = df_wo_common_support,\n                           method = \"nearest\", \n                           distance = \"mahalanobis\",\n                           replace = T,\n                           ratio = 1)\n\nmatch_df_wo_common_support &lt;- match.data(nearest_control)\n\nmathing_wo_common_support &lt;- lm(outcome ~ d + x, \n                     data = match_df_wo_common_support, \n                     weights = weights)\n\n# Comparamos los modelos\nmodelsummary(list(\"Regresi√≥n\"= reg_wo_common_support,\n                  \"Matching\" = mathing_wo_common_support),\n             coef_rename = c(\"d\" = \"Tratamiento\"),\n             statistic = NULL, \n             gof_omit = 'DF|Deviance|R2|AIC|BIC|Log.Lik|F|RMSE',\n             output = \"gt\") |&gt;\n  gt_highlight_rows(rows = 2, \n                    fill = \"lightyellow\",\n                    font_weight = \"bold\")\n\n\n\n\n\n\n\n\n\nRegresi√≥n\nMatching\n\n\n\n\n(Intercept)\n-0.018\n0.437\n\n\nTratamiento\n1.022\n0.367\n\n\nsin(x)\n1.015\n\n\n\nx\n\n0.020\n\n\nNum.Obs.\n1000\n590\n\n\n\n\n\nEstimaciones del efecto del tratamiento utilizando regresi√≥n y matching para los datos sin soporte com√∫n.\n\n\nLo que pasa ahora es que, gracias a la capacidad de extrapolar de la regresi√≥n lineal, la falta de soporte com√∫n no es un problema y el estimador del efecto del tratamiento es bastante bueno, \\(1.022\\). En cambio, el matching no puede extrapolar y, por lo tanto, el estimador del efecto del tratamiento es \\(0.02\\), es decir, un efecto casi nulo.\nVolvamos a ver las cosas gr√°ficamente a ver si esto nos echa un poco de luz sobre lo que est√° ocurriendo. Primero veamos la regresi√≥n lineal ajustada:\n\n\nVer el c√≥digo\n# Esto es s√≥lo una cosa para plotar los datos\ndf_wo_common_support &lt;- df_wo_common_support %&gt;%\n  mutate(group = case_when(\n    x &lt; 0.5 ~ \"segment1\",\n    x &gt; 2.5 ~ \"segment3\",\n    TRUE ~ \"segment2\"\n  ))\n\n# Los labels a una funci√≥n\ncreating_factor_d &lt;- function(x) factor(x,\n                                        levels = c(0, 1),\n                                        labels = c(\"No tratado\",\n                                                   \"Tratado\"))\n\ndf_wo_cs_treated &lt;- df_wo_common_support %&gt;% \n  mutate(extrapolation = ifelse(d == 1, \"No\", \"Yes\"),\n         d = 1,\n         d_factor = creating_factor_d(d)) %&gt;% \n  modelr::add_predictions(reg_wo_common_support, var = \"pred_treated\")\n\ndf_wo_cs_untreated &lt;- df_wo_common_support %&gt;% \n  mutate(extrapolation = ifelse(d == 0, \"No\", \"Yes\"),\n         d = 0,\n         d_factor = creating_factor_d(d)) %&gt;% \n  modelr::add_predictions(reg_wo_common_support, var = \"pred_untreated\")\n\nplot_wo_cs_reg &lt;- \n  ggplot() +\n  aes(x, outcome, color = d_factor) +\n  geom_point(data= df_wo_common_support, alpha = 0.3, size = 1) +\n  geom_line(data = df_wo_cs_untreated,\n            aes(y = pred_untreated,\n                alpha = extrapolation,\n                linetype = extrapolation,\n                group = group), size = 1) +\n  geom_line(data = df_wo_cs_treated,\n            aes(y = pred_treated,\n                alpha = extrapolation,\n                linetype = extrapolation,\n                group = group), size = 1) +\n  scale_alpha_manual(values = c(\"Yes\" = 0.5, \"No\" = 1)) +\n  scale_linetype_manual(values = c(\"Yes\" = \"dashed\", \"No\" = \"solid\")) +\n  scale_color_brewer(palette = \"Dark2\") +\n  labs(color = \"Estado del tratamiento\",\n       linetype = \"Extrapolaci√≥n\") +\n  guides(alpha = FALSE,\n         linetype = FALSE) +\n  theme_bw() +\n  theme(legend.position = \"top\")\n#&gt; Warning: The `&lt;scale&gt;` argument of `guides()` cannot be `FALSE`. Use \"none\" instead\n#&gt; as of ggplot2 3.3.4.\n\nplot_wo_cs_reg\n\n\n\n\n\nLa regresi√≥n lineal ajustada conociendo la forma de la relaci√≥n entre x y el outcome (seno). La l√≠nea punteada representa la fracci√≥n de x que es extrapolada por el modelo para estos datos sin soporte com√∫n.\n\n\n\n\nEn este caso podemos ver que al ajustar la regresi√≥n lineal, el modelo extrapola los valores de \\(x\\) y la distancia entre ambas curvas es, efectivamente cercana a \\(1\\) (que es el valor del par√°metro poblacional). ¬øY si vemos la estimaci√≥n de matching?\n\n\nVer el c√≥digo\nx_values &lt;- df_wo_common_support %&gt;% dplyr::select(x)\n\nknn_wo_cs_treated &lt;- knn.reg(\n  train = df_wo_common_support %&gt;% \n    filter(d == 1) %&gt;% \n    dplyr::select(x),\n  y = df_wo_common_support %&gt;% \n    filter(d == 1) %&gt;% \n    dplyr::pull(outcome),\n  test = x_values,\n  k = 15,\n  algorithm = \"brute\"\n)\n\nknn_wo_cs_untreated &lt;- knn.reg(\n  train = df_wo_common_support %&gt;% \n    filter(d == 0) %&gt;% \n    dplyr::select(x),\n  y = df_wo_common_support %&gt;% \n    filter(d == 0) %&gt;% \n    dplyr::pull(outcome),\n  test = x_values,\n  k = 15,\n  algorithm = \"brute\"\n)\n\ndf_untr_matching_wo_cs &lt;-\n  tibble(\n    y_pred = knn_wo_cs_untreated$pred,\n    x = df_wo_common_support$x,\n    d = 0\n  ) %&gt;%\n  mutate(d_factor = creating_factor_d(d))\n\ndf_tr_matching_wo_cs &lt;-\n  tibble(\n    y_pred = knn_wo_cs_treated$pred,\n    x = df_wo_common_support$x,\n    d = 1\n  ) %&gt;%\n  mutate(d_factor = creating_factor_d(d),\n         group = case_when(\n           x &lt; 0.5 ~ \"segment1\",\n           x &gt; 2.5 ~ \"segment3\",\n           TRUE ~ \"segment2\"\n         ))\n\nplot_matching_wo_cs &lt;- \n  ggplot() +\n  aes(x, outcome, color = d_factor) +\n  geom_point(data= df_wo_common_support, alpha = 0.3, size = 1) +\n  geom_line(data = df_untr_matching_wo_cs,\n            aes(y = y_pred), size = 1) +\n  geom_line(data = df_tr_matching_wo_cs,\n            aes(y = y_pred, group = group), size = 1) +\n  scale_color_brewer(palette = \"Dark2\") +\n  labs(color = \"Estado del tratamiento\") +\n  theme_bw() +\n  theme(legend.position = \"top\")\n\nplot_matching_wo_cs\n\n\n\n\n\nAlgo parecido a lo que usa el matching para estimar el efecto pero ahora sin soporte com√∫n.\n\n\n\n\nPodemos ver que para los valores de \\(x\\) donde no hay soporte com√∫n, el matching hace una estimaciones que est√°n muy lejos del valor real del par√°metro poblacional, \\(1\\). Esto se debe a que el matching no puede extrapolar y, por lo tanto, no puede estimar el efecto del tratamiento en esos valores de \\(x\\) donde no hay unidades tratadas.\nEn resumen, la regresi√≥n lineal puede ser una herramienta conveniente para obtener la independencia condicional, pero si la relaci√≥n entre las covariables y el outcome no es lineal (y no la conocemos) , el estimador del efecto del tratamiento puede estar sesgado. En cambio, el matching no asume una relaci√≥n lineal y puede ser m√°s robusto en estos casos, pero requiere soporte com√∫n para poder extrapolar. Si no hay soporte com√∫n, el matching no puede estimar el efecto del tratamiento en esos valores de las covariables donde no hay unidades tratadas.",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Subclasificaci√≥n y *matching*</span>"
    ]
  }
]