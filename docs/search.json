[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Diseños experimentales y cuasiexperimentales",
    "section": "",
    "text": "Prefacio\nEste libro surge con la intención de acompañar a los estudiantes de la materia Diseño experimentales y cuasiexperimentales correspondiente a la carrera de Licenciatura en Ciencias del Comportamiento de la Universidad de San Andrés (Victoria, Argentina). Sin embargo, este libro no contiene todo los materiales de la materia, sino más bien es una guía que nos permite comprender conceptos básicos e identificar lo importante en cada tema. De forma complementaria, en cada capítulo se brindará una lista de bibliografía recomendada.",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "intro_R.html",
    "href": "intro_R.html",
    "title": "1  R y el tidyverse",
    "section": "",
    "text": "1.1 Tidy data\nLo primero que tenemos que pensar cuando trabajamos con el tidyverse es que nuestros datos estén en formato tidy. ¿Qué significa esto? Cuando un dataset está en formato tidy, cada columna corresponde a una variable y cada fila a una única observación2. Veamos un ejemplo. Tenemos tres sujetos a los cuales les medimos el tiempo de respuesta en una tarea. Cada sujeto realiza dos repeticiones de esta medición, el trial 1 y el trial 2. En la tabla Tabla 1.1 podemos ver las dos formas de organizar esta información.\nA lo largo de este capítulo iremos viendo los beneficios de almacenar los datos en formato tidy. Por supuesto que estas ventajas tienen su precio, principalemente que las bases de datos crecen mucho en tamaño si tenemos muchas medidas repetidas con distintos valores de las variables.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>R y el tidyverse</span>"
    ]
  },
  {
    "objectID": "intro_R.html#el-tidyverse",
    "href": "intro_R.html#el-tidyverse",
    "title": "1  R y el tidyverse",
    "section": "1.1 El tidyverse",
    "text": "1.1 El tidyverse\n\n1.1.1 Tidy data\nLo primero que tenemos que pensar cuando trabajamos con el tidyverse es que nuestros datos estén en formato tidy. ¿Qué significa esto? Cuando un dataset está en formato tidy, cada columna corresponde a una variable y cada fila a una única observación2. Veamos un ejemplo. Tenemos tres sujetos a los cuales les medimos el tiempo de respuesta en una tarea. Cada sujeto realiza dos repeticiones de esta medición, el trial 1 y el trial 2. En la tabla Table 1.1 podemos ver las dos formas de organizar esta información.2 El caso contrario sería en el que una fila contiene varios mediciones para distintos niveles de una variable. Este formato se conoce como wide.\n\n\nTable 1.1: Ejemplo de tablas tidy y wide.\n\n\n\n\n(a) Tidy \n \n  \n    sujeto \n    trial \n    tiempo_respuesta \n  \n \n\n  \n    Jerry \n    1 \n    0.0807501 \n  \n  \n    Jerry \n    2 \n    0.8343330 \n  \n  \n    Elaine \n    1 \n    0.6007609 \n  \n  \n    Elaine \n    2 \n    0.1572084 \n  \n  \n    George \n    1 \n    0.0073994 \n  \n  \n    George \n    2 \n    0.4663935 \n  \n\n\n\n\n\n\n(b) Wide \n \n  \n    sujeto \n    trial_1 \n    trial_2 \n  \n \n\n  \n    Jerry \n    0.4977774 \n    0.7725215 \n  \n  \n    Elaine \n    0.2897672 \n    0.8746007 \n  \n  \n    George \n    0.7328820 \n    0.1749406 \n  \n\n\n\n\n\n\nA lo largo de este capítulo iremos viendo los beneficios de almacenar los datos en formato tidy. Por supuesto que estas ventajas tienen su precio, principalemente que las bases de datos crecen mucho en tamaño si tenemos muchas medidas repetidas con distintos valores de las variables.\n\n\n1.1.2 Introducción al Tidyverse\nComo contamos más arriba, el tidyverse es una colección cerca de 25 paquetes, todos relacionados con la carga, manejo, modificación y visualización de datos. La idea de este libro no es profundizar en todas sus capacidades pero consideramos importante presentar algunas de las funciones que más vamos a utilizar a lo largo del libro. Estas son funciones para leer datos del paquete {readr}, los verbos de {dplyr} para manipularlos, las funciones de {tidyR} para acomodarlos y el poderosísimo {ggplot2} para visualizarlos.\n\n1.1.2.1 Cargando datos con readr\nUna de las cosas que vamos a hacer más a menudo en este libro es cargar algún dataset. Para esto vamos a usar varias de las funcionalidades del paquete {readr}.\nEl caso más simple al que nos vamos a enfrentar es la carga de una base de datos organizada en columnas y separadas por comas en un archivo de extensión .csv. En este caso lo que tenemos que hacer es bastante simple, usar la función read_csv() como a continuación:\n\ndata <- read_csv(\"../data/summer.csv\")\n#> Rows: 31165 Columns: 9\n#> ── Column specification ─────────────────────────────────────────────────────\n#> Delimiter: \",\"\n#> chr (8): City, Sport, Discipline, Athlete, Country, Gender, Event, Medal\n#> dbl (1): Year\n#> \n#> ℹ Use `spec()` to retrieve the full column specification for this data.\n#> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nsummary(data)\n#>       Year          City              Sport            Discipline       \n#>  Min.   :1896   Length:31165       Length:31165       Length:31165      \n#>  1st Qu.:1948   Class :character   Class :character   Class :character  \n#>  Median :1980   Mode  :character   Mode  :character   Mode  :character  \n#>  Mean   :1970                                                           \n#>  3rd Qu.:2000                                                           \n#>  Max.   :2012                                                           \n#>    Athlete            Country             Gender             Event          \n#>  Length:31165       Length:31165       Length:31165       Length:31165      \n#>  Class :character   Class :character   Class :character   Class :character  \n#>  Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n#>                                                                             \n#>                                                                             \n#>                                                                             \n#>     Medal          \n#>  Length:31165      \n#>  Class :character  \n#>  Mode  :character  \n#>                    \n#>                    \n#> \n\nLos datos adentro de summer.csv son los ganadores de medallas en los juegos olímpicos de invierno. El formato en el que read_csv() almacena los datos se llama tibble y es el formato por excelencia del tidyverse. De momento lo único que nos importa es que es un formato que almacena los casos en filas y las variables en columnas (cada variable tiene un formato). Para más información sobre las cualidades de este formato, les recomiendo revisar la documentación.\n\n\n1.1.2.2 El operador pipe (|>) del paquete {magrittr}\nEl operador pipe nos permite concatenar funciones que utilizan como entrada los mismos datos. El principio de operación es el siguiente, supongan que nosotros queremos cargar un dataset y aplicarle la función summary. Esto lo podemos hacer simplemente cargando el dataset en una lìnea de código y ejecutanco la función summary() en la siguiente.\n\ndata <- read_csv(\"../data/summer.csv\")\n#> Rows: 31165 Columns: 9\n#> ── Column specification ─────────────────────────────────────────────────────\n#> Delimiter: \",\"\n#> chr (8): City, Sport, Discipline, Athlete, Country, Gender, Event, Medal\n#> dbl (1): Year\n#> \n#> ℹ Use `spec()` to retrieve the full column specification for this data.\n#> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nsummary(data)\n#>       Year          City              Sport            Discipline       \n#>  Min.   :1896   Length:31165       Length:31165       Length:31165      \n#>  1st Qu.:1948   Class :character   Class :character   Class :character  \n#>  Median :1980   Mode  :character   Mode  :character   Mode  :character  \n#>  Mean   :1970                                                           \n#>  3rd Qu.:2000                                                           \n#>  Max.   :2012                                                           \n#>    Athlete            Country             Gender             Event          \n#>  Length:31165       Length:31165       Length:31165       Length:31165      \n#>  Class :character   Class :character   Class :character   Class :character  \n#>  Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n#>                                                                             \n#>                                                                             \n#>                                                                             \n#>     Medal          \n#>  Length:31165      \n#>  Class :character  \n#>  Mode  :character  \n#>                    \n#>                    \n#> \n\nPero, también podemos aprovechar el operador pipe y hacer todo en una única línea de código.\n\nread_csv(\"../data/summer.csv\") |> summary()\n#> Rows: 31165 Columns: 9\n#> ── Column specification ─────────────────────────────────────────────────────\n#> Delimiter: \",\"\n#> chr (8): City, Sport, Discipline, Athlete, Country, Gender, Event, Medal\n#> dbl (1): Year\n#> \n#> ℹ Use `spec()` to retrieve the full column specification for this data.\n#> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n#>       Year          City              Sport            Discipline       \n#>  Min.   :1896   Length:31165       Length:31165       Length:31165      \n#>  1st Qu.:1948   Class :character   Class :character   Class :character  \n#>  Median :1980   Mode  :character   Mode  :character   Mode  :character  \n#>  Mean   :1970                                                           \n#>  3rd Qu.:2000                                                           \n#>  Max.   :2012                                                           \n#>    Athlete            Country             Gender             Event          \n#>  Length:31165       Length:31165       Length:31165       Length:31165      \n#>  Class :character   Class :character   Class :character   Class :character  \n#>  Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n#>                                                                             \n#>                                                                             \n#>                                                                             \n#>     Medal          \n#>  Length:31165      \n#>  Class :character  \n#>  Mode  :character  \n#>                    \n#>                    \n#> \n\nAl dejar vacío el paréntesis de la función summary(), la misma va a tomar como variable de entrada a la que está antes del operador pipe, es decir, a la que antes llamamos data. En el caso que la función summary() tuviera más de una variable de entrada, lo que viene antes del pipe tomaría el lugar de la primera de ellas.\nSi bien esta funcionalidad parece algo que complica las cosas y que no trae demasiados beneficios con un ejemplo tan simple, más adelante veremos que puede ser de gran utilidad, ayudando a disminuir la cantidad de línes de código y de variables intermedias.\n\n\n1.1.2.3 Dplyr y sus verbos\nUna de las cosas más útiles del Tidyverse para el tipo de procesamiento de datos que vamos a llevar a cabo en este libro son los verbos de dplyr. Estas funciones no permiten agregar columnas, resumir la información, filtrar filas, seleccionar columnas, etc. Y todas estas acciones las podemos hacer en la base de datos completa o en una parte de ella agrupada de acuerdo a algún criterio. Vayamos de a poco.\nhttps://dplyr.tidyverse.org/\n\n\n1.1.2.4 TidyR, el paquete para ordenar tus datos\n\n\n1.1.2.5 ggplot2 o cómo hacer figuras que sean la envidia de tu compañero de escritorio"
  },
  {
    "objectID": "intro_R.html#cierre",
    "href": "intro_R.html#cierre",
    "title": "1  R y el tidyverse",
    "section": "1.2 Cierre",
    "text": "1.2 Cierre\nComo vimos brevemente en este capítulo, los paquetes del tidyverse son una herramineta importantísima para el análisis de datos utilizando R. Para más detalles sobre estas funcionalidades les recomendamos la guía de Hadley Wickham(Wickham et al. 2019) o, si ya se quieren sumergir de lleno en el mundo del análisis de datos con R, este fantástico libro [Wickham, Çetinkaya-Rundel, and Grolemund (2023)]3. Es decir, sin tener que cargar ningún paquete de funciones adicional..3 Disponible gratis online en este link https://r4ds.had.co.nz/.\n\n\n\nWickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy D’Agostino McGowan, Romain François, Garrett Grolemund, et al. 2019. “Welcome to the Tidyverse.” Journal of Open Source Software 4 (43): 1686.\n\nWickham, Hadley, Mine Çetinkaya-Rundel, and Garrett Grolemund. 2023. R for Data Science. \" O’Reilly Media, Inc.\"."
  },
  {
    "objectID": "intro_stat.html#variables-aleatorias",
    "href": "intro_stat.html#variables-aleatorias",
    "title": "2  Repaso de probabilidad y estadística",
    "section": "",
    "text": "1 Del inglés Head y ceca sera T del inglés Tail.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Repaso de probabilidad y estadística</span>"
    ]
  },
  {
    "objectID": "intro_stat.html#probabilidad",
    "href": "intro_stat.html#probabilidad",
    "title": "2  Repaso de probabilidad y estadística",
    "section": "2.2 Probabilidad",
    "text": "2.2 Probabilidad\nPara una variable como la definida en el ejemplo anterior podemos definir fácilmente su probabilidad de ocurrencia. Debido que la moneda es justa, todos los eventos de \\(\\Omega\\) son equiprobables, y es por eso que podemos definir:\n\n\n\n\\(\\omega\\)\n\\(X(\\omega)\\)\n\\(P({\\omega})\\)\n\n\n\n\nTT\n0\n1/4\n\n\nTH\n1\n1/4\n\n\nHT\n1\n1/4\n\n\nHH\n2\n1/4\n\n\n\nSin embargo, el concepto de probabilidad es algo complejo, pero, como esto no es un curso de probabilidad, vamos a confiar en que ustedes ya lo traen claro. Si tienen coraje puede ir a leer el capítulo 1 de (Wasserman 2004) y si quiere algo más terrenal pueden ir a ver el repaso de probabilidad de (Cunningham 2021) (disponible online).\n\nCunningham, Scott. 2021. Causal inference: The mixtape. Yale university press.\nCuando las variables aleatorias son continuas la cosa se complica un poco más ya que \\(P(X=c)\\), es decir, la probabilida de que una variable tome un valor dado, es cero. Esto lo vamos a repensar un poco en la siguiente sección, cuando definamos lo que nos importa para este libro: Las funciónes de densidad y de distribución.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Repaso de probabilidad y estadística</span>"
    ]
  },
  {
    "objectID": "intro_stat.html#eventos-y-probabilidad-condicional",
    "href": "intro_stat.html#eventos-y-probabilidad-condicional",
    "title": "2  Repaso de probabilidad y estadística",
    "section": "2.3 Eventos y probabilidad condicional",
    "text": "2.3 Eventos y probabilidad condicional\n\n\nEn construcción 🚧"
  },
  {
    "objectID": "intro_stat.html#probabilidad-total",
    "href": "intro_stat.html#probabilidad-total",
    "title": "2  Repaso de probabilidad y estadística",
    "section": "2.4 Probabilidad total",
    "text": "2.4 Probabilidad total\nAhora imaginemos que pasa si queremos calcular la probabilidad de B (\\(P(B)\\)). Bueno, para esto tendríamos que considerar la probabilidad de que ocurra B dado que ocurrió S y junto con la probabilidad de B dado que NO ocurrió S. A su vez, cada una de estas probabilidades deberíamos pesarlas por la probabilidad de que ocurra o no A. Esto sería2:\n2 Recordemos que \\(\\neg\\) es el símbolo lógico de la negación.\\[\nP(B) = P(B|A) \\times P(A) +  P(B|\\neg A) \\times P(\\neg A)\n\\tag{2.1}\\]\nPensemosun ejemplo. Imaginemos que una perona tiene que completar un trabajo de jardinería (evento B) en un día. La probabilidad de que termine este trabajo si llueve (evento A) es \\(0.35\\) y la probabilidad de que lo termine si no llueve es de \\(0.95\\). Si la probabilidad de que llueva es \\(P(A)=0.4\\) ¿Cuál es la probabilidad (\\(P(B)\\)) de que el trabajo se complete en un día? Echemos mano a la fórmula de probabilidad total:\n\\[\n\\begin{array}\n_P(B) &=& P(B|A) \\times P(A) + P(B|\\neg A) \\times P(\\neg A) \\\\\n&=& 0.35 \\times 0.4 + 0.95 \\times 0.6 \\\\\n&=& 0.71\n\\end{array}\n\\tag{2.2}\\]\nEntonces, la probabilidad de completar el trabajo en un día es \\(P(B)=0.71\\).\nPor último, cuando tenemos muchas condiciones, podemos definir de forma general a la probabilidad total como:\n\\[\nP(B) = \\sum_n P(B|A_n) P(A_n)\n\\tag{2.3}\\]",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Repaso de probabilidad y estadística</span>"
    ]
  },
  {
    "objectID": "intro_stat.html#teorema-de-bayes",
    "href": "intro_stat.html#teorema-de-bayes",
    "title": "2  Repaso de probabilidad y estadística",
    "section": "2.5 Teorema de Bayes",
    "text": "2.5 Teorema de Bayes\nAhora que ya llegamos a la fórmula de Bayes a partir de las definiciones de probabilidad total podemos tomar prestado un ejemplo de (Herzog, Francis, y Clarke 2019): Tenemos un test para identificar si somos portadores de un virus (llamémoslo IKV). Este test tiene una sensibilidad de 99.99% y una especificidad de 99.99%. Es decir, la probabilidad de que el test de positivo, dado que tenemos el virus (\\(P(T^+|IKV)\\)) es de 0.9999, y lo mismo ocurre para la probabilidad de que el test de negativo en caso de que NO tengamos el virus (\\(P(T^-|\\neg IKV)\\)). Sabemos también que la incidencia del virus IKV es de 1 en 10000.\n\nHerzog, Michael H, Gregory Francis, y Aaron Clarke. 2019. Understanding statistics and experimental design: how to not lie with statistics. Springer Nature.\nSupongamos que somos elegidos aleatoriamente para realizarnos el test y este da positivo ¿Qué probabilidad de ser portadores del virus tenemos (\\(P(IKV|T^+)\\))? La primera respuesta que se nos viene es 0.9999 ¿Verdad? Pero, si estuvimos prestando atención, ya a esta altura debemos saber que para invertir la condicionalidad de una probabilidad tenemos que acudir al bueno de Bayes. O sea:\n\\[\nP(IKV|T^+) = \\frac{P(T^+|IKV) \\times P(IKV)}{P(T+)}\n\\tag{2.4}\\]\ndonde \\(P(T^+|IKV) = 0.9999\\) y \\(P(IKV) = 1/10000 = 0.0001\\). Además, echando mano a la definición de probabilidad total podemos calcular \\(P(T+)\\) como:\n\\[\nP(T+) = P(T^+|IKV) \\times P(IKV) + P(T^+|\\neg IKV) \\times P(\\neg IKV)\n\\tag{2.5}\\]\ndonde \\(P(T^+|\\neg IKV) = 1-0.9999\\) y \\(P(\\neg IKV) = 1-0.0001\\). Reemplazando todos los valores tenemos que:\n\\[\n\\begin{array}\n_P(IKV|T^+) &=& \\frac{P(T^+|IKV) \\times P(IKV)}{P(T+)}\\\\\n&=& \\frac{P(T^+|IKV) \\times P(IKV)}{P(T^+|IKV) \\times P(IKV) + P(T^+|\\neg IKV) \\times P(\\neg IKV)} \\\\\n&=& \\frac{0.9999 \\times 0.0001}{0.9999 \\times 0.0001 + (1-0.9999) \\times (1-0.0001)} \\\\\n&=& \\frac{0.9999 \\times 0.0001}{0.9999 \\times 0.0001 + 0.0001 \\times 0.9999} \\\\\n&=& 0.5\n\\end{array}\n\\tag{2.6}\\]\n¿Qué? ¿Esto significa que si el test me da positivo solo tengo un 0.5 de probabilidad de tener el virus? ¿Esto quiere decir que los tests no sirven para nada? Momento, analicemos un poco al resultado al que llegamos. Lo que nos dice esta cuenta es que, una vez que el test nos da positivo, a pesar de lo sensible del test y por lo “raro” de la portación del virus, nuestra probabilidad de ser portadores es de 0.5. Pero, ¿Y nuestra probabilidad de ser portadores si el test nos da negativos? Hagamos la cuenta:\n\\[\n\\begin{array}\n_P(IKV|T^-) &=& \\frac{P(T^-|IKV) \\times P(IKV)}{P(T-)}\\\\\n&=& \\frac{P(T^-|IKV) \\times P(IKV)}{P(T^-|IKV) \\times P(IKV) + P(T^-|\\neg IKV) \\times P(\\neg IKV)} \\\\\n&=& \\frac{(1-0.9999) \\times 0.0001}{(1 - 0.9999) \\times 0.0001 + (0.9999) \\times (1-0.0001)} \\\\\n&=& 1E-8\n\\end{array}\n\\tag{2.7}\\]\nOK, ahora la cosa tiene más sentido. O sea, el test es bastante bueno para decirnos cuando no somos portadores y dando negativo, el problema es cuando da positivo. En este caso tenemos que preocuparnos, pero, como vimos anteriormente, la probabilidad de ser portadores es de apenas 0.5.\nHay una solución más simple para esto y es la que deben estar pensando ustedes: ¿Y si me hacen un segundo test? ¡BINGO! Calculemos rápidamente la probabilidad de estar infectados si nos testean por segunda vez:\n\\[\nP(IKV|T^{2+}) = \\frac{0.9999^2 \\times 0.0001}{0.9999^2 \\times 0.0001 + 0.0001^2 \\times 0.9999} = 0.9999\n\\tag{2.8}\\] Ahora sí, si somos testeados por segunda vez, la probabilidad de ser portadores dado que tenemos dos resultados positivos trepa a 0.9999. Nos podemos quedar tranquilos.\nPara cerrar, me gustaría que pensemos un poco en una palabra MUY importante que se dijo en el enunciado del problema: Aleatoriamente. En muchos de los casos en los que nos testeamos para ver si somos portadores de un virus, lo hacemos porque tenemos algún tipo de presunción de que podemos serlo (por ejemplo, tenemos síntomas). ¿Cuál creen que sería la probabilidad que se modifica en la fórmula? Exacto, \\(P(IKV)\\), ya que sería más bien \\(P(IKV|síntomas)\\).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Repaso de probabilidad y estadística</span>"
    ]
  },
  {
    "objectID": "intro_stat.html#esperanza",
    "href": "intro_stat.html#esperanza",
    "title": "2  Repaso de probabilidad y estadística",
    "section": "2.6 Esperanza",
    "text": "2.6 Esperanza\nLa esperanza de una variable aleatoria \\(X\\), a veces también llamada media poblacional, es simplemente la suma pesada de todos sus valores posibles. No debemos confundir la esperanza con el promedio muestral, aunque, como veremos en breve, para algunos casos el primero es un estimador insesgado del segundo.\nLa esperanza de una variable aleatoria discreta se define como:\n\\[\nE(X) = \\sum_{1}^\\infty x_i p(x_i)\n\\tag{2.9}\\] En este caso es muy claro la naturaleza de promedio pesado, ya que a cada valor posible de \\(X\\) lo estamos pesando por su probabilidad. Sin embargo, para una variable aleatoria continua, en la que no tenemos definida una probabilidad puntual \\(p(x_i)\\) sino una función de densidad \\(f(x)\\), la definición es la siguiente:\n\\[\nE(X) = \\int_{-\\infty}^\\infty x f(x) dx\n\\tag{2.10}\\]\nComo resulta esperable, la suma se transforma en una integral y la probabilidad puntual se reemplaza por \\(f(x)\\).\nAlgunas propiedades importantes de la esperanza son:\n\\[\n\\begin{array}\n_E(aX+b) & = & aE(X) + b\\\\\nE(\\sum_{i=1}^n X_i) & = & \\sum_{i=1}^nE(X_i)\n\\end{array}\n\\tag{2.11}\\]\nPor último y a modo de aviso, advertencia y amenaza, recordemos que \\(E(X)^2 \\neq E(X^2)\\).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Repaso de probabilidad y estadística</span>"
    ]
  },
  {
    "objectID": "intro_stat.html#varianza-y-covarianza",
    "href": "intro_stat.html#varianza-y-covarianza",
    "title": "2  Repaso de probabilidad y estadística",
    "section": "2.7 Varianza y covarianza",
    "text": "2.7 Varianza y covarianza\nLa varianza nos da una idea de la variabilidad de los procesos aleatorios que generan una variable aleatorio3. La varianza de la variable aleatoria \\(X\\) se define como:\n3 Dato que será de vital importancia para sentar las bases de la inferencia estadística.\\[\nV(X) = \\sigma^2 = E \\left[ (X - E(X))^2 \\right]\n\\tag{2.12}\\]\nY se puede demostrar que:\n\\[\nV(X) = E(X^2) - E^2(X)\n\\tag{2.13}\\]\nPor otro lado, la covarianza es mide la cantidad de dependencia lineal entre dos variables aleatorias. La msma se define como\n\\[\nCov(X,Y) = E(XY) - E(X)E(Y)\n\\tag{2.14}\\]\nSi \\(Cov(X,Y)&gt;0\\), esto indica que las dos variables se mueven en la misma dirección, mientras que si \\(Cov(X,Y)&lt;0\\) esto indica que ambas variables se mueven en direcciones opuestas.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Repaso de probabilidad y estadística</span>"
    ]
  },
  {
    "objectID": "intro_stat.html#correlación",
    "href": "intro_stat.html#correlación",
    "title": "2  Repaso de probabilidad y estadística",
    "section": "2.8 Correlación",
    "text": "2.8 Correlación\nLa correlación es la versión más amigable de la covarianza. ¿Por qué? Porque nos dice cuánto covarían dos variables independizándose de la varianza de cada una de ellas, es decir, normalizando. Esto la convierte en una medida muy relevante e informativa. Si tenemos dos variables aleatorias \\(X\\) e \\(Y\\), la correlación de se define como la covarianza es sus versiones estandarizadas:\n\\[\n\\begin{array}\n_W &=& \\frac{X-E(X)}{\\sqrt{V(X)}} \\\\\nZ &=& \\frac{Y-E(Y)}{\\sqrt{V(Y)}}\n\\end{array}\n\\tag{2.15}\\]\nDe la siguiente forma:\n\\[\n\\begin{array}\n_Corr(X,Y) &=& Cov(W,Z) \\\\\n&=&  Cov(\\frac{X-E(X)}{\\sqrt{V(X)}}, \\frac{Y-E(Y)}{\\sqrt{V(Y)}}) \\\\\n&=&  \\frac{1}{\\sqrt{V(X)}} \\frac{1}{\\sqrt{V(Y)}}  Cov(X-E(X),Y-E(Y)) \\\\\n&=&  \\frac{Cov(X,Y)}{\\sqrt{V(X) V(Y)}}\n\\end{array}\n\\tag{2.16}\\]\nUsamos la propiedad de la covarianza que dice que:\n\\[\nCov(X+a, Y+b) = Cov(X,Y) + Cov(X,b) + Cov(a,Y) + Cov(a,b)\n\\tag{2.17}\\]\nY como \\(a\\) y \\(b\\) son constantes (en nuestro caso esperanzas), el único término que sobrevive es \\(Cov(X,Y)\\). Esta magnitud es también conocida como el coeficiente de correlación \\(\\rho\\).\nCon esta definición en la mano, si yo les digo que dos variables \\(X\\) e \\(Y\\) tienen una covarianza de \\(14.988\\) no les dice mucho, ¿No? Ahora, si les digo que el coeficiente de correlación es de \\(0.788\\) probablemente entiendan rápidamente que ambas variables están muy relacionadas4.\n4 Si quieren divertirse y de paso convertise en ases de la determinación del coeficiente de correlación a ojímetro les recomiendo este juegazo. Una estudiante ostenta el abultado récord de \\(231\\) puntos ¿La pasaste?Veamos este ejemplo con números y de paso repasemos como se calcula la correlación en R:\n\n\nVer el código\nset.seed(1234)\nx = rnorm(1000, 20, 4)\ny = x*.9 + rnorm(1000, 2, 3)\ncat(paste(\"La covarianza entre X e Y es\", round(cov(x,y), 3)))\n#&gt; La covarianza entre X e Y es 14.988\ncat(paste(\"La correlación entre X e Y es\", round(cor(x,y), 3)))\n#&gt; La correlación entre X e Y es 0.788\n\n\n\n\n\n\n\nRelación lineal entre X e Y.\n\n\n\n\nEs muy importante tener en cuenta que el cueficiente de correlación nos dice cuán linealmente relacionadas están las variables. Veamos esto con un ejemplito:\n\n\nVer el código\nset.seed(1234)\nx = runif(1000, -1, 1)\ny = x^2 + .1*runif(1000, -1, 1)\ncat(paste(\"La covarianza entre X e Y es\", round(cov(x,y), 3)))\n#&gt; La covarianza entre X e Y es 0.01\ncat(paste(\"La correlación entre X e Y es\", round(cor(x,y), 3)))\n#&gt; La correlación entre X e Y es 0.055\n\n\n\n\n\n\n\nRelación no lineal entre X e Y.\n\n\n\n\nEn este caso vemos que claramente hay uan relación entre X e Y (no son una nube de puntos sin estructura) pero como esta relación no es lineal (cuadrática en nuestro caso), el coeficiente de correlación es cercano a cero.\nFinalmente, tengamos en cuenta que el coeficiente de correlación puede tomar valores entre \\(-1\\) y \\(1\\). Una correlación positiva indica que las variables varían de la misma manera (si aumenta una aumenta la otra) y lo contrario ocurre con una correlación negativa (si aumenta una disminuye la otra. Cuanto más cerca esté el coeficiente de \\(1\\) o, más fuerte es la relación lineal.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Repaso de probabilidad y estadística</span>"
    ]
  },
  {
    "objectID": "intro_stat.html#población-y-muestra",
    "href": "intro_stat.html#población-y-muestra",
    "title": "2  Repaso de probabilidad y estadística",
    "section": "2.9 Población y muestra",
    "text": "2.9 Población y muestra\nAcá usar una versión de la figurita de All of statistics que pone la generación de los datos en el dominio de la probabilidad y la estimación de estos parámetros en el dominio de la estadística. Me parece una forma ideal de empezar a hablar de qué queremos hacer con la estadística.\nVamos con un ejemplo que nos puede ayudar a entender de qué hablamos cuando hablamos de estimación. Supongamos que conocemos distribución de la altura de la población de varones en Argentina. No estamos hablando de calcular el promedio de la altura de los varones sino de que conocemos la función de densidad de la cual la altura de cada varón es una muestra. Si no queda del todo claro respiren hondo y esperen un poco que ya se va a ir aclarando. Entonces, la altura de los varones de Argentina tiene una distribución normal con media en cm. de \\(\\mu_{varones} = 175\\) y una desviación estándar \\(\\sigma_{varones} = 7\\), o, como ya aprendimos a decir: \\(H_{varones} \\sim \\mathcal{N}(\\mu_{varones},\\sigma^2_{varones}) = \\mathcal{N}(175, 49)\\)5. A continuación podemos ver la función de densidad:\n5 h del inglés height.\n\n\n\n\nFunción de densidad de probabilidad de la variabla aleatoria H (altura de los varones)\n\n\n\n\nAhora bien, en la figura podemos ver la función \\(f_X(x)\\) junto con una línea vertical que nos indica la media y dos líneas que nos indican los percentiles \\(2.5\\) y \\(97.5\\), es decir, que contienen el 95% de la masa de probabilidad. Todo esto es muy lindo pero estamos jugando a ser dios (o el Doctor Manhattan, o en lo que ustedes crean). Es imposible conocer los parámetros de esta distribución pero lo que sí podemos hacer en la práctica es estimarlos. Estimar los parámetros de un modelo es el pan y manteca de la inferencia estadística y el data mining. Como podemos ver en esta hermosa figura de Wasserman(Wasserman 2004), la teoría de probabilidad nos ayuda a definir modelos para la generación de datos y la inferencia estadística nos ayuda a estimar estos parámetros.\n\nWasserman, Larry. 2004. All of statistics: a concise course in statistical inference. Springer Science & Business Media.\nHay diversas formas de encontrar estimadores para los parámetros de un modelo (por ejemplo, método de los momentos, máxima verosimilitud, etc.) pero entenemos que eso excede los contenidos de este curso. Sin embargo, para estimar todos conocemos los estimadores de los parámetros poblacionales \\(\\mu\\) y \\(\\sigma^2\\). Claro, el promedio \\(\\bar{x}\\) y el desvío muestral \\(\\hat{S}^2\\):\n\\[\n\\begin{array}\n\\\\\\bar{x} & = & n^{-1} \\sum_{i=1}^n x_i\\\\\n\\hat{S}^2 & = & (n-1)^{-1} \\sum_{i=1}^n (x_i\n\\end{array}\n\\tag{2.18}\\]\nSimulemos tres experimento tomando 10, 50 y 100 mediciones (\\(n\\)) y veamos los histogramas de estas muestras y sus estimaciones de \\(\\mu\\) y \\(\\sigma\\):\n\n\n\n\n\n\n\n\n\nComo es de esperarse, podemos ver que al aumentar \\(n\\), la estimación de los parámetros poblacionales es mejor. Pero tenemos que tener esta idea en mente, cada vez que tomamos una muestra podemos estimar un parámetro de la población y hasta hacer inferencias estadísticas sobre el mismo, pero NUNCA lo vamos a conocer.\nAlgo importante cuando usemos un estimador es que este sea consistente, lo que implica que si aumentamos \\(n\\) al infinito, el estimador converge al valor del parámetro (en este caso el promedio muestral para \\(n \\to \\infty\\) tiende a la media poblacional \\(\\mu\\)). Decimos entonces que un estimador converge en probabilidad a un determinado parámetro. Como usuarios de la estadística esto nos va a venir masticado y no nos vamos a tener que preocupar tanto pero es bueno tenerlo en mente cuando hablamos de estimadores y estimaciones.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Repaso de probabilidad y estadística</span>"
    ]
  },
  {
    "objectID": "potential_outcomes.html",
    "href": "potential_outcomes.html",
    "title": "3  Potential outcomes",
    "section": "",
    "text": "3.1 Guerra fría, manos y contrafácticos.\nSon las 3 de la mañana del 26 de septiembre de 1983. Con una taza de café en mano, Stanislav Petrov vigila las alarmas de una estación de monitoreo de ataques nucleares a las afueras de Moscú. De pronto, los paneles se iluminan con un rojo furioso: tres misiles intercontinentales están en camino a la cúpula del Kremlin… o, quizás, el sistema tiene un error y se trata de una falsa alarma.\nStanislav no duda. Sigue el protocolo y llama al Kremlin. En menos de tres minutos, Rusia lanza un ataque nuclear contra las principales ciudades de EE. UU. La contrarespuesta estadounidense borra Leningrado y Stalingrado unos 40 minutos después. Además de millones de muertos, los ataques levantan tal cantidad de polvo en la atmósfera que el mundo se sume en un invierno nuclear durante 30 años, provocando hambruna en gran parte del hemisferio norte. Menos afectada por los ataques, la economía africana mejora lentamente y se convierte en el principal proveedor de alimentos del mundo. Para 2025, el Imperio Panafricano es la principal potencia económica global.\nTodos sabemos que esto nunca ocurrió. Lo que realmente pasó fue que Stanislav Petrov pensó que se trataba de un error y nunca avisó a nadie (pueden ver la historia aquí).\nEste mundo posnuclear es un mundo donde los hechos ocurrieron de manera completamente distinta: un mundo alternativo, un what if, un escenario contrafáctico. Podemos especular sobre lo que habría sucedido si los eventos se hubieran desarrollado de otra forma, pero la realidad es que nunca ocurrieron. Por lo tanto, un contrafáctico, aunque posible, es siempre especulativo.\n¿Para qué sirve entonces construir contrafácticos, imaginar cosas que no ocurrieron y que nunca ocurrirán? Veamos otra historia.\nEste cuadro se llama Praying Hands y fue pintado por Albrecht Durero. Es una de las obras más importantes de su siglo.\nLos Durero eran una familia de mineros pobres del sur de Alemania. Dos de sus hijos, Albrecht y Joseph, tenían talento para el dibujo y decidieron hacer un pacto: uno estudiaría en Núremberg durante cuatro años mientras el otro trabajaría en las minas para pagar su educación. Decidiria quien con una moneda. Pasado ese tiempo, intercambiarían lugares.\nEl azar favoreció a Albrecht. Durante esos cuatro años, se convirtió en un pintor famoso y regresó a casa para cumplir su parte del acuerdo. Sin embargo, al llegar, Joseph lo recibió con una triste noticia: era demasiado tarde. El arduo trabajo en la mina le había provocado una artritis severa, impidiéndole sostener un pincel. Como único tributo a su sacrificio, Albrecht decidió pintar sus manos.\nAhora tenemos dos escenarios contrafacticos, lo que le hubiera sucedido a Albretch si se quedaba en la mina, y lo que le hubiera sucedido a Joseph si se iba a estudiar a Nuremberg. De modo que el escenario seria asi.\nAmbos son hermanos, comparten cierto talento y muchas cosas. Uno podria suponer que el destino de Joseph podria servir para suponer con mayor precision lo que le paso “le hubiera pasado a Albretch de no ir a Nuremberg” (escenario contrafactico) y el destino de Albetch “lo que le hubiera pasado a Joseph si hubiera podido ir a Nuremberg” (escenario contrafactico). Entonces imaginar escenarios contrafacticos nos permiten estimar el efecto de ir a Nuremberg o de quedarse. Para eso creamos los contrafacticos.\nAhora bien, es Joseph lo mismo que Albrecth, si la moneda hubiera favorecido a Joseph, habria un Durero pintor famoso? Bueno no estamos seguros de eso, lo que si podemos estar seguros es que pese a parecidos no son exactamente el mismo y quizas hay diferencias en talentos o en suceptibilidad a la artritis lo que hace que el destino de uno funcione como un simil o proxy de su destino contrafactico pero no el destino en si mismo. Con estas ideas podemos armar un marco teorico donde esos efectos se puedan estimar. Este marco teorico se llama outcomes potenciales.\nSupongamos que quiero evaluar la efectividad de la aspirina para mitigar el dolor de cabeza. Me duele la cabeza y lo quiero es saber el efecto diferencial entre tomar y no tomar esa aspirina. Es decir, en el tiempo 0 estoy yo con dolor de cabeza y en el tiempo 1 debería haber dos versiones mías (como si una no fuera suficiente), la que tomó la aspirina y la que no. A cada una de ellas les tendría que preguntar cuánto les duele la cabeza, el outcome de mi comparación. No hace falta ser demasiado astuto para darse cuenta que esto es imposible ya que sólo nos será posible obsevar una de esas versiones mientras que la otra será un contrafáctico.\nDe esto vamos a hablar en este capítulo, utilizando la tradición de los potential outcomes. Estas ideas terminan de tomar forma en la versión que conocemos en las ciencias sociales en (Rubin 1974).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>*Potential outcomes*</span>"
    ]
  },
  {
    "objectID": "potential_outcomes.html#sdf",
    "href": "potential_outcomes.html#sdf",
    "title": "3  Potential outcomes",
    "section": "3.1 Sdf",
    "text": "3.1 Sdf"
  },
  {
    "objectID": "dags.html",
    "href": "dags.html",
    "title": "4  Grafos acíclicos dirigidos (DAGS)",
    "section": "",
    "text": "4.1 Definiciones, características y ejemplos\nUn DAG es una representación gráfica de una cadena de efectos causales. Los nodos (los circulitos o cuadraditos que vamos a ver más adelante) representan variables aleatorias y las flechas que los unen representan la relación causal que se mueve de una variable a la otra en la dirección intuitiva de la flecha. Por ejemplo, pensemos que queremos estudiar el efecto de tomar una aspirina en la intensidad de nuestro dolor de cabeza cuando nos duele la cabeza. Tenemos dos variables Aspirina (A) e Intensidad del dolor (I). Esta relación la podemos expresar en el siguiente DAG:\nDAG que representa la relación entre tomar una aspirina (A) y la intensidad del dolor (I).\n¿Así de simple? Sí y no ¿Qué pasa cuando las cosas se empiezan a complicar? Pensemos en el clásico ejemplo del mantra “correlación no implica causalidad” la relación entre venta de helados (Hel) y accidentes por mordidas de tiburón en Australia(Sh). Si nosotros planteáramos que el aumento de la venta de helados causa el aumento de los accidentes no tendría mucho sentido, ¿No?. Entonces, ¿Qué está pasando? ¿Qué pinta tiene el DAG? Bueno, como ya comentamos cuando hablamos de correlación en este caso lo que tenemos es una común a ambos fenómenos que, a modo de simplificar, la podríamos resumir como la temperatura (T). Entonces, cuando sube la temperatura sube la venta de helados, pero también los accidentes por mordidas de tiburón. Una posible relación causal entre ambas variables podría ser esta:\nDAG que representa la relación entre las ventas de helados (Hel), los accidentes por mordida de tiburón (Sh) y la temnperatura (T) en las playas de Australia.\nTodo muy lindo, pero ¿Para qué?",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Grafos acíclicos dirigidos (DAGS)</span>"
    ]
  },
  {
    "objectID": "dags.html#definiciones-características-y-ejemplos",
    "href": "dags.html#definiciones-características-y-ejemplos",
    "title": "4  Grafos acíclicos dirigidos (DAGS)",
    "section": "",
    "text": "DAGS en R\n\n\n\nPara realizar los DAGS que aparecen en este capítulo utilizamos la librería {ggdag}. Para esto primero debemos hacer un esquema de nuestro DAG en Daggity y luego copiar parte de lo generado en la definición de nuestro DAG en R. En el desarrollo del capítulo utilizaremos algunas de las herramientas de {ggdag}, varias de las cuales pueden encontrar en este tutorial. Sin embargo, para una revisión pormenorizada de sus funciones recomiendo repasar la documentación del mismo.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Grafos acíclicos dirigidos (DAGS)</span>"
    ]
  },
  {
    "objectID": "dags.html#el-criterio-de-las-puertas-de-atrás",
    "href": "dags.html#el-criterio-de-las-puertas-de-atrás",
    "title": "4  Grafos acíclicos dirigidos (DAGS)",
    "section": "4.2 El criterio de las puertas de atrás",
    "text": "4.2 El criterio de las puertas de atrás\nUna de las principales ventajas de plantear un DAg para estudiar una relación causal es que nos permite ajustar un modelo a partir del cual, lo que estamos estimando en uno de sus parámetros es un estimador de la relación causal que queremos estudiar. Empecemos planteando los caminos posibles para llegar desde Hel a Sh. En este caso serían dos:\n\\[\n\\begin{array}\n_Hel    \\longrightarrow Sh \\\\\nHel \\longleftarrow T \\longrightarrow Sh\n\\end{array}\n\\]\nEl primero es lo que se llama un camino directo y es lo relación causal que queremos estudiar. Por otro lado, el segundo (\\(Hel \\leftarrow T \\rightarrow Sh\\)) es lo que se llama una puerta de atrás y lo identíficamos porque, al menos en alguna de sus relaciones causales, la flechita va para la izquierda. Identificar estos caminos puerta de atrás es una parte fundamental de controlar la variabilidad espúrea en nuestras relaciones causales. En particular en este ejemplo, tenemos un claro confusor y lo que queremos es controlar por T.\nSimulemos esta relación y veamos que pasa.\n\n\nVer el código\nset.seed(1414)\nhelados &lt;- tibble(\n  Temperatura = rnorm(1000, 20, 5),\n  Helados     = 1 + 1*Temperatura + rnorm(1000),\n  Ataques     = 1 + 2*Temperatura + 0*Helados + rnorm(1000)\n)\n\n\nVeamos que Temperatura es una variable aleatoria con distribución normal con media \\(20\\) y desviación estándar \\(5\\). Tomamos \\(1000\\) muestras de la misma y después generamos las variables Helados y Ataques como una combinación lineal de Temperatura más un error aleatorio de media \\(0\\) y desviación estándar \\(1\\). En la definición de Ataques podemos ver explícitamente que la influencia de Helados en Ataques es \\(0\\). Sin embargo, miremos la relación que existe entre ambas variables:\n\n\n\n\n\nDAG que representa la relación entre las ventas de helados (Hel), los accidentes por mordida de tiburón (Sh) y la temnperatura (T) en las playas de Australia.\n\n\n\n\nVemos que ambas variables están altamente correlacionadas, de hecho, su r de Pearson vale 0.977. Sin embargo, nosotros sabemos que esa correlación es espúrea, que no hay una relación causal entre ventas de helados y ataques de tiburón y que algo tenemos que hacer. Hemos escuchado muchas veces que lo que tenemos que hacer es “controlar” por la temperatura, lo que en el contexto de la regresión lineal no significa otra cosa que agergar Temperatura como una covariable. Ajustemos dos modelos de regresión, uno con la Temperatura como covariable y uno sin y comparemos las estimaciones de los efectos causales (\\(\\hat\\beta_H\\))2 :\n2 Recuerden que el diagrama causal no es un problema estadístico sino más bien se plantea previo a cualquier consideración estadística, usando como insumo el conocimiento del dominio que tenemos.\\[\n\\begin{array}\n_lm_1&:& Ataques_i = \\alpha + \\beta_{H} Helados_i + \\epsilon_i \\\\\nlm_2&:& Ataques_i = \\alpha + \\beta_{H} Helados_i +  \\beta_{T} Temperatura_i + \\tau_i\n\\end{array}\n\\] En la siguiente tabla podemos ver las estimaciones de \\(\\hat\\beta_H\\) para cada uno de los modelos:\n\n\n\nTabla 4.1: Estimaciones de los parámetros de los modelos lm1 y lm2 definidos anteriormente.\n\n\n\n\n\n\n\n\n\n\n\nDependent variable:\n\n\n\n\n\n\n\n\n\n\n\n\nAtaques\n\n\n\n\n\n\nSin controlar por Temp.\n\n\nControlando por Temp.\n\n\n\n\n\n\n(1)\n\n\n(2)\n\n\n\n\n\n\n\n\nHelados\n\n\n1.928***\n\n\n-0.001\n\n\n\n\n\n\n(0.013)\n\n\n(0.032)\n\n\n\n\n\n\n\n\n\n\n\n\nTemperatura\n\n\n\n\n2.003***\n\n\n\n\n\n\n\n\n(0.033)\n\n\n\n\n\n\n\n\n\n\n\n\nConstant\n\n\n0.602**\n\n\n1.015***\n\n\n\n\n\n\n(0.291)\n\n\n(0.134)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n1,000\n\n\n1,000\n\n\n\n\nR2\n\n\n0.954\n\n\n0.990\n\n\n\n\nAdjusted R2\n\n\n0.954\n\n\n0.990\n\n\n\n\nResidual Std. Error\n\n\n2.246 (df = 998)\n\n\n1.032 (df = 997)\n\n\n\n\nF Statistic\n\n\n20,826.210*** (df = 1; 998)\n\n\n51,243.220*** (df = 2; 997)\n\n\n\n\n\n\n\n\nNote:\n\n\np&lt;0.1; p&lt;0.05; p&lt;0.01\n\n\n\n\n\n\nComo podemos ver, si no controlamos por Temperatura , la estimación de \\(\\hat\\beta_H\\) tiene un valor cercano a \\(1\\), mientras que si controlamos por Temperatura tiene un valor cercano a \\(0\\) lo que sabemos es el valor “real” del parámetro \\(\\beta_H\\). Todo muy lindo pero, ¿Qué tiene que ver esto con los DAGS? Bueno, cuando planteamos un DAG existe algo que se llama el criterio de las puertas traseras que dice que para estimar el efecto causal que nos interesa debemos “cerrar” todas las puertas traseras que conectan la causa y elefecto. Y “cerrar” en este contexto es simplemente controlar por la variabilidad de alguna de las variables presentes en la puerta trasera. En este caso, controlando por Temperatura estamos cerrando la única puerta trasera, por lo tanto, estamos estimando el verdadero efecto causal que nos interesa.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Grafos acíclicos dirigidos (DAGS)</span>"
    ]
  },
  {
    "objectID": "dags.html#colliders",
    "href": "dags.html#colliders",
    "title": "4  Grafos acíclicos dirigidos (DAGS)",
    "section": "4.3 Colliders",
    "text": "4.3 Colliders\nHasta ahora tuvimos que lidiar casi únicamente con confusores pero existe otro tipo de variables en el contexto de un camino causal que se denomina collider. Vemos un ejemplo y apliquemos el criterio de las puertas traseras. Pensemos el siguiente ejemplo. Supongamos que queremos estudiar el efecto del factor de riesgo edad (Age) en la infección de COVID-19 (Cov), pero lo hacemos a través de datos voluntarios recavados por una aplicación móvil (App). Un DAG muy simplicado que podríamos plantear es el siguiente:\n\n\n\n\n\nDAG que representa la relación entre la edad (Age), la infección por COVID-19 (Cov) y el uso de la aplicación móvil de autoreporte (App).\n\n\n\n\nYa uqe sabemos que la edad tienen un. efecto en el uso de aplicaciones móviles y, podemos suponer, que la gente que se infecta de COVID-19 tiende a reportar más sus datos en la aplicación. Ahora veamos los caminos:\n\\[\n\\begin{array}\n_Age    \\longrightarrow Cov \\\\\nAge \\longrightarrow App \\longleftarrow Cov\n\\end{array}\n\\] Repitamos el ejercicio de simulación que utilizamos en el ejemplo de los confusores, sólo que esta vez Covid es una variable dicotómica y, por lo tanto, debemos muestrarla de una distribución Bernoulli3:\n3 Esto resulta especialmente útil cuando los DAGS se empiezan a complicar.\n\nVer el código\nset.seed(123)\ncovid &lt;- tibble(\n  Age   = rnorm(1000, 40, 10),\n  Covid = rbinom(1000, 1, prob = 1/(1+exp(10-.25*Age))),\n  App   = 1 - 1*Age + 1*Covid +rnorm(1000)\n)\n\n\nPuede verse que la verdadera relación entre Covid y Age (en términos de parámetros de una regresión logística) es \\(0.25\\). Veamos como se ve la edad de los infectados y no infectados:\n\n\n\n\n\nInfectados y no infectados de COVID-19 en función de la edad.\n\n\n\n\nSegún el criterio de las puertas traseras deberíamos controlar por App para así cerrar ese camino. Ajustemos estos dos regresiones logísticas y veamos sus estimaciones de los parámetros:\n\\[\n\\begin{array}\n_glm_1&:& logit(Covid_i) = \\alpha + \\beta_{Age} Age_i + \\epsilon_i \\\\\nglm_2&:& logit(Covid_i) = \\alpha + \\beta_{Age} Age_i + \\beta_{App} App_i + \\epsilon_i\n\\end{array}\n\\]\nEn la siguiente tabla podemos ver las estimaciones de \\(\\hat\\beta_{Age}\\) para cada uno de los modelos:\n\n\n\nTabla 4.2: Estimaciones de los parámetros de los modelos glm1 y glm2 definidos anteriormente.\n\n\n\n\n\n\n\n\n\n\n\nDependent variable:\n\n\n\n\n\n\n\n\n\n\n\n\nCovid\n\n\n\n\n\n\nSin controlar por App\n\n\nControlando por App\n\n\n\n\n\n\n(1)\n\n\n(2)\n\n\n\n\n\n\n\n\nAge\n\n\n0.243***\n\n\n1.354***\n\n\n\n\n\n\n(0.016)\n\n\n(0.109)\n\n\n\n\n\n\n\n\n\n\n\n\nApp\n\n\n\n\n1.100***\n\n\n\n\n\n\n\n\n(0.103)\n\n\n\n\n\n\n\n\n\n\n\n\nConstant\n\n\n-9.787***\n\n\n-11.839***\n\n\n\n\n\n\n(0.631)\n\n\n(0.763)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n1,000\n\n\n1,000\n\n\n\n\nLog Likelihood\n\n\n-419.336\n\n\n-344.156\n\n\n\n\nAkaike Inf. Crit.\n\n\n842.672\n\n\n694.312\n\n\n\n\n\n\n\n\nNote:\n\n\np&lt;0.1; p&lt;0.05; p&lt;0.01\n\n\n\n\n\n\nLa estimación del efecto correcta sería la del modelos sin controlar pero ¿Por qué pasa esto? Cuando tenemos un collider podemos considerar ese camino como cerrado por defecto y al controlar por él, ese camino se abre. Entonces, en si bien teníamos dos posibles caminos causales, sólo uno estaba abierto y no necesitábamos controlar por App. Esto se debe a que, al App no causar ninguna de mis otras dos variables, ese camino causal está cerrado. Para reflexionar un poco en por qué ese camino se abre al controlar por un collider recomiendo las reflexiones del capítulo 8 de (Huntington-Klein 2021).\n\n\n\n\n\n\nEl criterio de las puertas traseras\n\n\n\nEn resumen, el criterio de las puertas traseras nos dice que para estimar la relación causal principal debemos cerrar todas las puertas traseras (caminos causales entre la causa y el efecto que queremos estudiar que tienen alguna flecha hacia atrás). Recordemos que para cerrar esos caminos debemos controlar por alguna de las variables que lo componen, agragándola como covariable a nuestro modelo estadístico. Por último, recordemos que cuando tenemos un collider el camino està cerrado y al controlar por él lo abrimos.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Grafos acíclicos dirigidos (DAGS)</span>"
    ]
  },
  {
    "objectID": "dags.html#un-ejemplo",
    "href": "dags.html#un-ejemplo",
    "title": "4  Grafos acíclicos dirigidos (DAGS)",
    "section": "4.4 Un ejemplo",
    "text": "4.4 Un ejemplo\nAnalicemos un ejemplo que tiene un poquito de todo. En el mismo queremos estudiar la el efecto de las vitaminas (Vits) en los defectos de nacimiento (BD). Además de esta relación, podemos identificar otras variables que podrían influir en ellas: La dificultad para concebir un embarazo (DC); El cuidado pre-natal (PNC); el status socioeconómico (SES); y aspectos genéticos (Gen). El flujo de causalidad propuesto entre las variables puede verse representado en el siguiente DAG4:\n4 Recuerden que el diagrama causal no es un problema estadístico sino más bien se plantea previo a cualquier consideración estadística, usando como insumo el conocimiento del dominio que tenemos.\n\nVer el código\ndag_Vit &lt;- dagitty::dagitty('dag {\n                          BD [outcome,pos=\"0.109,0.631\"]\n                          DC [pos=\"0.117,-1.517\"]\n                          Gen [pos=\"0.850,-0.411\"]\n                          PNC [pos=\"-0.837,-0.433\"]\n                          SES [pos=\"-1.839,-1.468\"]\n                          Vits [exposure,pos=\"-1.844,0.645\"] \n                          DC -&gt; PNC\n                          Gen -&gt; BD\n                          Gen -&gt; DC\n                          PNC -&gt; BD\n                          PNC -&gt; Vits\n                          SES -&gt; PNC\n                          SES -&gt; Vits\n                          Vits -&gt; BD\n                          }')\n\ntidy_dag &lt;- tidy_dagitty(dag_Vit)\nggdag(tidy_dag) +\n  theme_dag()\n\n\n\n\n\nDAG que representa la relación causal entre las vitaminas y los defectos de nacimiento.\n\n\n\n\nSi tebemos todos estos datos observados y queremos estimar el efecto causal de las vitaminas en los defectos de nacimiento, lo primero que tenemos que hacer es plantear todos los caminos abiertos. Esto lo podemos hacer a ojo, pero también nos podemos ayudar con la función ggdag_paths del paquete {ggdags}5. A continuación vemos un ejemplo de uso de esta función:\n5 Esto resulta especialmente útil cuando los DAGS se empiezan a complicar.\n\nVer el código\ndag_Vit %&gt;% ggdag_paths(from = \"Vits\", to = \"BD\", shadow = TRUE) +\n  theme_dag() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nUsando ggdag_collider para identificar colliders en nuestro DAG.\n\n\n\n\nPodemos ver que los caminos abiertos son:\n\\[\n\\begin{array}\n_Vits \\longrightarrow BD\\\\\nVits \\longleftarrow PNC \\longrightarrow BD\\\\\nVits \\longleftarrow PNC \\longleftarrow DC \\longleftarrow Gen \\longrightarrow BD \\\\\nVits \\longleftarrow SES \\longrightarrow PNC \\longrightarrow BD\n\\end{array}\n\\]\nPero ¿Por qué no está abierto el camino \\(Vits \\leftarrow SES \\rightarrow PNC \\leftarrow DC \\leftarrow Gen \\rightarrow BD\\)? ¡Exacto! Está cerrado, porque para ese camino PNC es un collider, ya que está causada tanto por SES como por DC. Resulta importante notar que una variable es un collider o no en el contexto de un camino de causalidad y no lo es siempre. De hecho, podemos ver que PNC actúa como un confusor en el camino \\(Vits \\leftarrow PNC \\rightarrow BD\\). La función ggdag_collider también nos puede ayudar a identificar un collider.\n\n\nVer el código\ndag_Vit %&gt;% ggdag_collider() +\n     theme_dag() +\n     scale_color_brewer(palette = \"Dark2\")\n\n\n\n\n\nUsando ggdag_collider para identificar colliders en nuestro DAG.\n\n\n\n\nEntonces tenemos cuatro caminos abiertos, el que queremos estudiar y tres puertas de atráss. Sin embargo, tenemos la suerte que controlando sólo por PNC Todo indica que tenemos que controlar por Diab y listo ¿No? Apliquemos esto agregando el parámetro adjust_for = \"Diab\" a la función ggdag_paths:\n\n\nVer el código\ndag_Vit %&gt;% ggdag_paths(from = \"Vits\", to = \"BD\",\n                       adjust_for = \"PNC\", shadow = TRUE) +\n  theme_dag() +\n  labs(hue = NULL) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nCaminos causales abiertos luego de controlar por PNC.\n\n\n\n\nSin embargo, podemos ver que, aún controlando por PNC, los caminos abiertos son:\n\\[\n\\begin{array}\n_Vits \\longrightarrow BD\\\\\nVits \\leftarrow SES \\rightarrow PNC \\leftarrow DC \\leftarrow Gen \\rightarrow BD\n\\end{array}\n\\]\n¿Qué pasó? Bueno, lo que pasó es que al controlar por un collider abrimos un camino que estaba cerrado. Miremos qué pasa si controlamos por PNC y DC:\n\n\nVer el código\ndag_Vit %&gt;% ggdag_paths(from = \"Vits\", to = \"BD\",\n                       adjust_for = c(\"PNC\", \"DC\"), shadow = TRUE) +\n  theme_dag() +\n  labs(hue = NULL) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nCaminos causales abiertos luego de controlar por Diab y Smok.\n\n\n\n\nAhora sí, el único camino abierto es \\(Vits \\rightarrow DC\\), que es la relaciòn causal que queremos estudiar. Finalmente, el modelo que deberíamos ajustar es:\n\\[\nDC_i = \\alpha + \\beta_{Vits} Vits_i + \\beta_{PNC} PNC_i + \\beta_{DC} DC_i + + \\epsilon_i\n\\]\nDonde \\(\\beta_{Vits}\\) es un estimador del efecto causal que queremos estudiar.\nPara más ejemplos y detalles sobre los DAGS pueden consultar (Cunningham 2021) o (Huntington-Klein 2021). El canal de YouTube de Nick Huntington-Klein también es un excelente recurso para profundizar sobre estos temas6.\n\n\n\nCunningham, Scott. 2021. Causal inference: The mixtape. Yale university press.\n6 Nick es el autor de (Huntington-Klein 2021).\nHuntington-Klein, Nick. 2021. The effect: An introduction to research design and causality. Chapman; Hall/CRC.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Grafos acíclicos dirigidos (DAGS)</span>"
    ]
  },
  {
    "objectID": "exp_aleatorios.html",
    "href": "exp_aleatorios.html",
    "title": "5  Experimentos aleatorios",
    "section": "",
    "text": "El capítulo que sigue está en construcción 🚧. Por favor tengan paciencia."
  },
  {
    "objectID": "exp_aleatorios.html#sdf",
    "href": "exp_aleatorios.html#sdf",
    "title": "5  Experimentos aleatorios",
    "section": "5.1 Sdf",
    "text": "5.1 Sdf"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Cunningham, Scott. 2021. Causal Inference: The Mixtape. Yale\nuniversity press.\n\n\nHerzog, Michael H, Gregory Francis, and Aaron Clarke. 2019.\nUnderstanding Statistics and Experimental Design: How to Not Lie\nwith Statistics. Springer Nature.\n\n\nHuntington-Klein, Nick. 2021. The Effect: An Introduction to\nResearch Design and Causality. Chapman; Hall/CRC.\n\n\nR Core Team. 2023. R: A Language and Environment for Statistical\nComputing. Vienna, Austria: R Foundation for Statistical Computing.\nhttps://www.R-project.org/.\n\n\nRubin, Donald B. 1974. “Estimating Causal Effects of Treatments in\nRandomized and Nonrandomized Studies.” Journal of Educational\nPsychology 66 (5): 688.\n\n\nTönnies, Thaddäus, Sabine Kahl, and Oliver Kuss. 2022. “Collider\nBias in Observational Studies: Consequences for Medical Research Part 30\nof a Series on Evaluation of Scientific Publications.”\nDeutsches Ärzteblatt International 119 (7): 107.\n\n\nWasserman, Larry. 2004. All of Statistics: A Concise Course in\nStatistical Inference. Springer Science & Business Media.\n\n\nWickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy\nD’Agostino McGowan, Romain François, Garrett Grolemund, et al. 2019.\n“Welcome to the Tidyverse.” Journal of Open Source\nSoftware 4 (43): 1686.\n\n\nWickham, Hadley, Mine Çetinkaya-Rundel, and Garrett Grolemund. 2023.\nR for Data Science. \" O’Reilly Media, Inc.\"."
  },
  {
    "objectID": "dags.html#causalidad-sin-correlación",
    "href": "dags.html#causalidad-sin-correlación",
    "title": "4  Grafos acíclicos dirigidos (DAGS)",
    "section": "4.3 Causalidad sin correlación",
    "text": "4.3 Causalidad sin correlación\nMuchas veces escuchamos que “correlación no implica causalidad” pero ¿Causalidad implica correlación? Respondamos esta pregunta con un ejemplo. Supongamos que hay una relación causal entre el ingreso (I) y la satisfacción (S), a más ingreso más satisfacción."
  },
  {
    "objectID": "intro_R.html#tidy-data",
    "href": "intro_R.html#tidy-data",
    "title": "1  R y el tidyverse",
    "section": "",
    "text": "2 El caso contrario sería en el que una fila contiene varios mediciones para distintos niveles de una variable. Este formato se conoce como wide.\n\n\nTabla 1.1: Ejemplo de tablas tidy y wide.\n\n\n\n\n\n\n\n(a) Tidy\n\n\n\n\n\nsujeto\ntrial\ntiempo_respuesta\n\n\n\n\nJerry\n1\n0.0807501\n\n\nJerry\n2\n0.8343330\n\n\nElaine\n1\n0.6007609\n\n\nElaine\n2\n0.1572084\n\n\nGeorge\n1\n0.0073994\n\n\nGeorge\n2\n0.4663935\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b) Wide\n\n\n\n\n\nsujeto\ntrial_1\ntrial_2\n\n\n\n\nJerry\n0.4977774\n0.7725215\n\n\nElaine\n0.2897672\n0.8746007\n\n\nGeorge\n0.7328820\n0.1749406",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>R y el tidyverse</span>"
    ]
  },
  {
    "objectID": "intro_R.html#introducción-al-tidyverse",
    "href": "intro_R.html#introducción-al-tidyverse",
    "title": "1  R y el tidyverse",
    "section": "1.2 Introducción al Tidyverse",
    "text": "1.2 Introducción al Tidyverse\nComo contamos más arriba, el tidyverse es una colección cerca de 25 paquetes, todos relacionados con la carga, manejo, modificación y visualización de datos. La idea de este libro no es profundizar en todas sus capacidades pero consideramos importante presentar algunas de las funciones que más vamos a utilizar a lo largo del libro. Estas son funciones para leer datos del paquete {readr}, los verbos de {dplyr} para manipularlos, las funciones de {tidyR} para acomodarlos y el poderosísimo {ggplot2} para visualizarlos.\n\n1.2.1 Cargando datos con readr\nUna de las cosas que vamos a hacer más a menudo en este libro es cargar algún dataset. Para esto vamos a usar varias de las funcionalidades del paquete {readr}.\nEl caso más simple al que nos vamos a enfrentar es la carga de una base de datos organizada en columnas y separadas por comas en un archivo de extensión .csv. En este caso lo que tenemos que hacer es bastante simple, usar la función read_csv() como a continuación:\n\n\nVer el código\nsummer &lt;- read_csv(\"../data/summer.csv\")\n\n\nPodemos ver que al cargar los datos read_csv nos dice que hay ocho columnas chr (o sea de texto) y una dbl (o sea, un número). Si usamos la función summary podemos ver un detalle de cada avriable con su tipo y alguna descripción3:\n3 Existen alternativas para visualizar rápidamente un conjunto de datos como str o glimpse o la función skim del paquete {skimr}.\n\nVer el código\nsummary(summer)\n#&gt;       Year          City              Sport            Discipline       \n#&gt;  Min.   :1896   Length:31165       Length:31165       Length:31165      \n#&gt;  1st Qu.:1948   Class :character   Class :character   Class :character  \n#&gt;  Median :1980   Mode  :character   Mode  :character   Mode  :character  \n#&gt;  Mean   :1970                                                           \n#&gt;  3rd Qu.:2000                                                           \n#&gt;  Max.   :2012                                                           \n#&gt;    Athlete            Country             Gender             Event          \n#&gt;  Length:31165       Length:31165       Length:31165       Length:31165      \n#&gt;  Class :character   Class :character   Class :character   Class :character  \n#&gt;  Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n#&gt;                                                                             \n#&gt;                                                                             \n#&gt;                                                                             \n#&gt;     Medal          \n#&gt;  Length:31165      \n#&gt;  Class :character  \n#&gt;  Mode  :character  \n#&gt;                    \n#&gt;                    \n#&gt; \n\n\nLos datos adentro de summer.csv son los ganadores de medallas en los juegos olímpicos de verano. Podemos ver algunas filas de muestra:\n\n\nVer el código\nhead(summer)\n#&gt; # A tibble: 6 × 9\n#&gt;    Year City   Sport    Discipline Athlete               Country Gender\n#&gt;   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    &lt;chr&gt;      &lt;chr&gt;                 &lt;chr&gt;   &lt;chr&gt; \n#&gt; 1  1896 Athens Aquatics Swimming   HAJOS, Alfred         HUN     Men   \n#&gt; 2  1896 Athens Aquatics Swimming   HERSCHMANN, Otto      AUT     Men   \n#&gt; 3  1896 Athens Aquatics Swimming   DRIVAS, Dimitrios     GRE     Men   \n#&gt; 4  1896 Athens Aquatics Swimming   MALOKINIS, Ioannis    GRE     Men   \n#&gt; 5  1896 Athens Aquatics Swimming   CHASAPIS, Spiridon    GRE     Men   \n#&gt; 6  1896 Athens Aquatics Swimming   CHOROPHAS, Efstathios GRE     Men   \n#&gt; # ℹ 2 more variables: Event &lt;chr&gt;, Medal &lt;chr&gt;\n\n\nEl formato en el que read_csv almacena los datos se llama tibble y es el formato por excelencia del tidyverse. De momento lo único que nos importa es que es un formato que almacena los casos en filas y las variables en columnas (cada variable tiene un formato). Para más información sobre las cualidades de este formato, les recomiendo revisar la documentación.\n\n\n1.2.2 El operador pipe (|&gt;) del paquete {magrittr}\nEl operador pipe nos permite concatenar funciones que utilizan como entrada los mismos datos. El principio de operación es el siguiente, supongan que nosotros queremos cargar un dataset y aplicarle la función summary. Esto lo podemos hacer simplemente cargando el dataset en una lìnea de código y ejecutanco la función summary() en la siguiente.\n\n\nVer el código\ndata &lt;- read_csv(\"../data/summer.csv\")\nsummary(data)\n#&gt;       Year          City              Sport            Discipline       \n#&gt;  Min.   :1896   Length:31165       Length:31165       Length:31165      \n#&gt;  1st Qu.:1948   Class :character   Class :character   Class :character  \n#&gt;  Median :1980   Mode  :character   Mode  :character   Mode  :character  \n#&gt;  Mean   :1970                                                           \n#&gt;  3rd Qu.:2000                                                           \n#&gt;  Max.   :2012                                                           \n#&gt;    Athlete            Country             Gender             Event          \n#&gt;  Length:31165       Length:31165       Length:31165       Length:31165      \n#&gt;  Class :character   Class :character   Class :character   Class :character  \n#&gt;  Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n#&gt;                                                                             \n#&gt;                                                                             \n#&gt;                                                                             \n#&gt;     Medal          \n#&gt;  Length:31165      \n#&gt;  Class :character  \n#&gt;  Mode  :character  \n#&gt;                    \n#&gt;                    \n#&gt; \n\n\nPero, también podemos aprovechar el operador pipe y hacer todo en una única línea de código.\n\n\nVer el código\nread_csv(\"../data/summer.csv\") |&gt; summary()\n#&gt;       Year          City              Sport            Discipline       \n#&gt;  Min.   :1896   Length:31165       Length:31165       Length:31165      \n#&gt;  1st Qu.:1948   Class :character   Class :character   Class :character  \n#&gt;  Median :1980   Mode  :character   Mode  :character   Mode  :character  \n#&gt;  Mean   :1970                                                           \n#&gt;  3rd Qu.:2000                                                           \n#&gt;  Max.   :2012                                                           \n#&gt;    Athlete            Country             Gender             Event          \n#&gt;  Length:31165       Length:31165       Length:31165       Length:31165      \n#&gt;  Class :character   Class :character   Class :character   Class :character  \n#&gt;  Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n#&gt;                                                                             \n#&gt;                                                                             \n#&gt;                                                                             \n#&gt;     Medal          \n#&gt;  Length:31165      \n#&gt;  Class :character  \n#&gt;  Mode  :character  \n#&gt;                    \n#&gt;                    \n#&gt; \n\n\nAl dejar vacío el paréntesis de la función summary(), la misma va a tomar como variable de entrada a la que está antes del operador pipe, es decir, a la que antes llamamos data. En el caso que la función summary() tuviera más de una variable de entrada, lo que viene antes del pipe tomaría el lugar de la primera de ellas.\nSi bien esta funcionalidad parece algo que complica las cosas y que no trae demasiados beneficios con un ejemplo tan simple, más adelante veremos que puede ser de gran utilidad, ayudando a disminuir la cantidad de línes de código y de variables intermedias.\n\n\n1.2.3 {dplyr} y sus verbos\nUna de las cosas más útiles del tidyverse para el tipo de procesamiento de datos que vamos a llevar a cabo en este libro son los verbos de dplyr. Estas funciones no permiten agregar columnas, resumir la información, filtrar filas, seleccionar columnas, etc4. Y todas estas acciones las podemos hacer en la base de datos completa o en una parte de ella agrupada de acuerdo a algún criterio. Vayamos de a poco.\n4 Para más detalles sobre los verbos disponibles en el paquete {dplyr} pueden visital este la página de referencia.\n1.2.3.1 El verbo filter\nVolvamos a los datos de los JJOO de verano. Supongamos que nos queremos quedar sólo con las medallas de Argentina. Para este tipo de filtrado de filas (o casos, o mediciones) {dplyr} tiene un verbo que se llama filter y funciona de la siguiente forma5:\n5 Se preguntarán por qué antes de la función filter aparece un ::dplyr. Esto es simplemente una forma de decirle a R que la función filter que debe utilizar es la del paquete {dplyr}. Esta es una práctica recomendable sobre todo para funciones con nombres comunes como filter o select.\n\nVer el código\nsummer |&gt; dplyr::filter(Country == \"ARG\") |&gt; head(10)\n#&gt; # A tibble: 10 × 9\n#&gt;    Year City  Sport     Discipline Athlete          Country Gender\n#&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;     &lt;chr&gt;      &lt;chr&gt;            &lt;chr&gt;   &lt;chr&gt; \n#&gt; 1  1924 Paris Athletics Athletics  BRUNETO, Luis    ARG     Men   \n#&gt; 2  1924 Paris Boxing    Boxing     PORZIO, Alfredo  ARG     Men   \n#&gt; 3  1924 Paris Boxing    Boxing     QUARTUCCI, Pedro ARG     Men   \n#&gt; 4  1924 Paris Boxing    Boxing     COPELLO, Alfredo ARG     Men   \n#&gt; 5  1924 Paris Boxing    Boxing     MENDEZ, Hector   ARG     Men   \n#&gt; 6  1924 Paris Polo      Polo       KENNY, Arturo    ARG     Men   \n#&gt; # ℹ 4 more rows\n#&gt; # ℹ 2 more variables: Event &lt;chr&gt;, Medal &lt;chr&gt;\n\n\nNoten que estamos utilizando el operador |&gt; para concatenar las acciones: Con los datos de summer hacemos el filtrado y, luego, mostramos las primeras diez filas de esos datos ya filtrados.\nTambién podríamos quere quedarnos con las medallas de Argenitna en los JJOO de Atenas 2004, para esto debemos el operador lógico “y”, cuyo símbolo en R es &:\n\n\nVer el código\nsummer |&gt; dplyr::filter(Country == \"ARG\" & Year == 2004) |&gt; head(5)\n#&gt; # A tibble: 5 × 9\n#&gt;    Year City   Sport      Discipline Athlete                   Country Gender\n#&gt;   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;                     &lt;chr&gt;   &lt;chr&gt; \n#&gt; 1  2004 Athens Aquatics   Swimming   BARDACH, Georgina         ARG     Women \n#&gt; 2  2004 Athens Basketball Basketball DELFINO, Carlos Francisco ARG     Men   \n#&gt; 3  2004 Athens Basketball Basketball FERNANDEZ, Gabriel Diego  ARG     Men   \n#&gt; 4  2004 Athens Basketball Basketball GINOBILI, Emanuel David   ARG     Men   \n#&gt; 5  2004 Athens Basketball Basketball GUTIERREZ, Leonardo Mart… ARG     Men   \n#&gt; # ℹ 2 more variables: Event &lt;chr&gt;, Medal &lt;chr&gt;\n\n\nQue linda esa Generación Dorada🏅, ¿No?.Por otro lado, si nos queremos quedar con las medallas de Argentina o Brasil debemos utilizar el operador lógico “o”, cuyo símbolo en R es |:\n\n\nVer el código\nsummer |&gt; dplyr::filter(Country == \"ARG\" | Country == \"BRA\") |&gt; head(10)\n#&gt; # A tibble: 10 × 9\n#&gt;    Year City    Sport    Discipline Athlete                   Country Gender\n#&gt;   &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;    &lt;chr&gt;      &lt;chr&gt;                     &lt;chr&gt;   &lt;chr&gt; \n#&gt; 1  1920 Antwerp Shooting Shooting   PARAENSE, Guilherme       BRA     Men   \n#&gt; 2  1920 Antwerp Shooting Shooting   BARBOSA, Dario            BRA     Men   \n#&gt; 3  1920 Antwerp Shooting Shooting   DA COSTA, Afranio Antonio BRA     Men   \n#&gt; 4  1920 Antwerp Shooting Shooting   PARAENSE, Guilherme       BRA     Men   \n#&gt; 5  1920 Antwerp Shooting Shooting   SOLEDADE, Fernando        BRA     Men   \n#&gt; 6  1920 Antwerp Shooting Shooting   WOLF, Sebastiao           BRA     Men   \n#&gt; # ℹ 4 more rows\n#&gt; # ℹ 2 more variables: Event &lt;chr&gt;, Medal &lt;chr&gt;\n\n\nAunque, una alternativa muy útil cuando tenemos los valores de una variable que queremos filtrar en un array es:\n\n\nVer el código\nsummer |&gt; dplyr::filter(Country %in% c(\"ARG\", \"BRA\")) |&gt; head(10)\n#&gt; # A tibble: 10 × 9\n#&gt;    Year City    Sport    Discipline Athlete                   Country Gender\n#&gt;   &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;    &lt;chr&gt;      &lt;chr&gt;                     &lt;chr&gt;   &lt;chr&gt; \n#&gt; 1  1920 Antwerp Shooting Shooting   PARAENSE, Guilherme       BRA     Men   \n#&gt; 2  1920 Antwerp Shooting Shooting   BARBOSA, Dario            BRA     Men   \n#&gt; 3  1920 Antwerp Shooting Shooting   DA COSTA, Afranio Antonio BRA     Men   \n#&gt; 4  1920 Antwerp Shooting Shooting   PARAENSE, Guilherme       BRA     Men   \n#&gt; 5  1920 Antwerp Shooting Shooting   SOLEDADE, Fernando        BRA     Men   \n#&gt; 6  1920 Antwerp Shooting Shooting   WOLF, Sebastiao           BRA     Men   \n#&gt; # ℹ 4 more rows\n#&gt; # ℹ 2 more variables: Event &lt;chr&gt;, Medal &lt;chr&gt;\n\n\nFinalmente, si tenemos una variable numérica, podemos filtrar con condiciones como mayor o menor:\n\n\nVer el código\nsummer |&gt; dplyr::filter(Year &gt; 2010) |&gt; head(5)\n#&gt; # A tibble: 5 × 9\n#&gt;    Year City   Sport    Discipline Athlete          Country Gender\n#&gt;   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    &lt;chr&gt;      &lt;chr&gt;            &lt;chr&gt;   &lt;chr&gt; \n#&gt; 1  2012 London Aquatics Diving     BOUDIA, David    USA     Men   \n#&gt; 2  2012 London Aquatics Diving     QIU, Bo          CHN     Men   \n#&gt; 3  2012 London Aquatics Diving     DALEY, Thomas    GBR     Men   \n#&gt; 4  2012 London Aquatics Diving     CHEN, Ruolin     CHN     Women \n#&gt; 5  2012 London Aquatics Diving     BROBEN, Brittany AUS     Women \n#&gt; # ℹ 2 more variables: Event &lt;chr&gt;, Medal &lt;chr&gt;\n\n\n\n\n1.2.3.2 El verbo select\nEl verbo select es similar a filter pero nos permite filtrar no casos sino variables. Por ejemplo, ¿Qué pasa si solo nos interesa el año, la ciudad y el nombre del atleta?:\n\n\nVer el código\nsummer |&gt; dplyr::select(c(Year, City, Athlete)) |&gt; head(5)\n#&gt; # A tibble: 5 × 3\n#&gt;    Year City   Athlete           \n#&gt;   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;             \n#&gt; 1  1896 Athens HAJOS, Alfred     \n#&gt; 2  1896 Athens HERSCHMANN, Otto  \n#&gt; 3  1896 Athens DRIVAS, Dimitrios \n#&gt; 4  1896 Athens MALOKINIS, Ioannis\n#&gt; 5  1896 Athens CHASAPIS, Spiridon\n\n\n\n\n1.2.3.3 El verbo mutate\nAhora las cosas se complican un poco. mutate es un verbo que nos permite crear nuevas columnas ya sea con datos nuevos o en función de los datos existentes. Por ejemplo, creemos una columna nueva que tenga un chr con el país, un guión y el nombre del atleta y llamémosla nationality_athlete. Nos vamos a quedar sólo con el año, la medalla que ganó y el nuevo nombre combinado con la nacionalidad:\n\n\nVer el código\nsummer |&gt; \n  dplyr::mutate(nationality_athlete = paste(Country, \"-\", Athlete)) |&gt; \n  dplyr::select(c(Year, Medal, nationality_athlete)) |&gt;\n  head(5)\n#&gt; # A tibble: 5 × 3\n#&gt;    Year Medal  nationality_athlete     \n#&gt;   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;                   \n#&gt; 1  1896 Gold   HUN - HAJOS, Alfred     \n#&gt; 2  1896 Silver AUT - HERSCHMANN, Otto  \n#&gt; 3  1896 Bronze GRE - DRIVAS, Dimitrios \n#&gt; 4  1896 Gold   GRE - MALOKINIS, Ioannis\n#&gt; 5  1896 Silver GRE - CHASAPIS, Spiridon\n\n\nO, por ejemplo, podemos querer crear una variable que nos ponga un \\(1\\) si es griego y un \\(0\\) si no6:\n6 Para más detalles sobre la función if_else pueden ver el siguiente link.\n\nVer el código\nsummer |&gt; \n  dplyr::mutate(is_greek = if_else(Country == \"GRE\", 1, 0)) |&gt; \n  dplyr::select(c(Year, Medal, Country, is_greek)) |&gt;\n  head(5)\n#&gt; # A tibble: 5 × 4\n#&gt;    Year Medal  Country is_greek\n#&gt;   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;      &lt;dbl&gt;\n#&gt; 1  1896 Gold   HUN            0\n#&gt; 2  1896 Silver AUT            0\n#&gt; 3  1896 Bronze GRE            1\n#&gt; 4  1896 Gold   GRE            1\n#&gt; 5  1896 Silver GRE            1\n\n\nAhora vamos a aprender algo muy importante y cool 🆒: A agrupar los casos de acuerdo a una variable. Por ejemplo, si queremos agregar una columna que contenga la cantidad total de medallas ganadas por un país a cada atleta de ese país podemos hacer lo siguiente:\n\n\nVer el código\nsummer |&gt; \n  group_by(Country) |&gt;\n  dplyr::mutate(num_medals = n()) |&gt; \n  dplyr::select(c(Year, Medal, Athlete, num_medals)) |&gt;\n  head(5)\n#&gt; # A tibble: 5 × 5\n#&gt; # Groups:   Country [3]\n#&gt;   Country  Year Medal  Athlete            num_medals\n#&gt;   &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;                   &lt;int&gt;\n#&gt; 1 HUN      1896 Gold   HAJOS, Alfred            1079\n#&gt; 2 AUT      1896 Silver HERSCHMANN, Otto          146\n#&gt; 3 GRE      1896 Bronze DRIVAS, Dimitrios         148\n#&gt; 4 GRE      1896 Gold   MALOKINIS, Ioannis        148\n#&gt; 5 GRE      1896 Silver CHASAPIS, Spiridon        148\n\n\n¿Perdidos? Tomensé su tiepo para tratar de entender qué pasó y prueben distintas alternativas en sus computadoras.\n\n\n1.2.3.4 El verbo summarise\nPor último, el verbo summarise nos permite sacar medidas resumen de nuestros datos. Empecemos con algo obvio: ¿Cuántas medallas de oro ganó cada país en la historia de los juegos olímpicos?. Podemos hacer algo parecido a lo último que hicimos con mutate pero el resultados será ligeramente diferente7:\n7 La función arrange nos ordena los datos de acuerdo a la variable que le enviemos como parámetro de menos a mayor. Si queremos que ordene de mayor a menor debemos agregar la función desc en el argumento. Más detalles acá.\n\nVer el código\nsummer |&gt; \n  dplyr::filter(Medal == \"Gold\") |&gt;\n  group_by(Country) |&gt;\n  dplyr::summarise(num_medals = n()) |&gt;\n  arrange(desc(num_medals)) |&gt;\n  head(10)\n#&gt; # A tibble: 10 × 2\n#&gt;   Country num_medals\n#&gt;   &lt;chr&gt;        &lt;int&gt;\n#&gt; 1 USA           2235\n#&gt; 2 URS            838\n#&gt; 3 GBR            546\n#&gt; 4 ITA            476\n#&gt; 5 GER            452\n#&gt; 6 HUN            412\n#&gt; # ℹ 4 more rows\n\n\nHay algo raro, ¿No? Bueno, sí, de esta forma estamos contando a todos los atletas que tuvieron la misma medalla (por ejemplo, si la medalla fue por fútbol estamos contando cerca de 30 medallas). Para resolver esto nos podemos sacar de encima los casos duplicados por año, deporte, disciplina, evento y género8:\n8 La función distinct nos conserva una sola realización de cada caso que es igual de acuerdo a las variables que le pasemos como parámetros. Más detalles acá.\n\nVer el código\nsummer |&gt; \n  distinct(Year, Sport, Discipline, Event, Gender, .keep_all = TRUE) |&gt;\n  dplyr::filter(Medal == \"Gold\") |&gt;\n  group_by(Country) |&gt;\n  dplyr::summarise(num_medals = n()) |&gt;\n  arrange(desc(num_medals)) |&gt;\n  head(5)\n#&gt; # A tibble: 5 × 2\n#&gt;   Country num_medals\n#&gt;   &lt;chr&gt;        &lt;int&gt;\n#&gt; 1 USA             67\n#&gt; 2 GBR             46\n#&gt; 3 CHN             40\n#&gt; 4 RUS             22\n#&gt; 5 GER             19\n\n\nVayamos con lo último, calculemos la media y la desviación estándar de las medallas de Argentina por JJOO combinando todo lo que vimos.\n\n\nVer el código\nsummer |&gt; \n  distinct(Year, Sport, Discipline, Event, Medal, Gender, .keep_all = TRUE) |&gt;\n  dplyr::filter(Country == \"ARG\") |&gt;\n  group_by(Country, Year) |&gt;\n  dplyr::summarise(num_medals = n()) |&gt;\n  ungroup() |&gt;\n  summarise(media  = mean(num_medals),\n            desvio = sd(num_medals))\n#&gt; # A tibble: 1 × 2\n#&gt;   media desvio\n#&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1  3.83   2.28\n\n\nDigieran esto tranquilos.\n\n\n\n1.2.4 {tidyR}, el paquete para ordenar tus datos\nEl paquete {tidyR} tiene muchas herramientas de manejo de tablas como reformatear, expandir tablas, manejar valores faltantes, dividir celdas, anidar datos, etc9. Sin embargo, en esta breve introducción sólo vamos a presentar muy brevemente las herramientas que nos permiten convertir una tabla wide en tidy (o long) y viceverse.\n9 Para más información ver el cheatsheet.\n1.2.4.1 La función pivot_longer\nVolvamos a la tabla iniicial que teníamos en formato wide:\n\n\nVer el código\ntabla_wide &lt;- tibble(sujeto  = rep(c(\"Jerry\", \"Elaine\", \"George\")),\n                     trial_1 = runif(3),\n                     trial_2 = runif(3)) \n\ntabla_wide\n#&gt; # A tibble: 3 × 3\n#&gt;   sujeto trial_1 trial_2\n#&gt;   &lt;chr&gt;    &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 Jerry    0.320  0.404 \n#&gt; 2 Elaine   0.402  0.0637\n#&gt; 3 George   0.196  0.389\n\n\nSi nosotros quisiñeramos transformar esta tabla en una tabla en formato tidy podemos utilizar la función pivot_longer10. Veamos como funciona y después la desmenuzamos:\n10 Más información acá.\n\nVer el código\npivot_longer(data = tabla_wide, \n             cols = trial_1:trial_2, \n             names_to = \"trial\",\n             values_to = \"tiempo_respuesta\")\n#&gt; # A tibble: 6 × 3\n#&gt;   sujeto trial   tiempo_respuesta\n#&gt;   &lt;chr&gt;  &lt;chr&gt;              &lt;dbl&gt;\n#&gt; 1 Jerry  trial_1           0.320 \n#&gt; 2 Jerry  trial_2           0.404 \n#&gt; 3 Elaine trial_1           0.402 \n#&gt; 4 Elaine trial_2           0.0637\n#&gt; 5 George trial_1           0.196 \n#&gt; 6 George trial_2           0.389\n\n\nLos argumentos son los siguientes: data es la tabla a la que le vamos a realizar el cambio de formato; cols son las columnas que vamos a cambiar, en este caso desde trial_1 a trial_2; en names_to indicamos la variable a la que vamos a mandar los nombres de las columnas actuales; y values_to la variables a la que vamos a mandar los valores.\nAlgo ligeramente raro es que la columna trial no es numérica y, sólo por completitud, lo vamos a solucionar usando a nuestro gran amigo |&gt; y al verbo mutate11:\n11 Y la función parse_number del paquete {readr}.\n\nVer el código\npivot_longer(data = tabla_wide, \n             cols = trial_1:trial_2, \n             names_to = \"trial\",\n             values_to = \"tiempo_respuesta\") |&gt;\n  mutate(trial = parse_number(trial))\n#&gt; # A tibble: 6 × 3\n#&gt;   sujeto trial tiempo_respuesta\n#&gt;   &lt;chr&gt;  &lt;dbl&gt;            &lt;dbl&gt;\n#&gt; 1 Jerry      1           0.320 \n#&gt; 2 Jerry      2           0.404 \n#&gt; 3 Elaine     1           0.402 \n#&gt; 4 Elaine     2           0.0637\n#&gt; 5 George     1           0.196 \n#&gt; 6 George     2           0.389\n\n\n\n\n1.2.4.2 La función pivot_wider\nAhora vamos con el caso contrario en el que tenemos una tabla en formato long y la queremos convertir en wide:\n\n\nVer el código\ntabla_long &lt;- pivot_longer(data = tabla_wide, \n                           cols = trial_1:trial_2, \n                           names_to = \"trial\",\n                           values_to = \"tiempo_respuesta\") |&gt;\n  mutate(trial = parse_number(trial))\n\ntabla_long\n#&gt; # A tibble: 6 × 3\n#&gt;   sujeto trial tiempo_respuesta\n#&gt;   &lt;chr&gt;  &lt;dbl&gt;            &lt;dbl&gt;\n#&gt; 1 Jerry      1           0.320 \n#&gt; 2 Jerry      2           0.404 \n#&gt; 3 Elaine     1           0.402 \n#&gt; 4 Elaine     2           0.0637\n#&gt; 5 George     1           0.196 \n#&gt; 6 George     2           0.389\n\n\nPara esto vamos a hechar mano a la función pivot_wider12 que tiene una sintáxis parecida a su prima pivot_longer:\n12 Más información acá.\n\nVer el código\npivot_wider(data = tabla_long, \n            names_from = trial, \n            values_from = tiempo_respuesta)\n#&gt; # A tibble: 3 × 3\n#&gt;   sujeto   `1`    `2`\n#&gt;   &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1 Jerry  0.320 0.404 \n#&gt; 2 Elaine 0.402 0.0637\n#&gt; 3 George 0.196 0.389\n\n\nEt Voilà!, ya tenemos nuestra tabla en formato wide. En este caso le dijimos de que variable tomar los nombres de las nuevas columnas en names_from y de que variable tomar los valores en values_from.\nFinalmente, y sólo para alimnetar nuestra obsesión, vamos a corregir los nombres de las columnas agregando el prefijo trial_ utilizando el parámetro de la función names_prefix:\n\n\nVer el código\npivot_wider(data = tabla_long, \n            names_from = trial, \n            names_prefix = \"trial_\",\n            values_from = tiempo_respuesta)\n#&gt; # A tibble: 3 × 3\n#&gt;   sujeto trial_1 trial_2\n#&gt;   &lt;chr&gt;    &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 Jerry    0.320  0.404 \n#&gt; 2 Elaine   0.402  0.0637\n#&gt; 3 George   0.196  0.389",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>R y el tidyverse</span>"
    ]
  },
  {
    "objectID": "intro_R.html#algunas-palabras-finales",
    "href": "intro_R.html#algunas-palabras-finales",
    "title": "1  R y el tidyverse",
    "section": "1.3 Algunas palabras finales",
    "text": "1.3 Algunas palabras finales\nComo vimos brevemente en este capítulo, los paquetes del tidyverse son una herramineta importantísima para el análisis de datos utilizando R. Para más detalles sobre estas funcionalidades les recomendamos la guía de Hadley Wickham(Wickham et al. 2019) o, si ya se quieren sumergir de lleno en el mundo del análisis de datos con R, este fantástico libro (Wickham, Çetinkaya-Rundel, y Grolemund 2023)13. Es decir, sin tener que cargar ningún paquete de funciones adicional..\n\n\n\nWickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy D’Agostino McGowan, Romain François, Garrett Grolemund, et al. 2019. «Welcome to the Tidyverse». Journal of open source software 4 (43): 1686.\n\nWickham, Hadley, Mine Çetinkaya-Rundel, y Garrett Grolemund. 2023. R for data science. \" O’Reilly Media, Inc.\".\n13 Disponible gratis online en acá.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>R y el tidyverse</span>"
    ]
  },
  {
    "objectID": "potential_outcomes.html#presentación",
    "href": "potential_outcomes.html#presentación",
    "title": "3  Potential outcomes",
    "section": "3.1 Presentación",
    "text": "3.1 Presentación\nSupongamos que quiero evaluar la efectividad de la aspirina para mitigar el dolor de cabeza. Me duele la cabeza y lo quiero es saber el efecto diferencial entre tomar y no tomar esa aspirina. Es decir, en el tiempo 0 estoy yo con dolor de cabeza y en el tiempo 1 debería haber dos versiones mías (como si una no fuera suficiente), la que tomó la aspirina y la que no. A cada una de ellas les tendría que preguntar cuánto les duele la cabeza, el outcome de mi comparación. No hace falta ser demasiado astuto para darse cuenta que esto es imposible ya que sólo nos será posible obsevar una de esas versiones mientras que la otra será un contrafáctico.\nDe esto vamos a hablar en este capítulo, utilizando la tradición de los potential outcomes. Estas ideas terminan de tomar forma en la versión que conocemos en las ciencias sociales en (Rubin 1974)"
  },
  {
    "objectID": "intro_stat.html#inferencia-estadística",
    "href": "intro_stat.html#inferencia-estadística",
    "title": "2  Repaso de probabilidad y estadística",
    "section": "2.10 Inferencia estadística",
    "text": "2.10 Inferencia estadística\nVamos a hacer un breve paseo por los conceptos clave de la inferencia estadística de la mano de un ejemplo.\n\n\n\n\n\n\nEl ejemplo de inferencia\n\n\n\nSupongamos que tenemos una página web de noticias y queremos probar una nueva feature con la que queremos aumentar el tiempo de retención de los usuarios. Para esto le vamos a presentar a los usuarios la versión nueva de la página y vamos a medir el tiempo que se mantienen en la página en ms6.\n\n\n6 Probabilemente lo más correcto para responder esta pregunta sea un A/B test, pero ya hablaremos de eso más adelante.7 Además, como vamos a ver más adelante, cuando el \\(n\\) es lo suficientemente grande, esta condición deja de importar tanto.Primero definamos nuestra variable aleatoria: \\(X\\):“La diferencia de tiempo en ms entre después y antes del cambio”. Nuestro objetivo entonces es poder afirmar con cierto grado de seguridad si \\(E(X)\\) es igual a cero o distinto (nos importa tanto si aumenta como si disminuye). Empecemos con lo más sencillo, supongamos que \\(X \\sim \\mathcal{N}(\\mu, \\sigma^2)\\). Esta suposición no es tan loca ya que mucho procesos naturales se distribuyen de forma normal7. Supongamos también por un momento (más adelante vamos a relajar esta condición) que, ya sea por un experimento previo o porque somos magos, conocemos la \\(\\sigma^2\\) de \\(X\\).\nComo dijimos en el recuedro, si bien nuestro objetivo es probar si \\(\\mu\\) es diferente de \\(0\\), esto lo vamos a hacer a partir de un experimento. Una vez que hagamos el experimento y midamos vamos a tener al clásico estimador de \\(\\mu\\): \\(\\hat{\\mu}=\\bar{X}\\), es decir, el promedio muestral. Ahora supongamos que el promedio nos da \\(0.5\\): ¿Es distinto de cero? Para responder esa pregunta es que vamos a utilizar las herramientas de la inferencia estadística.\nDefinamos primero las hipótesis:\n\\[\n\\begin{array}\n_H_0 &:& \\mu = 0 \\\\\nH_1 &:& \\mu \\neq 0\n\\end{array}\n\\tag{2.19}\\]\nLo que vamos a querer hacer es rechazar \\(H_0\\) con cierto grado de confianza. Para esto vamos a comparar nuestra medición \\(\\bar{x}_{obs}\\) con la distribución de los \\(\\bar{X}\\) bajo \\(H_0\\).\nRecordemos que si \\(X \\sim \\mathcal{N}(\\mu, \\sigma^2)\\) entonces \\(\\bar{X}_n \\sim \\mathcal{N}(\\mu, \\sigma^2/n)\\)8, donde \\(n\\) es la cantidad de realizaciones con las que yo calculo mi \\(\\bar{X}\\). Entonces si mi \\(\\bar{x}_{obs}\\) medida está lo suficientemente lejos de \\(0\\) podemos decir que que \\(\\mu\\) es diferente de cero. Pero: ¿Qué es suficientemente lejos?\n8 La \\(n\\) en \\(\\bar{X}_n\\) es simplemente para enfatizar que es el promedio de una seciencia de \\(n\\) realizaciones.Bueno, para responder esa pregunta vamos a tener que primero definir los errores que podemos cometer. Podemos cometer el error de decir que \\(\\mu\\) es diferente de cero cuando no lo es (Error tipo I o dalso positivo) o podemos cometer el error de decir que \\(\\mu\\) no es diferente de cero cuando sí lo es (Error tipo II o dalso negativo). Nuestro razonamiento va a ser empezar acotando el error de tipo I.\nPara esto vamos a calcular qué tal probable es observar un valor igual o más alejado del cero que \\(\\bar{x}_{obs}\\) dado que \\(H_0\\) es verdadera. Es decir, \\(P(|\\bar{X}|&gt;\\bar{x}_{obs}|H_0)\\). Esta magnitud es lo que se conoce como el viejo y querido p-valor o p-value (si te gusta hacerte el canchero). En nuestro caso lo podemos calcular explícitamente. Empecemos estandarizando \\(\\bar{X}\\) de la siguiente forma:\n\\[\nZ = \\frac{\\bar{X} - \\mu}{\\sqrt{\\sigma^2/n}} \\sim \\mathcal{N}(0,1)\n\\tag{2.20}\\]\nQque bajo \\(H_0\\) es:\n\\[\nZ_{H_0} = \\frac{\\bar{X}}{\\sqrt{\\sigma^2/n}} \\sim \\mathcal{N}(0,1)\n\\tag{2.21}\\]\nEntonces, si consideramos a \\(z_{\\bar{x}}\\) como la versión estandarizada de \\(\\bar{x}_{obs}\\), podemos calcular el p-valor como:\n\\[\n\\begin{array}\n_p_{valor} &=& P(|Z| \\geq |z_{\\bar{x}}| \\: \\: |H_0) \\\\\n&=& P(Z \\geq |z_{\\bar{x}}| \\: \\: |H_0) + P(Z \\leq -|z_{\\bar{x}}| \\: \\: |H_0) \\\\\n&=& 2 P(Z \\leq -|z_{\\bar{x}}| \\: \\: |H_0)\n\\end{array}\n\\tag{2.22}\\]\nY como bajo \\(H_0\\) ocurre que \\(Z_{H_0} \\sim \\mathcal{N}(0,1)\\):\n\\[\np_{valor} = 2 \\phi(-|z_{\\bar{x}}|)\n\\tag{2.23}\\]\nY ahora que tenemos esta probabilidad qué hacemos. Bueno, lo que podemos hacer es decir: Si los datos vienen de \\(H_0\\) podemos calcular que tan “raros” son, entonces pongamos una cota en esa probabilidad y de esa forma estaremos acotando el error de tipo I en el largo plazo9. Así es que surge el famoso \\(\\alpha\\) que normalmente hacemos valer \\(0.05\\)10. ¿Qué significa eso? Bueno, significa que, si la hipótesis nula fuera verdaera diríamos euivocadamente que hay un efecto cuando no lo hay el \\(5%\\) de las veces. Este párrafo se podría extender al infinito, pero por ahora quedémonos con esta interpretación “práctica” del p-valor (si se quedan con las ganas pueden ir a leer esto).\n9 El enfoque frecuentista de la estadística justamente se basa en controlar los errores dada una repetición infinita de mi experimento.10 Para una discusión más profunda sobre el tema de la selección de \\(\\alpha\\) en la psicología experimental les recomiendo este hermoso artículo de Maier y Lakens (Maier y Lakens 2022).\nMaier, Maximilian, y Daniël Lakens. 2022. «Justify your alpha: A primer on two practical approaches». Advances in Methods and Practices in Psychological Science 5 (2): 25152459221080396.\nEntonces el camino es el siguiente: Tomamos las medidas, calculamos el promedio, calculamos el p-valor y si este es menor que \\(\\alpha\\) podemos decir que \\(H_0\\) es falsa. Todo muy lindo, pero siempre tengamos en mente que no sabemos exactamente si para esa realización estamos comentiendo un error de tipo I o no, y ese es uno de las limitaciones de la estadística frecuentista.\nSimulemos un experimento para \\(n=50\\) en el que nosotros conocemos tanto \\(\\sigma^2\\) como \\(\\mu\\):\n\n\nVer el código\nset.seed(123)\nn &lt;- 50\nmu &lt;- .5\nsigma &lt;- 2\n\nX &lt;- rnorm(n, mu, sigma)\n\ncat(paste(\"El promedio muestral es:\", round(mean(X), 3)))\n#&gt; El promedio muestral es: 0.569\ncat(paste(\"El promedio muestral estandarizado es:\", round(mean(X)/sqrt(sigma^2/n), 3)))\n#&gt; El promedio muestral estandarizado es: 2.011\n\n\nAcá vemos que, efectivamente, \\(H_0\\) es falsa ya que \\(\\mu=0.5\\) (el verdadero parámetro poblacional). La media observada vale 0.569 y la media estandarizada (\\(z_{\\bar{x}}\\)) vale 2.011. Miremos ccomo queda \\(z_{\\bar{x}}\\) dentro de la distribución de los \\(Z_{H_0}\\) (los \\(\\bar{X}\\) bajo \\(H_0\\) estandarizados):\n\n#&gt; Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n#&gt; ℹ Please use `linewidth` instead.\n\n\n\n\nFunción de densidad de probabilidad de la variabla aleatoria H (altura de los varones)\n\n\n\n\nLa curva azul es la función de densidad de \\(Z_{H_0}\\), las líneas verticales naranjas delimitan los valores de \\(Z\\) cuales la probabilidad de encontrar valores más extremos es mayor a \\(0.05\\), es decir, a la derecha de la línea naranja positiva y a la izquierda de la negativa estamos en la región en la que vamos a considerar a \\(z_{\\bar{x}}\\) como evidencia significativa de que \\(H_0\\) es falsa. La suma de las integrales de la curva azul a la derecha de la línea naranja posiva y a la izquierda de la negativa da como resultado \\(\\alpha\\).\nEl punto verde (y la línea punteada que lo acompaña) es nuestra observación \\(z_{\\bar{x}}\\). O sea, todo parece indicar que controlando nuestro error de tipo I con \\(\\alpha=0.05\\) el valor observado nos permitiría que podemos rechazar \\(H_0\\) o, como se dice habitualmente: “Que \\(\\mu\\) es significativamente diferente de cero”. Calculemos el p-valor y veamos si esto es efectivamente así.\n\\[\np_{valor} = 2 \\phi(-|z_{\\bar{x}}|) = 2 \\phi(-2.011)\n\\tag{2.24}\\]\nQue en R lo podemos calcular como:\n\n\nVer el código\ncat(paste(\"El p-valor es:\", round(2*pnorm(-mean(X)/sqrt(sigma^2/n)),3)))\n#&gt; El p-valor es: 0.044\n\n\nQue como es menor que \\(0.05\\) nos permite rechazar \\(H_0\\).\nPara resolver este ejemplo hicimos dos consideraciones que les pueden hacer ruido: 1. Asumimos que conocíamos la desviación estándar de X. 2. Asumimos que X tiene distribución normal.\n\n2.10.1 ¿Qué pasa si no conozco \\(\\sigma\\)?\nCon respecto a 1, es natural que les haga ruido ya que en la mayoría de los casos no conocemos al \\(\\sigma\\) poblacional sino que lo vamos a estimar. Y ¿Cómo lo vamos a estimar? Echando mano del estimador insesgado de la desviación estándar \\(S\\). El mismo se define como:\n\\[\nS^2 = \\frac{\\sum_{i=1}^n(x_i-\\bar{x})^2}{n-1}\n\\tag{2.25}\\]\nPara nuestro ejemplo vale:\n\n\nVer el código\ncat(paste(\"la estimación de sigma es:\", round(sd(X), 3)))\n#&gt; la estimación de sigma es: 1.852\n\n\nBastante cercana al valor poblacional \\(2\\).\nAhora, no es cuestión de normalizar con este nuevo \\(S^2\\) y seguir como si nada. La cosa cambia y la distribución de \\(\\bar(X)\\) estandarizado bajo \\(H_0\\) ya no tiene una distribución normal sino una distribución t de student con \\(n-1\\) grados de libertad. O sea:\n\\[\n\\frac{\\bar{X} - \\mu}{\\sqrt{S^2/n}} \\sim t_{n-1}\n\\tag{2.26}\\]\nEsto se deduce a partir de que: \\[\n\\frac{\\bar{X} - \\mu}{\\sqrt{\\sigma^2/n}} \\sim \\mathcal{N}(0,1)\n\\] Y:\n\\[\n(n-1)\\frac{S^2}{\\sigma^2} \\sim \\chi^2_{n-1}\n\\tag{2.27}\\]\nY la definición de \\(t_{n-1}\\) es11:\n11 Dentro de la función pt ahora se agrega el parámetro df que representa los grados de libertad.\\[\n\\begin{array}\n_U &\\sim& \\mathcal{N}(0,1) \\\\\nV &\\sim& \\chi^2_{n} \\\\\n\\frac{U}{\\sqrt{V/n}} &\\sim& t_{n}\n\\end{array}\n\\tag{2.28}\\]\nCalculemos el p-valor de nuestro ejemplo, pero ahora como si no conociéramos la \\(\\sigma\\) poblacional12:\n12 Dentro de la función pt ahora se agrega el parámetro df que representa los grados de libertad.\n\nVer el código\ncat(paste(\"El p-valor es:\", round(2*pt(-mean(X)/sqrt(sd(X)^2/n), df = n-1),4)))\n#&gt; El p-valor es: 0.0347\n\n\nUna buena noticia es que este p valor se puede calcular directamente con la función t.test(X) de la siguiente forma:\n\n\nVer el código\nt.test(X)\n#&gt; \n#&gt;  One Sample t-test\n#&gt; \n#&gt; data:  X\n#&gt; t = 2.1721, df = 49, p-value = 0.03472\n#&gt; alternative hypothesis: true mean is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  0.04254842 1.09506577\n#&gt; sample estimates:\n#&gt; mean of x \n#&gt; 0.5688071\n\n\nPara cerrar, vale la pena mencionar que los parámetros \\(\\beta\\) de un modelo lineal también tienen distribución t (los grados de libertad son más complejos). O sea que todo lo que vimos hasta acá de errores tipo I, tipo II, p-valor, etc. vale también para ellos.\n\n\n2.10.2 ¿Qué pasa si \\(X\\) no se distribuye normalmente?\nAhora que ya vimos que estamos haciendo cuando hacemos inferencia sobre la media, nos damos cuenta que más que interesarnos la distribución de los datos \\(X\\) nos interesa la de sus medias \\(\\bar(X)\\) (si estiman algún parámetro de interés, claro). Y acá viene al rescate el teorema central del límite:\n\\[\n\\frac{\\bar{X}-\\mu}{\\sqrt{\\sigma^2/n}}  \\xrightarrow{\\mathcal{D}} \\mathcal{N}(0,1)\n\\tag{2.29}\\]\nEl mismo nos dice que distribución de la media estandarizada converge endistribución a una \\(\\mathcal{N}(0,1)\\) sin importar la distribución de \\(X\\). Esto significa que si el \\(n\\) es lo suficientemente grande podemos estar tranquilos de que no es una asunción tan loca13.\n13 Cuando las cosas no se pueden aproximar así hay solución, existen otros tests o simplemente tests que no asumen ninguna distribución (no paramétricos).Supongamos que hay una variable aleatoria \\(V \\sim \\mathcal{E}(\\lambda=1)\\) tal que \\(E(V) = \\lambda\\). Si tomamos una muestra de \\(n=100\\) de \\(V\\), el histograma de la misma se ve algo así:\n\n\n\n\n\nHistograma de una muestra de 100 datos de una exponencial con lambda=1\n\n\n\n\nDonde en azul vemos el histograma y en negro la función de densidad para \\(\\mathcal{E}(\\lambda=1)\\). Ahora, qué pasa si tomamos \\(1000\\) muestras y hacemos el histograma de sus medias:\n\n\nVer el código\nn = 1000\nZs &lt;- c()\nset.seed(123)\nfor (i in 1:10000) {\n  x &lt;- rexp(n, rate = 1)\n  Zs &lt;- c(Zs, (mean(x) - 1)/sqrt(sd(x)^2/n))\n}\n\nZ_means &lt;- tibble(Zs)\nZ_means %&gt;% ggplot() +\n  geom_histogram(aes(x = Zs, y = ..density..), fill = \"steelblue\") +\n  stat_function(fun = dnorm, args = list(mean = 0, sd = 1), \n                color = \"black\", linewidth = 1) +\n  labs(title = paste(\"n = \", n), x = \"Medias de v\", y = \"Densidad\") +\n  scale_x_continuous(limits = c(-4, 4))\n#&gt; Warning: Removed 2 rows containing non-finite outside the scale range\n#&gt; (`stat_bin()`).\n#&gt; Warning: Removed 2 rows containing missing values or values outside the scale range\n#&gt; (`geom_bar()`).\n\n\n\n\n\nHistograma de 1000 medias de muestras de 100 datos de una exponencial con lambda=1\n\n\n\n\nDonde ahora la curva negra es una \\(\\mathcal{N}(0,1)\\). Hagan la prueba con otras distribuciones u otros \\(n\\) y van a ver que rápido (o lento para las distribuciones altamente asimétricas) que convergen a una \\(\\mathcal{N}(0,1)\\).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Repaso de probabilidad y estadística</span>"
    ]
  },
  {
    "objectID": "intro_stat.html#el-p-valor",
    "href": "intro_stat.html#el-p-valor",
    "title": "2  Repaso de probabilidad y estadística",
    "section": "2.11 El p-valor",
    "text": "2.11 El p-valor\nEn construcción 🚧"
  },
  {
    "objectID": "intro_stat.html#potencia-estadística",
    "href": "intro_stat.html#potencia-estadística",
    "title": "2  Repaso de probabilidad y estadística",
    "section": "2.11 Potencia estadística",
    "text": "2.11 Potencia estadística\nYa hablamos de los errores de tipo I y prometimos hablar de los errores de tipo II. ¿Qué sería eso? Bueno, sería el caso en el que \\(H_0\\) fuera falsa y nosotros no la rechazáramos. A diferencia del contros de errores de tipo I, la probabilidad de cometer errores de tipo II (llamada muy originalmente \\(\\beta\\)) depende del valor real de mi parámetro. En el ejemplo anterior, cuando \\(H_0\\) era verdadera \\(\\mu\\) era igual a cero pero, ¿Qué pasa cuando es falsa? ¿Qué valor de \\(\\mu\\) tenemos que asumir?.\nEmpecemos definiendo a la potencia estadística, la misma se define como \\(1-\\beta\\), es decir, cuanto más acotado este el error de tipo II más alta será la potencia. Una definición formal podría ser:\n\\[\npotencia = P(rechazar \\, H_0 | H_0 \\, falsa)\n\\tag{2.30}\\]\nQue, para el ejemplo anterior la podríamos reescribir como:\n\\[\n\\begin{array}\n_potencia &=& P(rechazar \\, H_0 | H_1) \\\\\n&=& P\\left( \\left| \\frac{\\bar{X}}{\\sqrt{\\sigma^2/n}} \\right| \\geq Z_{1-\\alpha/2}  \\right)\\\\\n&=& 1 - P\\left( Z \\leq Z_{\\alpha/2} + \\frac{\\mu}{\\sqrt{\\sigma^2/n}} \\right) - P\\left( Z \\leq Z_{1-\\alpha/2} + \\frac{\\mu}{\\sqrt{\\sigma^2/n}} \\right) \\\\\n\\end{array}\n\\]\nFijensé que para calcularla no sólo necesitamos a \\(\\sigma\\) (que podríamos estimar) sino también a \\(mu\\), que es nuestro parámetro de interés. Por ejemplo, podemos ver que la pontencia depende de \\(\\mu\\), siendo más grande para valores de \\(\\mu\\) más alejados del cero. Esto tiene sentido ya que a medida que \\(|\\mu|\\) es mayor, es menor probable cometer errores tipo II.\n\n\nVer el código\npotencia &lt;- function(sigma, mu, n, alpha) {\n  pnorm(qnorm(alpha/2)-mu/(sqrt(sigma^2/n))) + 1 -\n    pnorm(qnorm(1-alpha/2)-mu/(sqrt(sigma^2/n)))\n}\n\npot &lt;- potencia(3,seq(-3,3,.1),20,0.05)\npot_tbl &lt;- tibble(mu = seq(-3,3,.1), potencia = pot)\npot_tbl %&gt;% ggplot(aes(x = mu,\n           y = potencia)) +\n  geom_line(linewidth = 1) +\n  theme_bw()\n\n\n\n\n\nPotencia estadística en función de mu.\n\n\n\n\nComo es de esperarse, la potencia también depende del \\(\\alpha\\):\n\n\nVer el código\npot &lt;- potencia(3,1,20,seq(0, 0.05, 0.001))\npot_tbl &lt;- tibble(alpha = seq(0, 0.05, 0.001), potencia = pot)\npot_tbl %&gt;% ggplot(aes(x = alpha,\n                       y = potencia)) +\n  geom_line(linewidth = 1) +\n  labs(title = \"Potencia en función de alfa\") +\n  theme_bw()\n\n\n\n\n\nPotencia estadística en función de alfa.\n\n\n\n\nCon valores de potencia mayores para valores más garndes de \\(\\alpha\\). Nuevamente esto tiene sentido ya que ser más restictivo con el rechazo de \\(H_0\\) (o sea, que tenga que observar un valor más extremo) lleva a una disminución de \\(\\alpha\\), a un aumento de los errores tipo II y con ello a una disminución de la potencia.\nFinalmente, la potencia también depende del \\(n\\):\n\n\nVer el código\npot &lt;- potencia(3,1,seq(5, 200),0.05)\npot_tbl &lt;- tibble(n = seq(5, 200), potencia = pot)\npot_tbl %&gt;% ggplot(aes(x = n,\n                       y = potencia)) +\n  geom_line(linewidth = 1) +\n  labs(title = \"Potencia en función de n\") +\n  theme_bw()\n\n\n\n\n\nPotencia estadística en función de n.\n\n\n\n\nCon valores de potencia más altos para \\(n\\) más grande. Es decir, si tengo una muestra más grande voy a cometer menos errores14. Esta última dependencia es muy importante.\n14 Las distribuciones de \\(H_0\\) y \\(H_1\\) se hacen más finas y hay menos solapamiento, recuerden que en ambas la varianza disminuye con \\(1/n\\).Hay una interpretación que me gusta que es la siguiente, la potencia estadística es la lupa con la que miramos el problema. Es decir, si tenemos una potencia alta vamos a poder detectar cambios pequeños sin cometer demasiados errores. Supongamos que queremos diseñar un experimento con una dada potencia. El \\(\\alpha\\) lo decidimos cuando acotamos el error de tipo I, a \\(\\mu\\) no lo conocemos (algo vamos a hacer), entonces, lo que más a mano nos queda para tener un experimento más potente es aumentar el \\(n\\).\nEl uso que se le da normalmente a esta herramienta es para determinar el mínimo tamaño de muestra necesario para un experimento. El procedimiento es el siguiente:\n\nEstimamos la variabilidad de nuestro experimento de alguna forma. Lo más usual es hacer un piloto pero también puede ser un dato que salga de la bibliografía, o de experimentos anteriores que hayamos realizado.\nDeterminamos el mínimo tamaño de efecto de interés (SESOI15). Esta no es una determinación estadística sino que de dominio, tenemos que conocer el problema y pensar en cuál sería el mínimo tamaña de efecto que consideraría relevante (relevante, no significativo). Esto a veces puede ser un poco confuso pero también nos obliga a pensar qué consideramos relevante en nuestro experimento.\nUna vez que tenemos estas dos magnitudes calculamos el tamaño de muestra para una potencia dada (por ejemplo \\(0.9\\)) y un \\(\\alpha\\) dado (por ejemplo \\(0.05\\)).\n\n15 Del inglés smallest effect size of interest.No siempre resulta tan directo como en nuestro ejemplo, en el que podemos despejar explícitamente \\(n\\), pero la forma de pensar el problema es siempre similar.\nPara más detalles sobre los procedimientos para justificar el temaño de muestra ver (Lakens 2022).\n\n\n\nLakens, Daniel. 2022. «Sample size justification». Collabra: psychology 8 (1): 33267.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Repaso de probabilidad y estadística</span>"
    ]
  },
  {
    "objectID": "potential_outcomes.html#potential-outcomes",
    "href": "potential_outcomes.html#potential-outcomes",
    "title": "3  Potential outcomes",
    "section": "3.2 Potential outcomes",
    "text": "3.2 Potential outcomes\nLo que nos proponen los potential outcomes es la definición del efecto causal como la comparación de dos estados en el mundo. En una versión del mundo, la “actual”, me tomo una aspirina y a las dos horas registro la severidad de mi dolor de cabeza mientras que en la otra versión del mundo, la “contrafactual”, no me la tomo y las dos horas registro la severidad del dolor. A partir de esto, la tradición de los potential outcomes define al efecto causal de tomar una aspirina en el dolor de cabeza como la diferencia entre esas dos mediciones.\nTodo muy lindo, pero como ya estarán sospechando es imposible calcular un efecto que está expresado en función de un contrafactual, ya que este contrafactual no lo podemos observar. Pero no se preocupen que le vamos a encontrar la vuelta.\nEmpecemos con un poco de notación que nos va a ayudar a acomodar las ideas. Por simplicidad vamos a asumir una variable binaria para la asignación del grupo (por ejemplo, tratamiento y control). Esta variable vale \\(1\\) si la unidad i recibe el tratamiento y \\(0\\) si no. Cada unidad \\(i\\) va a tener dos potential outcomes: \\(Y_i^1\\) si la unidad recibió el tratamiento y \\(Y_i^0\\) si no. Esto significa que una unidad experimental en el mismo momento del tiempo va a recibir y no recibir el tratamiento, o sea, alguno de estos va a ser contrafactual1.\n1 De ahí el nombre de potential, porque se trata de posibles estados del mundo. Un estado en el que la unidad \\(i\\) recibe el tratamiento y uno en el que no.Los outcomes observables difieren de los potenciales. Mientras que los potenciales son variables aleatorias hipotéticas, los observables son variables aleatorias factuales y medibles. Hay una ecuación que nos permite definir el outcome observable (\\(Y^i\\)) en función de los potenciales, se llama la switching equation:\n\\[\nY_i = D_i Y_i^1 + (1-D_i) Y_i^0\n\\tag{3.1}\\]\nDonde \\(D_i\\) vale \\(1\\) si la unidad i recibió el tratamiento (entonces \\(Y_i=Y_i^1\\)) y \\(0\\) si no (entonces \\(Y_i=Y_i^0\\)). Vale la pena notar que \\(Y_i\\), el outcome observable, no tiene ningún supraíndice ya que no es más potencial.\nUsando esta notación definimos el efecto causal del tratamiento para una unidad \\(i\\) como: \\[\n\\delta_i = Y_i^1 - Y_i^0\n\\tag{3.2}\\]\nDonde queda claro que para estimar el efecto causal de acuerdo a la tradición de los potential outcomes debemos conocer dos estados del mundo a los que es imposible acceder simultáneamente. Y aqui yace el problema funcamental de la inferencia causal: Para calcular el efecto causal se requiere acceso a datos que siempre nos van a faltar (los contrafácticos)(Rubin 1974).\n\nRubin, Donald B. 1974. «Estimating causal effects of treatments in randomized and nonrandomized studies.» Journal of educational Psychology 66 (5): 688.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>*Potential outcomes*</span>"
    ]
  },
  {
    "objectID": "potential_outcomes.html#efecto-promedio-del-tratamiento",
    "href": "potential_outcomes.html#efecto-promedio-del-tratamiento",
    "title": "3  Potential outcomes",
    "section": "3.3 Efecto promedio del tratamiento",
    "text": "3.3 Efecto promedio del tratamiento\nAl igual que los potential outcomes, el efecto para la unidad \\(i\\) (\\(\\delta_i\\)) también es una variable aleatoria, y su esperanza es lo que vamos a llamar el efecto promedio del tratamiento (ATE2). El ATE va a ser la magnitud de interés en nuestros experimentos, el efecto promedio de mi tratamiento. El mismo se define de la siguiente forma:\n2 Del inglés Average treatment effect.\\[\n\\begin{array}\n_ATE &=& E[\\delta_i] \\\\\n&=& E[Y_i^1 - Y_i^0] \\\\\n&=& E[Y_i^1] - E[Y_i^0]\n\\end{array}\n\\tag{3.3}\\]\nAhora vamos a definir el efecto promedio, pero para el grupo tratado (es decir, los participantes asignados al grupo tratamiento, con \\(D_i=1\\)):\n\\[\n\\begin{array}\n_ATT &=& E[\\delta_i|D_i=1] \\\\\n&=& E[Y_i^1 - Y_i^0|D_i=1] \\\\\n&=& E[Y_i^1|D_i=1] - E[Y_i^0|D_i=1]\n\\end{array}\n\\tag{3.4}\\]\nEsta magnitud se llama ATT3 y se calcula de la misma forma que el ATE pero condicionando los \\(\\delta_i\\) al valor de \\(D_i\\) igual a 1. De manera análoga definimos el efecto promedio pero para el grupo no tratado4(\\(D_i=0\\))\n3 Del inglés Average treatment effect for the treated.4 Del inglés Average treatment effect for the untreated.\\[\n\\begin{array}\n_ATU &=& E[\\delta_i|D_i=0] \\\\\n&=& E[Y_i^1 - Y_i^0|D_i=0] \\\\\n&=& E[Y_i^1|D_i=0] - E[Y_i^0|D_i=0]\n\\end{array}\n\\tag{3.5}\\]\nOjo con confundir estos tres conceptos. Creo que el ATE es autoexplicativo, pero se suele confundir ATT y ATU. En el primer caso, estamos calculando la esperanza de los \\(\\delta_i\\) para los individuos pertenecientes al grupo tratamiento. Esto involucra tanto sus \\(Y^1_i\\) como sus \\(Y^0_i\\). Es una confusión común confundir estos efectos promedios con magnitudes no potenciales pero, como se observa de sus fórmulas, tanto estos últimos dos como el ATE no se pueden calcular en la práctica. En las secciones siguientes vamos a ver como, cumpliendo ciertas condiciones5, podemos estimar el ATE a partir de los outcomes observables.\n5 Spoiler: Asignación aleatoria de las unidades experimentales a los grupos.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>*Potential outcomes*</span>"
    ]
  },
  {
    "objectID": "potential_outcomes.html#diferencia-de-medias-simple",
    "href": "potential_outcomes.html#diferencia-de-medias-simple",
    "title": "3  Potential outcomes",
    "section": "3.4 Diferencia de medias simple",
    "text": "3.4 Diferencia de medias simple\n¿Qué es lo que sí podemos observar? Una magnitud que a priori podríamos creer que va aestar relacionada con el ATE y que podemos observar es la diferencia de medias entre los outcomes observados del grupo tratamiento y el grupo control. La vamos a llamar SDO6 y se calcula de la siguiente forma:\n6 Del inglés simple difference in outcomes.\\[\n\\begin{array}\n_SDO &=& E[Y_i^1|D_i=1] - E[Y_i^0|D_i=0] \\\\\n&=& \\frac{1}{N_T} \\sum_{i=1}^{N_T} (y_i|d_i=1) - \\frac{1}{N_C} \\sum_{i=1}^{N_C} (y_i|d_i=0)\n\\end{array}\n\\tag{3.6}\\]\nDonde \\(N_T\\) y \\(N_C\\) son la cantidad de individuos en el grupo tratamiento y control respectivamente (y \\(N_T + N_C = n\\)). Todo muy lindo, pero operemos un poquito para ver hasta que punto el SDO es un estimador insesgado del ATE. Empecemos escribiendo el ATE como una suma pesada del ATT y el ATU:\n\\[\n\\begin{array}\n_ATE &=& \\pi ATT + (1-\\pi) ATU \\\\\n&=& \\pi E[Y_i^1|D_i=1] - \\pi E[Y_i^0|D_i=1] + \\\\\n& & (1-\\pi) E[Y_i^1|D_i=0] - (1-\\pi) E[Y_i^0|D_i=0] \\\\\n&=& \\bigl\\{ \\pi E[Y_i^1|D_i=1] + (1-\\pi) E[Y_i^1|D_i=0] \\bigl\\} - \\\\\n& & \\bigl\\{ \\pi E[Y_i^0|D_i=1] + (1-\\pi) E[Y_i^0|D_i=0] \\bigl\\}\n\\end{array}\n\\tag{3.7}\\]\nCon \\(\\pi = N_T/n\\) y \\(1 - \\pi = N_C/n\\).\nOperando con la Ecuación 3.8 podemos despejar la diferencia entre los outcomes observables (SDO) y ver cómo esta se realciona con el resto de las magnitudes definidas7.\n7 Pueden ver el despeje numérico en detalle en el capítulo 4 de (Cunningham 2021).\nCunningham, Scott. 2021. Causal inference: The mixtape. Yale university press.\n\\[\n\\begin{array}\n_E[Y_i^1|D_i=1] - E[Y_i^0|D_i=0] &=& ATE \\\\\n&+& ( E[Y_i^0|D_i=1] - E[Y_i^0|D_i=0] ) \\\\\n&+& (1-\\pi) (ATT - ATU)\n\\end{array}\n\\tag{3.8}\\]\nQue podemos reescribir como:\n\\[\n\\begin{array}\n_\\underbrace{\\frac{1}{N_T} \\sum_{i=1}^{N_T} (y_i|d_i=1) - \\frac{1}{N_C} \\sum_{i=1}^{N_C} (y_i|d_i=0)}_\\text{Diferencia de los outcomes} &=& \\underbrace{ATE}_\\text{Efecto promedio del tratamiento} \\\\\n&+& \\underbrace{( E[Y_i^0|D_i=1] - E[Y_i^0|D_i=0] )}_\\text{Sesgo de selección} \\\\\n&+& \\underbrace{(1-\\pi) (ATT - ATU)}_\\text{Sesgo de efecto heterogéneo}\n\\end{array}\n\\tag{3.9}\\]\nLo que puede verse en Ecuación 3.9 es que si pudiéramos asegurar de alguna forma que los sesgos de selección y de efecto heterogéneo fueran cero, el SDO sería un buen estimador del ATE que es, al fin y al cabo, el efecto causal promedio que nos interesa en nuestro experimento.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>*Potential outcomes*</span>"
    ]
  },
  {
    "objectID": "potential_outcomes.html#independencia",
    "href": "potential_outcomes.html#independencia",
    "title": "3  Potential outcomes",
    "section": "3.5 Independencia",
    "text": "3.5 Independencia\nLa definición de independencia en el contexto de los potential outcomes es la siguiente:\n\\[\n(Y^0, Y^1) \\perp D\n\\] Momento cerebrito, pensemos una poco qué quiere decir. Esto significa que la asignación de los participantes al grupo control o tratamiento (\\(D\\)) no depende de los outcomes potenciales de ese individuo.\nVamos a pensarlo con un ejemplo concreto. Imaginen que tenemos una grupo de participantes para poner a prueba una cirugía experimental como altenativa a un tratamiento médico establecido no quirúrgico. Si la asingación de individuos al grupo tratamiento la hace un médico en base a lo que cree que va a ser conveniente para él, por ejemplo, no asignando a pacientes de edad avanzada al grupo tratamiento por el riesgo asociado a una cirugía, o asignando a pacientes cuyo pronóstico con el método tradicional vea poco favorable al grupo control. En este caso, la asignación a un grupo sí depende de los posibles resultados, por lo tanto, no hay independencia. Si en lugar de eso tiráramos una moneda antes de recibir a cada paciente, podríamos de esa forma asegurar la independencia.\nLa independencia implica que se cumpla:\n\\[\n\\begin{array}\n_E[Y^1|D=1] - E[Y^1|D=0] &=& 0 \\\\\nE[Y^0|D=1] - E[Y^0|D=0] &=& 0\n\\end{array}\n\\tag{3.10}\\]\nEs decir, que la esperanza de los outcomes para los participantes que fueron asignados al grupo tratamiento como al grupo control serían iguales si pudieramos medirlos a ambos en “mundo tratamiento”8. Y lo mismo pasaría si pudiéramos medirlos a ambos grupos en el “mundo control”[^indep]. Ojo que esto no implica que la esperanza del outcome para tratamiento en los tratados sea igual a la esperanza para no tratamiento en los controles (\\(E[Y^1|D=1] - E[Y^0|D=0] = 0\\)) ni igual a la esperanza no tratamiento de los tratados (\\(E[Y^1|D=1] - E[Y^0|D=1] = 0\\)).\n8 Tengamos en cuenta que \\(E[Y^1|D=0]\\) es un contrafáctico, ya que es el outcome habiendo sido expuesto al tratamiento pero de los individuos en el grupo control (de ahí la condicionalidad con \\(D=0\\))¿Qué implicancias tiene las igualdades presentadas en Ecuación 3.10 en los sesgos que vimos en la ecuación Ecuación 3.8? Empecemos por el sesgo de selección (\\(E[Y^0|D=1] + E[Y^0|D=0]\\)). Vemos que, deacuerdo a la primera línea de Ecuación 3.10 ya nos dice que, de ser independiente la asignación del grupo experimental, este sesgo sería cero. Pensemos un poco. Lo que nos está diciendo la condición de independencia es que si ambos grupos fueran no tratados, ambos tendrían el mismo outcome lo que pareciera indicarnos que es razonable considerar nulo al sesgo de selección.\nLa relación del sesgo de efecto heterogéneo (\\((1-\\pi) (ATT - ATU)\\)) con la independencia es un poquito más difícil de demostrar. Olvidémonos del \\((1-\\pi)\\) de momento. Reescribamos los efectos ATT y ATU:\n\\[\n\\begin{array}\n_ATT &=& E[Y^1|D=1] - E[Y^0|D=1] \\\\\nATU &=& E[Y^1|D=0] - E[Y^0|D=0]\n\\end{array}\n\\]\nY ahora restemos ambos términos:\n\\[\n\\begin{array}\n_ATT - ATU &=& E[Y^1|D=1] - E[Y^0|D=1] - ( E[Y^1|D=0] - E[Y^0|D=0] )\\\\\n&=& \\bigl\\{ E[Y^1|D=1] - E[Y^1|D=0] \\bigl\\} + \\bigl\\{ E[Y^0|D=0] - E[Y^0|D=1] \\bigl\\}\n\\end{array}\n\\tag{3.11}\\]\nReescrito de esta forma podemos ver los dos primero términos de Ecuación 3.11 se hacen cero por la rpimero línea de Ecuación 3.10, y los últimos dos se hacen cero por la segunda.\nFinalmente, demostramos que si hay independencia en la asignación de los grupos, la diferencia de las medias entre el grupo tratado y el control es un buen estimador del ATE.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>*Potential outcomes*</span>"
    ]
  },
  {
    "objectID": "intro_stat.html#probabilidad-condicional",
    "href": "intro_stat.html#probabilidad-condicional",
    "title": "2  Repaso de probabilidad y estadística",
    "section": "2.3 Probabilidad condicional",
    "text": "2.3 Probabilidad condicional\nLa probabilidad condicional es la probabilidad de que ocurra un evento A dado que ocurrió un evento B y se escribe como \\(P(A|B)\\). Por ahora quedémonos con esta definición simple que será de vital importancia para lo que sigue.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Repaso de probabilidad y estadística</span>"
    ]
  },
  {
    "objectID": "potential_outcomes.html#guerra-fría-manos-y-contrafácticos.",
    "href": "potential_outcomes.html#guerra-fría-manos-y-contrafácticos.",
    "title": "3  Potential outcomes",
    "section": "",
    "text": "De qué hablamos cuando hablamos de contrafactuales\n\n\n\nEn el marco de los potential outcomes de Rubin(Rubin 1974), un contrafactual es el resultado que habría ocurrido para una unidad (por ejemplo, una persona, un paciente, un sujeto experimental) si hubiera recibido un tratamiento diferente del que realmente recibió. Este concepto es fundamental para entender los efectos causales. Nos permite definir lo que entendemos por causa: la diferencia entre lo que realmente sucedió y lo que habría sucedido en un escenario alternativo.\nEn pocas palabras:\n\nPara alguien que recibió el tratamiento, el contrafactual es lo que habría sucedido si no hubiera recibido el tratamiento. Por ejemplo, si un paciente recibió un nuevo medicamento y se recuperó, el resultado contrafactual es su estado de salud si no hubiera recibido el medicamento. Esto nos ayuda a aislar el efecto del medicamento.\nPara alguien que no recibió el tratamiento, el contrafactual es lo que habría sucedido si hubiera recibido el tratamiento. Por ejemplo, si un estudiante no asistió a un programa de tutoría y reprobó un examen, el contrafactual es su calificación hipotética si hubiera asistido al programa.\n\nDado que cada unidad recibe solo un tratamiento, solo podemos observar un resultado (el resultado real). El resultado contrafactual es, por definición, inobservable. Esto se conoce a menudo como el problema fundamental de la inferencia causal. Debido a que no podemos observar simultáneamente ambos resultados potenciales para el mismo individuo, vamos a usar métodos y suposiciones estadísticas para estimar los efectos promedio del tratamiento en grupos de individuos. Más de esto en los próximos capítulos.\n\n\n\n\n\n\n\nPraying Hands de Albrecht Durero.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>*Potential outcomes*</span>"
    ]
  },
  {
    "objectID": "exp_aleatorios.html#guerra-fría-manos-y-contrafácticos.",
    "href": "exp_aleatorios.html#guerra-fría-manos-y-contrafácticos.",
    "title": "5  Experimentos aleatorios",
    "section": "5.1 Guerra fría, manos y contrafácticos.",
    "text": "5.1 Guerra fría, manos y contrafácticos.\nSon las 3 de la mañana del 26 de septiembre de 1983. Con una taza de café en mano, Stanislav Petrov vigila las alarmas de una estación de monitoreo de ataques nucleares a las afueras de Moscú. De pronto, los paneles se iluminan con un rojo furioso: tres misiles intercontinentales están en camino a la cúpula del Kremlin… o, quizás, el sistema tiene un error y se trata de una falsa alarma.\nClaro, aquí tienes un resumen detallado con subtítulos para cada tema presentado en la presentación “CC400-2025-Semana4”:Resumen de la Presentación “CC400-2025-Semana4”Introducción a Diseños Experimentales y Aleatorizados La presentación introduce los diseños experimentales y cuasi-experimentales, enfocándose en los diseños aleatorizados. Se presenta a Ignacio Spiousas como el presentador para el Otoño 2025. Potencial Outcomes y el SDO (Sample Difference of Outcomes) Se discute cómo el SDO contiene al ATE (Average Treatment Effect), pero en la práctica no conocemos otros términos. Se introduce el concepto de “potential outcomes” y la descomposición del SDO. Independencia en Potencial Outcomes Se enfatiza la importancia de la independencia en los “potential outcomes”. Esto implica que la asignación al tratamiento no debe depender de los resultados potenciales. Se advierte sobre el sesgo si los participantes son elegidos para tratamientos basados en expectativas de resultados. Experimentos Aleatorios Se explica que en los experimentos aleatorios, los sujetos son asignados a grupos (tratamiento y control) de manera aleatoria. Los experimentos aleatorios son el “gold-standard” para estimar efectos y la base para estudiar cuasi-experimentos. Diseños Between-Groups Aleatorios Se describen los diseños between-groups aleatorios, donde los participantes son asignados a un grupo de tratamiento o control. Se aclara la diferencia entre muestra aleatoria y asignación aleatoria. Xs y Os en Experimentos Aleatorios Se introduce la notación de “X” para la administración de un tratamiento y “O” para una observación. Se presentan ejemplos de diseños simples between-groups, como el diseño posttest-only y pretest-posttest. Ejemplos de Experimentos Aleatorios en el Campo Se mencionan ejemplos de estudios RCT (Randomized Controlled Trials) en economía del desarrollo y políticas públicas en países en desarrollo, citando a Duflo y el Banco Mundial. También se menciona un ejemplo de asignación aleatoria de policías extra a ciertas partes de la ciudad. El Problema de la Selección Se discute el problema de la selección y cómo los participantes pueden ser confusores de los tratamientos en diseños between-groups. Se destaca que la asignación aleatoria ayuda a evitar el sesgo. Experimentos Aleatorios Posttest-Only Se presenta el modelo de regresión para experimentos posttest-only y se explica cómo estimar el efecto del tratamiento. Se utiliza un ejemplo de A/B testing para ilustrar el análisis. A/B Testing Se detalla un ejemplo de A/B testing, donde se comparan dos versiones de un sitio web midiendo el tiempo de permanencia. Se muestra cómo simular datos, realizar análisis de regresión y pruebas t para comparar los grupos. Experimentos Aleatorios Pretest-Posttest Se describe el diseño pretest-posttest between-group randomized experiment. Se explica cómo las medidas pretest pueden aumentar la precisión y potencia del estudio. Blocking o Matching en Diseños Pretest-Posttest Se introduce la técnica de blocking o matching, donde los sujetos son separados en grupos basados en medidas pretest. Se muestra cómo esto puede mejorar el análisis. Covariables en Diseños Pretest-Posttest Se explica cómo agregar medidas pretest como covariables en el análisis de regresión. Se discute cómo esto puede reducir la varianza no explicada y aumentar la potencia estadística. Interacciones en Diseños Pretest-Posttest Se aborda el tema de las interacciones entre el tratamiento y las medidas pretest. Se muestra cómo modelar y interpretar estas interacciones en el análisis de regresión. Precisión y Potencia Se discute cómo la relación entre las variables pretest y posttest afecta la potencia estadística y precisión del estudio. Se menciona que cuanto más relacionadas estén las variables, mejor será la potencia. Bibliografía Se cita a Reichardt, C. S. (2019) como referencia bibliográfica para el tema de cuasi-experimentación."
  },
  {
    "objectID": "exp_aleatorios.html#por-qué-son-importantes-los-experimentos-aleatorios",
    "href": "exp_aleatorios.html#por-qué-son-importantes-los-experimentos-aleatorios",
    "title": "5  Experimentos aleatorios",
    "section": "5.1 ¿Por qué son importantes los experimentos aleatorios?",
    "text": "5.1 ¿Por qué son importantes los experimentos aleatorios?\nEn los experimentos aleatorios1 los sujetos son asignados a los grupos (por ejemplo, tratamiento y control) aleatoriamente. Esto significa que en la asignación de los grupos aleatorios hay involucrado un proceso realmente aleatorio, como arrojar un moneda. Ojo con confundir el concepto de asignación aleatoria con el de muestra aleatoria: Que el muestreo sea aleatorio significa que los participantes son una muestra seleccionada al azar de una población más amplia, mientras que la asignación aleatoria significa que los participantes, independientemente de si fueron seleccionados de una población más amplia o no, son asignados al azar a diferentes condiciones experimentales.1 A lo largo del capítulo vamos a usar de forma intercambiable las expresiones experimentos aleatorios y experimentos aleatorizados. También vamos a usar la sigla RCT del inglés randomized controlled trials.\n\n\n\n\n\n\nSobre la aleatoridad de las computadoras\n\n\n\nCuando hablamos de un evento aleatorio, hablamos de una entidad abstracta cuyo resultado no se puede predecir exactamente. Para poner este tipo de eventos en el mundo real solemos hechar mano de ejemplos clásicos que involucran una complejidad fìsica tal que resulta imposible predecirlos exactamente, como arrojar un dado o una moneda. El ejemplo de la moneda es la forma más usual de hablar de una variable aleatoria con dos posibles valores equiprobables (aunque parezca que no tanto (Bartoš et al. 2023)). Sin embargo, esta aleatoridad es muy costosa de reproducir. Es por eso que las computadores utilizan lo que se llama generadores de números pseudo aleatorios2. Estos generadores utilizan series de números generados de forma pseudo aleatoria pero que puede ser recuperada determinìsticamente a partir de una “semilla”. Es por eso que cuando simulamos datos en este libro lo primero que hacemos es ejecutar set.seed(42) (42 o el número que sea), para de esa forma poder obtener el mismo resultado cada vez que replicamos, o el lector quiere replicar, las simulaciones.\n\nBartoš, František, Alexandra Sarafoglou, Henrik R Godmann, Amir Sahrani, David Klein Leunk, Pierre Y Gui, David Voss, et al. 2023. «Fair coins tend to land on the same side they started: Evidence from 350,757 flips». arXiv preprint arXiv:2310.04153.\n2 Para más información pueden ir a leer esto.Dicho esto. A fines prácticos, es totalmente razonable utilizar un generador de números pseudo aleatorios para la asignación a grupos experimentales en los experimentos aleatorios.\n\n\nPor ejemplo, en el caso más simple, esto significa que dada una muestra de personas, vamos a asignar a cada de una de ellas “tirando una moneda” al grupo control (\\(D=0\\)) o tratamiento (\\(D=1\\)) como se ve en la siguiente figura.\n\n\n\n\n\nLos experimentos aleatorios son el gold-standard para estimar el efecto de un tratamiento. De hecho, al ser la asignación aleatoria, podemos asegurar que, como mencionamos en el capítulo Capítulo 3, existe independencia (\\((Y^0, Y^1) \\perp D\\)). Esto nos asegura que la diferencia de medias de los grupos tratamiento y control son un estimador consistente del ATE. Dicho esto, veremos que hay formas más “eficientes” de estimar el ATE, es decir, con mayo potencia estadística.\nHay una razón extra para que en este libro empecemos hablando en detalle de los experimentos aleatorizados, y es que cuando entremos de lleno en el mundo de los cuasiexperimentos nos será de gran ayuda entender cuál es el problema y cuál es la solución que se propone. Esto nos va a permitir tener una idea más concreta de las ventajas y limitaciones de cada uno de los diseños cuasiexperimentales que vamos a estudiar más adelante.\nEn muchas ocasiones los experimentos aleatorios terminan siendo degradados a la categoría de cuasiexperimento. Por ejemplo: Supongamos que hay un estudio que quiere evaluar el efecto de un programa de mindfulness en la cantidad de hechos de violencia en un establecimiento educativo. Para esto se asigno aleatoriamente a diez escuelas al grupo mindfulness y diez escuelas al grupo control. Hasta acá todo muy lindo, deberíamos llevar adelante el programa, medir la cantidad de hechos de violencia en cada escuela, hacer la diferencia de medias y voilá, ya tenemos un estimador del ATE. Pero a veces las cosas no son tan sencillas y en el medio de este experimento van a pasar cosas. Por ejemplo, hay un grupo de colegios del grupo control que, por presión de los padres, incorporan un programa de mindfulness propio, mientras que otro grupo del colegios, esta vez del grupo tratamiento, deciden no implementar el programa de mindfulness propuesto por nosotros porque les interfiere con la curricula. Para colmo, varios colegios de ambos grupos deciden que la participación sea voluntaria. En fin, el horror. Lo que nos termina pasando es que, aunque el diseño sea un experimento aleatorio, la pérdida de control sobre la implementación y la participación voluntaria generan contaminación y sesgo de selección, degradando el estudio a un cuasiexperimento. Es decir, la comparación entre grupos ya no se basa en la aleatorización y vamos a requerir de otros controles estadísticos para corregir posibles sesgos. Más adelante vamos a charlar un poquito más de esto.\nDicho esto volvamos al maravilloso mundo de los 🌈experimentos aleatorizados ideales🌈."
  },
  {
    "objectID": "exp_aleatorios.html#experimentos-bewtween-groups",
    "href": "exp_aleatorios.html#experimentos-bewtween-groups",
    "title": "5  Experimentos aleatorios",
    "section": "5.4 Experimentos bewtween groups",
    "text": "5.4 Experimentos bewtween groups\n\n\n\n\n\n\nHablemos un poco de la nomenclatura\n\n\n\n\n\n\n\n5.4.1 Sólo posttest\n\\[\n\\begin{array}\n_Y_{i} &=& \\beta_0 + \\beta_T T_i + \\epsilon_{i}\n\\end{array}\n\\tag{5.1}\\]\nDonde \\(T_i\\) es una variable indicadora que toma el valor \\(1\\) si el participante pertenece al grupo tratamiento y el valor \\(0\\) si no.\n\n\n5.4.2 Pretest-posttest",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Experimentos aleatorios</span>"
    ]
  },
  {
    "objectID": "exp_aleatorios.html#diseños-clúster",
    "href": "exp_aleatorios.html#diseños-clúster",
    "title": "5  Experimentos aleatorios",
    "section": "5.5 Diseños clúster",
    "text": "5.5 Diseños clúster\nLos diseños clúster son una forma de diseño experimental donde los sujetos son asignados a grupos (clústeres) y luego se asignan tratamientos a esos grupos. Este enfoque es útil cuando no es práctico o posible asignar tratamientos a individuos de manera independiente.\nLas ventajas de los diseños cluster son varias:\n\nA veces puede resultar más práctico o conveniente asignar aleatoriamente a grupos que a individuos. Por ejemplo, en el sistema escolar nos pueden permitir asignar cursos o escuelas a distintos tratamientos pero no a estudiantes\nLa aleatorización a nivel clúster puede ser útiles para minimizar los efectos de difusión, imitación de tratamientos u otros problemas de adherencia. Por ejemplo, para un estudiante es más difícil ser crossover si el tratamiento diferente lo tienen en otro aula o escuela en lugar de su compañero de banco.\nPueden ser necesarios para evitar los spillovers. En el estudio de la campaña de SMSs para mejorar la tasa de vacunación contra el HPV hubieran hecho la aleatorización a nivel barrio o cioudad, no hubieran tenido el spillover debido a que un vecino te comenta del SMS que recibió.\nPueden ser necesarios para evitar las externalidades. Por ejemplo, si se está haciendo un experimento para evaluar el efecto de un tratamiento dentro de un determinado grupo cerrado (una ciudad), el aumento de empleabilidad para el grupo tratamiento puede generar que haya menos empleos disponibles para el grupo control y que baje su tasa de empleo, no como consecuencia de ser menos “empleables”. Aleatorizando por ciudad se puede reducir este efecto.\nAlgunos programas se aplican sí o sí a grupos. Por ejemplo, una campaña mediática, una terapia de grupo o un cambio de política a nivel escuela.\nLos efectos pueden ser mayores cuando se aplican a todo un grupo. Esto tiene que ver con que debemos tener en cuenta que, si lo que queremos evaluar es una intervención que se va a aplicar a nivel grupo, si lo hacemos aleatorizando a nivel individual podemos estar subestimando su efecto. Por ejemplo, una intervención que mejore las habilidades de lectura de todo un curso puede tener un efecto sinergético que no estaría presente si sólo la mitad del curso está expuesto al tratamiento y la maestra debe alternar entre un subgrupo y el otro.\n\nAlgo muy importante es que la aleatorización a nivel clúster no significa que vamos a dejar de prestar atención a los individuos y utilizar medidas a nivel clúster. De hecho todo lo contrario, si bien vamos a aleatorizar a nivel grupo, vamos a medir el outcome para cada individuo y la relaciòn entre la variabilidad entre e intra grupos va a jugar un papel importante (más de esto en las siguietne secciones). En caso de que aleatoricemos a nivel grupo y después tomemos simplemente un outcome por grupo no estamos ante un diseño clúster sino que simplemente cambiamos la unidad experimental del individuo al grupo.\nTodo parece ideal, ¿No? Pero nada de esto viene sin un costo. En general el costo es la potencia estadística. Es decir, para tener la misma potencia estadística que aleatorizando a nivel de individuo, vamos a necesitar más (y a veces muchos más) sujetos experimentales divididos en grupos. Más de eso en la sección que sigue.\n\n5.5.1 Análisis de datos jerárquicos\nPara analizar este tipo de datos utilizamos modelos estadísticos que tienen en cuenta la estructura jerárquica de los datos. En este libro los vamos a llamar de forma general modelos jerárquicos9. A continuación tenemos la estructura de un modelo lineal jerárquico con un sólo nivel de agrupamiento10.9 También se pueden llamar hierarchical linear models, linear mixed-effect model , mixed models, nested data models, random coefficient, random-effects models, random parameter models o split-plot designs. Pero siempre estamos hablando de los mismo.10 Por ejemplo, sirve para modelar los estudiantes de una escuela, pero también podríamos tener modelos que nos permitan modelar los estudiantes de una escuela, que a su vez pertenece a un distrito escolar, a una provincia, etc. Teniendo más niveles de agrupamiento, pero eso queda afuera del alcance de este libro.\n\\[\n\\begin{array}\n_Y_{ij} &=& \\mu_j + \\epsilon_{ij} \\\\\n\\mu_j &=& \\beta_0 + \\beta_T T_j + r_j\n\\end{array}\n\\]\nDonde tanto \\(r_j\\) como \\(\\epsilon_{ij}\\) tiene esperanza cero y varianza \\(\\sigma^2_{inter-clúster}\\) y \\(\\sigma^2_{intra-clúster}\\) respectivamente. En la ecuación anterior \\(T_j\\) es una variable indicadora que toma el valor \\(1\\) si la escuela, y no el participante como antes, pertenece al grupo tratamiento y el valor \\(0\\) si no. De esta forma, si la escuela pertenece al grupo tratamineto su media será \\(\\mu_{j|D_j=1} = \\beta_0 + \\beta_T + r_j\\) mientras que si pertenece al grupo control será \\(\\mu_{j|D_j=0} = \\beta_0 + r_j\\), y la esperanza de la diferencia entre ambas (dado que la esperanza de \\(E(r_j)=0\\)) será justamente la magnitud del efecto del tratamiento \\(\\beta_T\\).\n\n\n5.5.2 La potenncia y la correlación intraclase (ICC)\nLa correlación intraclase (ICC) es una estadística descriptiva que indica en qué medida los resultados: 1) tienden a ser similares dentro de cada clúster, o 2) tienden a diferir entre distintos clústers, en relación con los resultados observados en otros grupos. Se define de la siguiente forma:\n\\[\nICC = \\frac{\\sigma^2_{inter-clúster}}{\\sigma^2_{inter-clúster} + \\sigma^2_{intra-clúster}}\n\\]\ndonde \\(\\sigma^2_{inter-clúster}\\) es la varianza entre clústers, es decir, cuánto se varían las medias de los clústers entre clústers, y \\(\\sigma^2_{intra-clúster}\\) es la varianza dentro de los clústers, es decir, cuánto varías las mediciones de cada individuo dentro de cada clúster.\nComo mencionamos anteriormente, la aleatorización a nivel de clúster tiene su costo. Si los outcomes dentro de cada clúster están altamente correlacionados y la magnitud de los resultados varía considerablemente entre clústers, entonces es probable que los participantes dentro de un mismo grupo tengan resultados similares, y el ICC será alto. En estos casos, los datos provenientes de un individuo aportan casi tanta información como si se incluyera a todos los miembros. Por lo tanto, el tamaño muestral efectivo se aproxima más al número de clústers que al tamaño total de la muestra de individuoos.\nPasando en limpio. Si los clústers son más similares entre sí, el modelo estadístico será más potente, con un tamaño de muestra efectivo cercano a la cantidad de individuos mientras que si los clústers difieren mucho entre sí la potencia estadística cae, aproximándonos a un tamaño de muestra efectivo igual a la cantidad de clústers.\nEs por esto último que en la práctica siempre conviene agergar más clústers que individuos11. Pero claro, eso es lo que suele ser más costoso.11 Un ejemplo numérico, dado un total de \\(1000\\) participantes, la potencia sería de \\(0.75\\) si hubiera \\(50\\) grupos de \\(20\\) participantes cada uno, mientras que el poder sería sólo de \\(0.45\\) con \\(20\\) grupos de \\(50\\) participantes cada uno, suponiendo un \\(ICC\\) de \\(0.1\\).\n\n\n5.5.3 Un ejemplo con datos\nSimulemos un pequeño ejemplo. Supongamos que, sin un ápice de creatividad, queremos evaluar la efectividad de una intervención educativa que sólo se puede aplicar a nivel de escuela. El outcome de interés a nivel estudiante va a ser la nota obtenida en un examen estandarizado de matemáticas. Tengamos en cuenta la ecuación ?eq-cluster_model, en nuestro caso \\(Y_{ij}\\) sería la nota de cada estudiante, mientras que \\(mu_j\\) sería la media de cada colegio.\nLas medias de cada colegio las crearemos usitilizando los parámetros \\(beta_0 = 50\\) y \\(beta_T = 10\\), es decir, la magnitud del efecto que deberíamos recuperar luego es \\(10\\). Además el error será \\(r_j \\sim \\mathcal{N}(0, \\sigma_{escuelas}^2)\\), con \\(\\sigma_{escuelas} = 5\\). Vamos a simular \\(40\\) escuelas, asignando la mitad al grupo tratamiento y la otra mitad al grupo control. Veamos qué pasa con las medias de las escuelas que vamos a simular.\n\n\nVer el código\n# Data jerárquica\nset.seed(42)\nn_escuelas <- 40\n\n# Supongamos que tengo n_escuelas escuelas, cada una de ellas tiene una media de la calificacion de nota de matemática\nmu_j <- rnorm(n_escuelas, 50, 5)\n  \n# Las primera 3 son asignadas al grupo tratamiento y las otrasa tres al grupo control\nd <- c(rep(\"Tratamiento\", n_escuelas/2), rep(\"Control\",  n_escuelas/2))\n\n# El efecto del tratamiento es 10, entonces a la media de cada escuela que pertenece al grupo tratamiento\n# le sumamos 10\nbeta_T <- 10\n\n# Armo un tibble con las escuelas\nescuelas <- tibble(tratamiento = d, media = mu_j) |>\n    mutate(media = if_else(tratamiento == \"Tratamiento\", media + beta_T, media)) \n\n# Graficamos los promedios de las escuelas\nescuelas |>\n  ggplot(aes(x = tratamiento, \n             y = media,\n             color = tratamiento)) +\n  geom_jitter(size = 2, \n              alpha = .6,\n              width = .2) +\n  scale_color_manual(values = c(\"#1380A1\", \"#ED6A5A\")) +\n  labs(color = NULL, x = NULL, y = \"Media de la escuela j\") +\n  theme_bw() +\n  theme(legend.position = \"top\")\n\n\n\n\n\nComo era esperable, las medias de las escuelas en el grupo tratamiento están por encima de las medias en el grupo control. Sin embargo, hay escuelas para las que esto no es así. Es por eso que es muy importante modelar a la escuela (el clúster) como una posible fuente de variabilidad.\nAhora lo que podemos hacer es simular las notas de los estudiantes dentro de cada colegio \\(Y_{ij}\\). Para eso vamos a echar mano a la primera línea de la ecuación ?eq-cluster_model. En este caso el \\(mu_j\\) será el obtenido en el punto anterior con un \\(\\epsilon_{ij} \\sim \\mathcal{N}(0, \\sigma_{estudiante}^2)\\), con \\(\\sigma_{estudiante} = 10\\). Veamos ahora qué pinta tienen estos datos.\n\n\nVer el código\n# Data jerárquica\n\n# Ahora vamos a muestrear 20 estudiantes en cada escuela, con media mu_j y un sigma de 10\nalumnos <- tibble(tratamiento = rep(d, each = 20), \n                  order =rep(1:n_escuelas, each = 20),\n                  escuela = rep(paste(\"Escuela\", 1:n_escuelas), each = 20),\n                  media = rep(mu_j, each = 20)) |>\n  mutate(media = if_else(tratamiento == \"Tratamiento\", media + beta_T, media)) |>\n  rowwise() |>\n  mutate(Yij = rnorm(1, media, 10)) |>\n  select(-media)\n\n# Graficamos los promedios de las escuelas\nalumnos |>\n  ggplot(aes(x =  fct_reorder(escuela, desc(order)), \n             y = Yij,\n             color = tratamiento)) +\n  geom_jitter(size = 1, \n              alpha = .6,\n              width = .2) +\n  scale_color_manual(values = c(\"#1380A1\", \"#ED6A5A\")) +\n  labs(color = NULL, x = NULL, y = \"Yij\") +\n  coord_flip() +\n  theme(legend.position = \"top\")\n\n\n\n\n\nAcá vemos que a la variabilidad de las escuelas se suma la variabilidad de los sujetos.\nAhora vamos a tratar de recuperar el tamaño del efecto ajustando un modelo lineal de efectos mixtos12.12 Sin entrar en demasiado detalle, un modelo lineal de efectos mixtos tiene en cuenta la estructura jerarquica del efecto. En este caso en particular vamos a permitirle al modelo que el punto medio de cada colegio sea considerado un factor aleatorio.\n\n\nVer el código\nmlmer <- lmer(Yij ~ tratamiento + (1|escuela), data = alumnos)\nmodelsummary(list(\"Escuelas\"= mlmer),\n             coef_rename = c(\"tratamientoTratamiento\" = \"Tratamiento\"),\n             statistic = NULL, \n             gof_omit = 'DF|Deviance|R2|AIC|BIC|Log.Lik|F')\n\n\n\n \n\n  \n    \n    \n    tinytable_c5l6bs0cuyooeaniywog\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n        \n              \n                 \n                Escuelas\n              \n        \n        \n        \n                \n                  (Intercept)           \n                  47.802\n                \n                \n                  Tratamiento           \n                  12.923\n                \n                \n                  SD (Intercept escuela)\n                  6.260 \n                \n                \n                  SD (Observations)     \n                  9.733 \n                \n                \n                  Num.Obs.              \n                  800   \n                \n                \n                  ICC                   \n                  0.3   \n                \n                \n                  RMSE                  \n                  9.51  \n                \n        \n      \n    \n\n    \n\n  \n\n\n\n\nTratemos de entender qué nos dice este modelo. (Intecept) no es otra cosa que \\(\\hat{\\beta_0}\\) que, de acuerdo a lo que simulamos, debería valer \\(50\\), que era el valor del parámetro que usamos para generar las medias de las escuelas antes de sumarles el error \\(r_j\\) y el efecto del tratamiento. Hablando del efecto del tratamiento, podemos ver que para esta simulación en particular, la estimación del efecto de la intervención \\(\\beta_T\\) que sabemos que vale \\(10\\) es estimada como \\(\\hat{\\beta_T} = 12.92\\). Otra cosa interesante que podemos ver es que el modelo también estima la variabilidad de los errores donde SD (Intercept escuela) es una estimación de \\(r_j\\) y SD (Observations) es una estimación de \\(\\epsilon_{ij}\\), con un valor de \\(9.73\\). Ambos valores de variabilidad son similares a los que usamos para hacer las simulaciones.\nPero… ¿Por qué el valor estimado del efecto es \\(\\hat{\\beta_T} = 12.92\\) en lugar de \\(10\\)? Bueno, porque se trata de una simulación con su respectiva variabilidad. Por ejemplo, veamos qué pasa si simulamos \\(1000\\) experimentos.\n\n\nVer el código\n# Data jerárquica\nset.seed(12)\n\nn_escuelas <- 100\nbetalmer <- c()\nbeta_T <- 10\nd <- c(rep(\"Tratamiento\", n_escuelas/2), rep(\"Control\",  n_escuelas/2))\n\nfor (i in 1:1000) {\n  mu_j <- rnorm(n_escuelas, 50, 5)\n  \n  alumnos <- tibble(tratamiento = rep(d, each = 20), \n                    escuela = rep(paste(\"Escuela\", 1:n_escuelas), each = 20),\n                    media = rep(mu_j, each = 20)) |>\n    mutate(media = if_else(tratamiento == \"Tratamiento\", media + beta_T, media)) |>\n    rowwise() |>\n    mutate(Yij = rnorm(1, media, 10)) |>\n    select(-media)\n  \n  mlmer <- lmer(Yij ~ tratamiento + (1|escuela), data = alumnos)\n  betalmer <- c(betalmer, fixef(mlmer)[2])\n}\n\nbetas <- tibble(betalmer = betalmer)\nmean_beta <- betas |>\n  summarise(m_beta = mean(betalmer))\n\nbetas |>\n  ggplot(aes(x = betalmer)) +\n  geom_histogram(fill = \"#1380A1\", \n                 alpha = .6,\n                 bins = 30) +\n  geom_vline(xintercept = mean_beta$m_beta, \n             color = \"#1380A1\", \n             linewidth = 1) +\n  geom_label(data = mean_beta,\n            aes(label = paste(\"Efecto promedio =\", round(m_beta,2))),\n            x = 10, \n            y = 50)  +\n  labs(x = \"Estimación del efecto del tratamiento\",\n       y = NULL) +\n  theme_bw()\n\n\n\n\n\nVemos que si hacemos un histograma de todas las estimaciones del parámetro en base a las \\(1000\\) simulaciones de los datos, el promedio es 10.02, un valor bastante cercano al valor real de \\(10\\)13. Ahora sí nos podemos quedar tranquilos.13 Recordemos que en la práctica nunca vamos a conocer el valor real del parámetro y que esa es un ventaja que sólo tenemos en estos casos en los que simulamos “muestras” a partir de valores conocidos de los parámetros."
  },
  {
    "objectID": "exp_aleatorios.html#el-experimento-ideal",
    "href": "exp_aleatorios.html#el-experimento-ideal",
    "title": "5  Experimentos aleatorios",
    "section": "5.2 El experimento ideal",
    "text": "5.2 El experimento ideal\nEl experimento ideal es ese experimento tan bien planificado, tan bien implementado y tan bien acatado por sus participantes que en la realidad nunca ocurre. Sin embargo, hay una excepción y son, en general, los medical trials. De hecho hay algunas características que esperaríamos ver en un RCT3 y son las siguientes.3 Randomized clinical trials, o ensayos clínicos aleatorizados. Son estudios experimentales que se utilizan para testear la eficacia o la seguridad de procedimientos médicos o tratamientos.\n\nControles adecuados: Si diseñamos un experimento para estimar el efecto de un tratamiento, debemos tener un grupo control adecuado con el que comparar. Sin embargo, esto no significa que el grupo control sea siempre un grupo simplemente no expuesto al tratamiento. Por ejemplo, es muy conocido el ejemplo de la determinación de la efectividad de un fármaco, en los que al grupo control se le ofrece una pastilla que no contiene a la droga siendo estudiada sino unas pastilla de igual forma, tamaño y prescripción de consumo pero, típicamente, de azucar. Esto lo que nos permite es poder descontar el efecto de consumir un placebo en la estimación final de la efectividad del fármaco4.También es posible que por consideraciones éticas no podamos dejar al grupo control con un tratamiento placebo (por ejemplo cuando ya existe un tratamiento efectivo para la enfermedad que estamos estudiando, si lo hicieramos privaríamos a los sujetos del grupo control de su derecho a la salud), en estos casos el grupo control recibe el tratamiento típico y el grupo intervención el del estudio, en estos casos descontaremos el efecto del tratamiento común y nuestro ATE es el efecto de la intervencion por encima del tratamiento usual\n\n\n4 Si les interesa, también existen el efecto nocebo y know-cebo.\nAsignación aleatoria a los grupos experimentles: Como vimos en el capítulo Capítulo 3, la mejor forma de asegurar que los grupos control y tratamiento son lo más iguales posibles es asignando aleatoriamente a los participantes. Esto, junto con una cantidad de participantes suficiente nos asegura que ambos grupos son iguales en todos los factores que pueden influenciar el resultado del experimento, incluyendo los factores de los que no sabemos.\nLos individuos deben ser considerados en el grupo asignado: Los participantes asignados al grupo tratamiento deben ser considerados como tratamiento, independientemente de si se expusieron o no al mismo. Esto es conocido como el principio intention to treat y puede sonar un poco raro. Sin embargo, lo podemos pensar como un cambio del tratamiento que queremos evaluar. Por ejemplo, hay un experimento en el que se quiere evaluar el efecto de la estatinas en el colesterol LDL. Hay un grupo al que le dan estatinas y otro grupo al que le dan un placebo. Un $18% $ de los que fueron originalmente asignados al grupo estatinas dejó de tomarlas y un $38% $ de los que fueron asignados al grupo placebo empezó a tomar estatinas durante el trial. Esto significa que nuestro experimento no estimaría correctamente el efecto de tomar las estatinas, pero por otro lado, sí estimaría bien el efecto de ser recetado con estatinas. Y si lo pensamos un poco: ¿No es algo más razonable estimar el efecto de lo segundo?5\n\n\n5 Una mejor explicación de este enfoque y su contraparte (no recomendada), el análisis por protocolo pueden visitar este paper[esto] https://onlinelibrary.wiley.com/doi/10.1111/nep.13709\nTodos los grupos deben ser tratados igual: Por ejemplo, si en el ejemplo anterior invitamos a la gente del grupo de estatinas a controles médicos más seguidos, o los evaluamos con más dedicación, va a ser imposible separar los beneficios de la droga de los beneficios de las diferencias en cómo tratamos a los pacientes.\nBlinded: Para que las estimaciones de un experimento no se contaminen, resulta necesario que los participantes (o unidad experimental) no conozcan a que grupo experimental pertenecen. Esto es importante porque podría haber algún tipo de contaminación del efecto como por ejemplo que los sujetos que sepan que reciben la intervención se esfuercen para rendir mejor en el outcome o lo contrario al saberse “abandonados” al grupo control tiendan a rendir peor.\nDouble blinded: Siguiendo con lo mencionado antes, también resulta deseable que los investigadores tampoco sepan a que grupo experimental pertenece un sujeto o unidad experimental. Esto tiene como objetivo reducir al mínimo las diferencias entre los grupos. Por ejemplo, en un experimento para estimar la efectividad de una campaña de comunicación para motivar la vacunación, los investigadores podrían espaciar menos las comunicaciones con alguno de los grupos experimentales, contaminando así el efecto de la intervención en sí misma.\nPor supuesto que esto no siempre es posible. Por ejemplo, si un experimento quiere estimar la efectividad de una nueva cirujía laparoscopica versus su alternativa tradicional, resulta imposible que el cirujano que va a llevar adelante la misma no sepa a qué grupo pertenece el paciente. Sin embargo, es importante que en estos casos la asignación al grupo se retrase lo más posible disminuyendo la posible influencia de otros participantes (por ejemplo, un investigador podría estar más atento a la preparación preoperatoria de algún grupo experimental).\nMedir a todos los individuos: Todos los individuos que comenzaron el experimento deben ser medidos para evaluar el efecto del tratamiento. Esto no siempre pasa y es algo de lo que vamos a hablar más adelante en este capítulo.\n\nQue lindo es el diseño experimental. Todos somos felices, todo funciona. ¿El libro debería terminar acá?\n\n\n\n\n\nPues no mi ciela. Ojalá llevar adelante experimentos fuera tan fácil."
  },
  {
    "objectID": "exp_aleatorios.html#cuando-la-cosa-no-es-tan-ideal",
    "href": "exp_aleatorios.html#cuando-la-cosa-no-es-tan-ideal",
    "title": "5  Experimentos aleatorios",
    "section": "5.3 Cuando la cosa no es tan ideal",
    "text": "5.3 Cuando la cosa no es tan ideal\n\n5.3.1 Aleatorización por bloques\nIntuitivamente pensamos que la aleatorizacion de los sujetos a un grupo control o un grupo intervencion es tan simple como lanzar una moneda (y muchas veces lo es), este método se conoce como aletorización simple. Sin embargo puede que este método no sea siempre deseado. Por ejemplo, se quiere testear la ventaja de una intervención laparoscópica (mínimamente invasiva) sobre una cirugía tradicional (en la que se abre el abdomen). Es razonable pensar que los cirujanos se vuelven mejores con el tiempo sin importar a que tipo de cirugía, porque la práctica hace al maestro. Bueno imaginemos que aplicamos un proceso de aleatorización simple, es posible que los primeros sujetos sean asignados con más frecuencia al grupo intervencion que al grupo control y los últimos viceversa (ya que la randomizacion es un proceso independiente, la asignación del sujeto anterior no condiciona al que sigue, y esto es posible). En este escenario hipotetico pero posible, el ATE que queremos estimar se encuentra contaminado por una variable confusora (la habilidad del cirujano). ¿Cómo evitamos esto? Bueno una forma razonable es evitar que los sujetos se asignen al grupo todos juntos sino a medida que el cirujano va aprendiendo. Para hacer esto se pueden crear bloques temporales, por ejemplo, los 10 primeros voluntarios, los 10 siguientes y así sucesivamente. Dentro de cada bloque hacemos una asignación aleatoria, de esta forma nos aseguramos que haya un numero mas o menos balanceado de sujetos en el grupo control e intervencion expuestos al cirujano torpe, intermedio y master level.\n\n\n\n\n\n\n\n5.3.2 Spillover\nEn un experimento ideal, los sujetos son asignados aletoriamente a los grupos experimentales y se quedan ahí. El efecto spillover o derrame sucede cuando los sujetos del grupo control reciben en forma indirecta parte o todo el tratamiento que esta diseñado para el grupo de intervención. ¿Cómo es esto posible? Es muy posible, sobre todo en intervenciones conductuales. Pongamos ejemplos para que se entienda. Supongamos que queremos ver el efecto de una intervención educativa como hábitos saludables para prevenir cierta enfermedad, algunos sujetos son asignados a la intervención y reciben una charla educativa y otros nada. Un par de amigos (i y j) han sido aleatorizados a un grupo y al otro respectivamente. Al terminar la intervención el sujeto intervenido (i) le cuenta la charla al sujeto del grupo control (j) y este “recibe el tratamiento”. En este ejemplo un sujeto asignado a un grupo control recibe el tratamiento destinado al grupo intervención. Es decir, el grupo tratamiento ha derramado hacia el grupo control.\n\nVale la pena preguntarse por qué el spillover es relevante en los estudios aleatorizados. Si volvemos al capítulo 3 y a repasar outcomes potenciales podemos ver que este marco requiere una asuncion a la que llamamos SUTVA6 o en otras palabras este supuesto establece que los resultados potenciales del sujeto j dependen únicamente de su propio estado de tratamiento (el que fue asignado), sin verse afectados por el tratamiento recibido por otro sujeto i. Sin embargo esto no es así, ya que i es responsable del resultado potencial de j porque “le ha aplicado” el tratamiento. Al violar esta asunción, estimar el ATE a través de una diferencia de medias puede estar francamente sesgado por este efecto. El spillover es un efecto difícil de rastrear y sobretodo difícil de corregir, es frecuente en intervenciones que tienen que ver con comunicacion o informacion, ya que la comunicación fluye despues de la intervención de forma incontrolable para los investigadores. El mejor enfoque es preveer esta posibilidad e instaurar barreras a priori para disminuir el contagio que una intervención pueda tener sobr el grupo control.6 Del inglés stable unit treatment value assumption.\n\n\n5.3.3 Reversión de la cadena causal (o reverse causation)\nLa reversión causal es uno de los sesgos que pueden plagar nuestra interpretación de la cadena causa-efecto, sobre todo en los estudios observacionales.\nInventemos un escenario hipotético: pensemos que un investigador quiere evaluar si la lluvia caída aumenta la frecuencia de gente con paragüas en la calle. La respuesta es obvia para nosotros que conocemos las leyes de la naturaleza y que la gente odia mojarse. Cada vez que llueve, la gente sale a la calle con paragüas. Pero que pasa si nuestro investigador fuera un ser completamente ajeno a todo esto (digamos un batiduende de la 5ta dimensión) y no tuviera conocimiento alguno previo. Este ser, podría contar la frecuencia de paraguas en la calle y si llueve o no, hacer una regresión logística (por poner un ejemplo) para predecir la lluvia en función de la cantidad de paragüas de la calle y de seguro que sería un predictor significativo Y es más, podría cerrar su estudio concluyendo que un aumento de una unidad en la frecuencia de paragüas aumenta enun cierto porcentaje las chances de que lluve, o sea que los paragüas causan la lluvia. Nuestro batiduende investigador habría incurrido en un sesgo de causalidad inversa. Podríamos pensar por lo absurdo del ejemplo que este sesgo es dificil de que afecte a nuestras investigaciones, sin embargo es muy frecuente. Ejemplos de causalidad reversa son por ejemplo: observar que los barrios con propiedades mas costosas tienen un centro comercial y suponer que colocar un centro comercial en un barrio aumenta el valor de la vivienda, cuando lo que pasa es que los centros comerciales decidan colocarse en barrios con propiedades costosas; u observar que las personas que hacen más ejercicio tienen menos síntomas depresivos, e interpretar que hacer ejercicio reduce la depresión cuando podría ser que las personas menos deprimidas tienen más energía o motivación para hacer ejercicio.\nLos diseños experimentales pueden protegernos mejor que los estudios observacionales de este tipo de sesgo, por qué, fundamentalmente porque en nuestro diseño experimental vamos a aplicar la causa y esperar que la consecuencia suceda después de esto. Por regla general las causas no pueden ocurrir después que sus consecuencias y de esta manera la dirección de la causalidad es forzada hacia un solo lado. Sin embargo, el sesgo de causalidad inversa puede ocurrir aún así en un ensayo experimental bajo ciertas condiciones:\n\nNo cumplimiento del tratamiento (non-compliance) Supongamos que en el experimento se asigna aleatoriamente a algunos sujetos a recibir un tratamiento, por ejemplo una nueva terapia para la caida de cabello, pero los sujetos con mas caida de cabello en las primeras dosis del grupo tratamiento sienten que el tratamiento es inutil y dejan de tomar las pastillas . Este evento introduce un sesgo de causalidad inversa si analizamos a los sujetos por si tomaron el tratamiento o no (por protocolo en lugar de intention-to-treat) ya que el outcome (la caida del cabello) genera la exposicion (la cantidad de medicación que las personas en el grupo de tratamiento reciben.\nEfectos anticipados o comportamiento reactivo A veces, los participantes modifican su comportamiento en respuesta a saber su asignación. Ejemplo: alguien asignado al grupo control empieza a buscar alternativas por su cuenta (porque no recibió tratamiento), y eso afecta su resultado. O alguien en el grupo tratado ya anticipa que tendrá mejoríay cambia su comportamiento desde antes del tratamiento real. El resultado cambia en respuesta a la expectativa del tratamiento, y no necesariamente al tratamiento en sí.\nMediciones mal temporizadas En algunos experimentos, puede que la variable de outcome sea medida antes de que el tratamiento surta efecto, o incluso antes de aplicarlo bien. Si los resultados se usan para definir o cambiar el tratamiento asignado (por error o por diseño), ya no hay garantía de temporalidad: el resultado podría estar influyendo en el tratamiento.\n\n\n\n\n\n\n\nAdvertencia\n\n\n\nSi prestaron atención a las secciones anteriores sospecharan que muchos de estos sesgos de causalidad inversa puedan evitarse aplicando analisis ITT y asegurandonos un blinded adecuado, es así"
  },
  {
    "objectID": "exp_aleatorios.html#experimentos-between-groups",
    "href": "exp_aleatorios.html#experimentos-between-groups",
    "title": "5  Experimentos aleatorios",
    "section": "5.4 Experimentos between groups",
    "text": "5.4 Experimentos between groups\n\n\n\n\n\n\nHablemos un poco de la nomenclatura\n\n\n\n\n\n\nEn este capítulo definimos los experimentos aleatorizados como aquellos en los que se asigna al azar a los participantes a una condición de tratamiento o de control. Este enfoque corresponde, en realidad a un sólo tipo de diseño aletorizado, los diseños conocidos como between-groups.\nEn los experimentos between-groups, los participantes se distribuyen aleatoriamente entre diferentes condiciones de tratamiento, formando grupos que luego se comparan entre sí. Por ejemplo, se puede asignar a estudiantes a distintos métodos de enseñanza, a pacientes hipertensos a planes de dieta variados o a adultos mayores a programas de ejercicio físico.\nAntes de analizar los distintos tipos de diseños dentro de esta categoría, presentaremos algunas definiciones y notaciones clave.\nCuando querramos representar esquematicamente un diseño, vamos a recurrir a la notación clásica. Según esta, se representarán gráficamente tanto los experimentos aleatorizados como los cuasi-experimentos usando las letras \\(X\\) y \\(O\\). Una \\(X\\) indica la administración de un tratamiento, y una \\(O\\) representa una observación. Una \\(O\\) puede referirse a una observación de una o varias variables en un momento determinado. Una observación puede ser cualquier tipo de medición, ya sea un test escrito, un registro fisiológico, un informe verbal, o cualquier otra evaluación empírica. En estos diagramas, el tiempo (como la lectura) fluye de izquierda a derecha. Cuando se realizan varias observaciones, se utilizan subíndices en las \\(O\\) para indicar el momento de cada medición.\nUtilizando esta notación, el experimento aleatorizado entre grupos más simple se representa así:\n\n\n\\[\\begin{array}{lcl}\n\\text{R:} & X & O \\\\\n\\text{R:} &   & O \\\\\n\\end{array}\\]\n\n\nVamos a tratar de entender que significa esta notación, en principio hay dos líneas, esto indica que hay dos grupos, cada línea empieza con una \\(R\\), esto indica que los sujetos fueron asignados aleatoriamente (o random) a la participacion de ese grupo, vemos en la primera línea que ese grupo a recibido un tratamiento \\(X\\) y el otro no y que ambos grupos han sido evaluados posterior a ello en una instancia \\(O\\). Este diseño se conoce como post-test only o sólo post-test ya que como puede verse en este diseño la única medida que se toma es despues de la intervención.\nUna vez que hemos entendido este diseño sencillo podemos introducir otro un poco más complejo como este\n\\[\\begin{array}{lcl}\n\\text{R:}& O_1 & X & O_2 \\\\\n\\text{R:}& O_1 &   & O_2 \\\\\n\\end{array}\\]\nLa fila superior indica que un grupo es observado (\\(O_1\\)), luego recibe un tratamiento (\\(X\\)), y se observa nuevamente (\\(O_2\\)). La fila inferior muestra que un segundo grupo es observado, no recibe el tratamiento (aunque puede recibir uno alternativo), y luego es observado de nuevo. Nuevamente, la “\\(R:\\)” indica asignación aleatoria. (Lo ideal es realizar la asignación aleatoria después de la \\(O_1\\), así que la posición de “\\(R:\\)” no indica necesariamente el orden temporal, ya discutiremos el por qué de esto). En pocas palabras lo que diferencia este diseño del anterior es que existe una observación más, una antes de la intervención. Este tipo de diseño entonces se llama pretest-posttest Ahora que hemos introducido esquemáticamente los dos diseños fundamentales de los experimentos aletorizados entre grupos vamos a hablar de ello.\n\n5.4.1 Sólo posttest\nRecapitulemos, los diseños post-test only son la forma más simple de experimentos aletorizados entre grupos en donde un grupo es aleatoriamente asignado a una intervención, el otro a su condición de control, y posteriormente a ello se evalua el outcome. Resumiendo e la notación:\n\\[\\begin{array}{lcl}\n\\text{R:} & X & O \\\\\n\\text{R:} &   & O \\\\\n\\end{array}\\]\nEste diseño puede escribirse (y analizarse) utilizando un modelo lineal que tiene la siguiente forma:\n\\[\n\\begin{array}\n_Y_{i} &=& \\beta_0 + \\beta_T T_i + \\epsilon_{i}\n\\end{array}\n\\tag{5.1}\\]\nDonde \\(Y_i\\) es el valor de que adopta \\(O\\) (es decir nuestro outcome post-intervención), y \\(T_i\\) es una variable indicadora que toma el valor \\(1\\) si el participante pertenece al grupo tratamiento y el valor \\(0\\) si no y \\(\\epsilon_{i}\\) representa el término de error (varianza no explicada por el modelo). Para los modelos que veamos en estas secciones \\(\\epsilon_{i}\\) tiene una distribución \\(\\epsilon_{i} \\sim \\mathcal{N}(0, \\sigma_\\epsilon^2)\\),\nVamos a ver como podemos usar este diseño (y este modelo), para estimar el ATE.\n\n5.4.1.1 Un A/B test\nUn A/B test es un experimento aletorizado muy popular en el campo del diseño de páginas web. El mismo consiste en presentar a los usuarios con dos versiones del mismo sitio web (la versión A y la versión B) y medir su comportamiento en función de la versión que se les presenta. Por ejemplo, se puede medir el tiempo que los usuarios pasan en el sitio web, la tasa de clics en un botón o cualquier otra métrica relevante. La idea es comparar el rendimiento de las dos versiones para determinar cuál es más efectiva.\nEn nuestro ejemplo vamnos a asignar aleatoriamente a los usuarios a dos versiones distintas de un sitio web (la version anterior Website A o control, y la version nueva Website B o intervención) y mediremos el tiempo de permanencia en segundos. Es decir, queremos ver si el cambio de diseño de la página web tiene un efecto positivo en el tiempo que los usuarios pasan en el sitio. En este caso, el tiempo de permanencia es nuestro outcome y la variable de tratamiento es la versión del sitio web.\nVamos a simular los datos para \\(100\\) usuarios (50 en cada grupo) y luego vamos a estimar el ATE usando un modelo lineal. Como los datos son simulados, conocemos el efecto real de la intervención (el ATE) que es de \\(5\\) segundos. De hecho, sabemos que el tiempo promedio de permanencia en la versión A es de \\(50\\) segundos y en la versión B es de \\(55\\) segundos 7.7 asdfasdf\n\n\nVer el código\nset.seed(42)\n# Simulamos el experimento\nn <- 50 # Sujetos por condición\nt <- rnorm(2*n, 50, 10) # Variable que indica la exposición al tratamiento\nt_control <- t[1:n] # Tiempos del grupo control\nt_tratamiento <- t[(n+1):(2*n)] + 5 # Tiempos del grupo tratamiento\n\ndata <- tibble(tiempo = c(t_control, t_tratamiento),\n               condicion = c(rep(\"Website A\", n), rep(\"Website B\", n)))\n\ndata |>\n  ggplot(aes(x = condicion, \n             y = tiempo, \n             color = condicion)) +\n  geom_jitter(width = .2) + \n  scale_color_manual(values = c(\"#1380A1\", \"#ED6A5A\")) +\n  labs(x = NULL,\n       y = \"Tiempo (s)\", \n       color = NULL) +\n  theme_bw() +\n  theme(legend.position = \"top\")\n\n\n\n\n\nEn nuestro caso la versión del modelo de la ecuación Ecuación 5.2 es la siguiente:\n\\[\n\\begin{array}\n_t_{i} &=& \\beta_0 + \\beta_T T_i + \\epsilon_{i}\n\\end{array}\n\\tag{5.2}\\]\nDonde \\(t_i\\) es el tiempo de permanencia en segundos, y \\(T_i\\) es una variable indicadora que toma el valor \\(1\\) si el participante pertenece al grupo tratamiento (Website B) y el valor \\(0\\) si pertenece al grupo control (Website B). En este caso, \\(\\beta_T\\) representa la diferencia promedio entre los dos grupos, es decir, el ATE.\nAjustemos un modelo lineal y veamos cómo da la cosa.\n\n\nVer el código\nmodel_postets_only <- lm(data = data, tiempo ~ condicion, model = T)\nmodelsummary(list(\"A/B Postest only\"= model_postets_only),\n             coef_rename = c(\"condicionWebsite B\" = \"Website B\"),\n             statistic = c(\"Error estándar = {std.error}\"),\n             gof_omit = \".*\",)\n\n\n\n \n\n  \n    \n    \n    tinytable_drwszvl64uvhct1r2wsj\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n        \n              \n                 \n                A/B Postest only\n              \n        \n        \n        \n                \n                  (Intercept)\n                  49.643                \n                \n                \n                             \n                  Error estándar = 1.477\n                \n                \n                  Website B  \n                  6.364                 \n                \n                \n                             \n                  Error estándar = 2.089\n                \n        \n      \n    \n\n    \n\n  \n\n\n\n\nComo podemos ver, la estimación del efecto del tratamiento es de 6.36 segundos. Esto significa que la nueva versión del sitio web tiene un efecto positivo en el tiempo de permanencia de los usuarios en comparación con la versión anterior.\n¿Pero no era que el efecto real era de \\(5\\) segundos y que el \\(\\hat\\beta_T\\) era un estimador insesgado del efecto porque se trata de un experimento aleatorio?8 La respuesta es simple y complicada al mismo tiempo. Al simular los datos del experimento estamos tomando una muestra aleatorio y este \\(\\hat\\beta_T\\) no es más que una estimación, es decir, una realización. Esto tiene que ver con que si bien el parámetro \\(\\beta_T\\) vale \\(5\\) sus estimaciones no son siempre exactamente \\(5\\). Lo que si nos asegura el experimento aleatorizado es que el estimador \\(\\hat\\beta_T\\) es un estimador insesgado del parámetro \\(\\beta_T\\). Es decir, si repitiéramos el experimento muchas veces, la media de todas las estimaciones \\(\\hat\\beta_T\\) sería igual a \\(5\\).8 asdfasf\nComo simulamos los datos, podemos simular \\(1000\\) realizaciones del experiento y ver qué pinta tiene esto, ¿No?\n\n\nVer el código\n# Simulemos mil experimentos\n\nset.seed(42)\n# Simulamos el experimento\nn <- 50 # Sujetos por condición\n\nbetapostest <- c()\nbeta_T <- 5\nd <- c(rep(\"Website A\", n), rep(\"Website B\", n))\n\nfor (i in 1:1000) {\n  t <- rnorm(2*n, 50, 10) # Variable que indica la exposición al tratamiento\n  t_control <- t[1:n] # Tiempos del grupo control\n  t_tratamiento <- t[(n+1):(2*n)] + beta_T # Tiempos del grupo tratamiento\n  \n  data <- tibble(tiempo = c(t_control, t_tratamiento),\n                 condicion = d)\n  \n  model_postets_only <- lm(data = data, tiempo ~ condicion, model = T)\n  betapostest <- c(betapostest, coef(model_postets_only)[2])\n}\n\nbetas_post <- tibble(betapostest = betapostest)\nmean_beta <- betas_post |>\n  summarise(m_beta = mean(betapostest))\n\nbetas_post |>\n  ggplot(aes(x = betapostest)) +\n  geom_histogram(fill = \"#1380A1\", \n                 alpha = .6,\n                 bins = 30) +\n  geom_vline(xintercept = mean_beta$m_beta, \n             color = \"#1380A1\", \n             linewidth = 1) +\n  geom_label(data = mean_beta,\n            aes(label = paste(\"Efecto promedio =\", round(m_beta,2))),\n            x = 5, \n            y = 50)  +\n  labs(x = \"Estimación del efecto del tratamiento\",\n       y = NULL) +\n  theme_bw()\n\n\n\n\n\nBueno, el promedio de las mil estimaciones de \\(\\beta_T\\) es de 4.99, ya podemos dormir sin frazada.\n\n\n\n5.4.2 Pretest-posttest\n¿Les parece que al diseño simple de la sección anterior le falta algo? Hay algo que cualquiera que haya leído, planificado o llevado a cabo un experiemnto tiene en mente. Es más potente medir el outcome antes de la intervención y después de la intervención. Esto nos permite tener una mejor estimación del efecto del tratamiento, ya que podemos controlar por el efecto de la medición inicial. En este caso, el diseño se llama pretest-posttest y se representa así:\n\\[\\begin{array}{lcl}\n\\text{R:}& O_1 & X & O_2 \\\\\n\\text{R:}& O_1 &   & O_2 \\\\\n\\end{array}\\]\nPara analizar los resultados de este tipo de experimentos, tenemos que agregar de alguna forma la medida pre. Lo hacemos de la siguiente forma:\n\\[\n\\begin{array}\n_Y_{i} &=& \\beta_0 + \\beta_T T_i + \\beta_X X_i + \\epsilon_{i}\n\\end{array}\n\\tag{5.3}\\]\nDonde todo representa lo mismo que en la ecuación [#eq-postest_model], pero ahora \\(X_i\\) es la medida pre del sujeto \\(i\\). En este caso, \\(\\beta_T\\) representa de nuevo el efecto del tratamiento y \\(\\beta_X\\) representa el efecto de la medida pre.\nVeamos como se adaptaría el ejemplo de la sección anterior si agregamos una medición\n\n5.4.2.1 Midamos algo antes en el A/B test\nA los datos que simulamos anteriormente les vamos a agergar una nueva medida, el tiempo que están en el sitio web antes de la intervención. Vamos a suponer, igual que en el ejemplo anterior, que el tiempo promedio de permanencia en la versión A es de \\(50\\) segundos y en la versión B es de \\(55\\) segundos. Vamos a simular de nuevo los datos para \\(100\\) usuarios (\\(50\\) en cada grupo).\nEmpecemos mirando los datos como los vimos antes\n\n\nVer el código\n# Pretest-posttest ####\nset.seed(123)\nn <- 50\ntime_post <- rnorm(2*n, 50, 10)\ntime_pre <-time_post + rnorm(n,  0, 5)\n\ncontrol_pre  <- time_pre[1:n] \ntratamiento_pre  <- time_pre[(n+1):(2*n)]\ncontrol_post <- time_post[1:n] \ntratamiento_post <- time_post[(n+1):(2*n)] + 5\n\ndata_pre <- tibble(tiempo_pre = c(control_pre, tratamiento_pre),\n                   tiempo_post = c(control_post, tratamiento_post),\n                   condicion = c(rep(\"Website A\", n), rep(\"Website B\", n)))\n\ndata_pre %>% ggplot(aes(x = condicion, \n                        y = tiempo_post, \n                        color = condicion)) +\n  geom_jitter(width = .2) + \n  geom_smooth(method = \"lm\", se = F) +\n  scale_color_manual(values = c(\"#1380A1\", \"#ED6A5A\")) +\n  labs(x = NULL,\n       y = \"Tiempo post (s)\", \n       color = NULL) +\n  theme_bw() +\n  theme(legend.position = \"top\")\n#> `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nSe ve bastante parecido a lo que vimos antes ¿No? Tratemos de medir el efecto del tratamiento como lo hicimos en el ejemplo anterior, usando la ecuación [#eq-postest_model]. Si ajustamos ese modelo, que no tiene en cuenta a la medida pre, vamos a obtener las mismas estimaciones que en el ejemplo previo. Tiene sentido ¿No? Claro que sí, porque usamos la misma semilla para generar los datos.\n\n\nVer el código\nmodelo_pre_basico <- lm(data = data_pre, \n                        tiempo_post ~ condicion)\n\nmodelsummary(list(\"A/B Sin incluir el tiempo pre\"= modelo_pre_basico),\n             coef_rename = c(\"condicionWebsite B\" = \"Website B\"),\n             statistic = NULL, \n             gof_omit = 'DF|Deviance|R2|AIC|BIC|Log.Lik|F')\n\n\n\n \n\n  \n    \n    \n    tinytable_8a5vbiqvqt3nr25zt9oz\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n        \n              \n                 \n                A/B Sin incluir el tiempo pre\n              \n        \n        \n        \n                \n                  (Intercept)\n                  50.344\n                \n                \n                  Website B  \n                  6.120 \n                \n                \n                  Num.Obs.   \n                  100   \n                \n                \n                  RMSE       \n                  9.07  \n                \n        \n      \n    \n\n    \n\n  \n\n\n\n\n¿Esto está mal? Por supuesto que no. Pero miremos los datos, pero esta vez usando el tiempo pre como predictor.\n\n\nVer el código\ndata_pre %>% ggplot(aes(x = tiempo_pre, y = tiempo_post, color = condicion)) +\n  geom_jitter(width = .2) + \n  geom_smooth(method = \"lm\", se = F) +\n  scale_color_manual(values = c(\"#1380A1\", \"#ED6A5A\")) +\n  labs(x = \"Tiempo pre (s)\",\n       y = \"Tiempo post (s)\", \n       color = NULL) +\n  theme_bw() +\n  theme(legend.position = \"top\")\n#> `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nLo que podemos ver es que, debido a cómo simulamos los datos, el tiempo pre y el tiempo post están correlacionados, es decir, parte de la variabilidad que tenemos en el tiempo post la podemos explicar por diferencias en el tiempo pre. Entonces vamos a incorporar el tiempo pre como predictor en nuestro modelo. En este caso (usando la ecuación [#eq-pre_postest_model]). Comparemos las estimaciones de este modelo con las del de la ecuación [#eq-postest_model].\n\n\nVer el código\nmodelo_pre_basico <- lm(data = data_pre, tiempo_post ~ condicion)\nmodelo_pre <- lm(data = data_pre, tiempo_post ~ condicion + tiempo_pre)\n\nmodelsummary(list(\"A/B Sin incluir el tiempo pre\"= modelo_pre_basico,\n                  \"A/B Pretest-postest only\"= modelo_pre),\n             coef_rename = c(\"condicionWebsite B\" = \"Website B\",\n                             \"tiempo_pre\" = \"Tiempo-pre\"),\n             statistic = NULL, \n             gof_omit = 'DF|Deviance|R2|AIC|BIC|Log.Lik|F')\n\n\n\n \n\n  \n    \n    \n    tinytable_4kuzqm2e6xuhhy8eg6t7\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n        \n              \n                 \n                A/B Sin incluir el tiempo pre\n                A/B Pretest-postest only\n              \n        \n        \n        \n                \n                  (Intercept)\n                  50.344\n                  11.614\n                \n                \n                  Website B  \n                  6.120 \n                  5.236 \n                \n                \n                  Tiempo-pre \n                        \n                  0.789 \n                \n                \n                  Num.Obs.   \n                  100   \n                  100   \n                \n                \n                  RMSE       \n                  9.07  \n                  4.42  \n                \n        \n      \n    \n\n    \n\n  \n\n\n\n\nAhora el estimador del modelo pretest-postest es de 5.24 segundos. Una estimación más cercana al valor del parámetro \\(\\beta_T\\) que sabemos que es \\(5\\). Esto, como ya vimos en el ejemplo anterior, no significa que el estimador sea sesgado en el caso de no usar el timpo pre. Pero vamos a ver que la estimación es mejor y vamos a ver por qué.\nRepitamos la simulación de \\(1000\\) experimentos, pero ahora usando el modelo pretest-postest. Vamos a ver cómo se distribuyen las estimaciones de \\(\\beta_T\\) incluyendo y no incluyendo el tiempo pre.\n\n\nVer el código\n# Simulemos mil experimentos\n\nset.seed(123)\n# Simulamos el experimento\nn <- 50 # Sujetos por condición\n\nbetapostest <- c()\nbetaprepostest <- c()\nbeta_T <- 5\nd <- c(rep(\"Website A\", n), rep(\"Website B\", n))\n\nfor (i in 1:1000) {\n  time_post <- rnorm(2*n, 50, 10)\n  time_pre <- time_post + rnorm(n,  0, 5)\n  \n  control_pre  <- time_pre[1:n] \n  tratamiento_pre  <- time_pre[(n+1):(2*n)]\n  control_post <- time_post[1:n] \n  tratamiento_post <- time_post[(n+1):(2*n)] + beta_T\n  \n  data <- tibble(tiempo_pre = c(control_pre, tratamiento_pre),\n                     tiempo_post = c(control_post, tratamiento_post),\n                     condicion = d)\n  \n  model_postets_only <- lm(data = data, tiempo_post ~ condicion, model = T)\n  betapostest <- c(betapostest, coef(model_postets_only)[2])\n  \n  model_pre_postets <- lm(data = data, tiempo_post ~ condicion + tiempo_pre, model = T)\n  betaprepostest <- c(betaprepostest, coef(model_pre_postets)[2])\n}\n\nbetas <- tibble(beta = c(betapostest, betaprepostest),\n                modelo = c(rep(\"Posttest only\", 1000), rep(\"Pretest-posttest\", 1000)))\n\nmean_beta <- betas |>\n  group_by(modelo) |>\n  summarise(m_beta = mean(beta)) |>\n  mutate(ypos = c(50, 100))\n\nbetas |>\n  ggplot(aes(x = beta, fill = modelo)) +\n  geom_histogram(alpha = .5,\n                 bins = 30,\n                 position = \"identity\") +\n  geom_vline(data = mean_beta,\n             aes(xintercept = m_beta, \n                 color = modelo), \n             linewidth = 1) +\n  geom_label(data = mean_beta,\n            aes(label = paste(\"Efecto promedio =\", round(m_beta,2)),\n                y = ypos),\n            x = 5,\n            show.legend=FALSE)  +\n  scale_color_manual(values = c(\"#1380A1\", \"#ED6A5A\")) +\n  scale_fill_manual(values = c(\"#1380A1\", \"#ED6A5A\")) +\n  labs(x = \"Estimación del efecto del tratamiento\",\n       y = NULL,\n       fill = NULL,\n       color = NULL) +\n  theme_bw() +\n  theme(legend.position = \"top\")\n\n\n\n\n\nAcá viene lo importante. Podemos ver que cuando incluimos la medición del tiempo pre en el modelo, la distribución de las estimaciones de \\(\\beta_T\\) es más angosta. Esto significa que la variabilidad de las estimaciones es menor y que el error estándar de la estimación del efecto del tratamiento es menor. En otras palabras, al incluir la medición pre en el modelo, estamos reduciendo la varianza no explicada por el modelo y, por lo tanto, mejorando la precisión de nuestras estimaciones y con ella la potencia estadística de nuestro test.\nDe hecho, para \\(n\\) infinito podemos escibir una relación entre las varianzas no explicadas por los modelos que incluyen o no la tiempo pre. De lo que estamos hablando es de \\(\\sigma_\\epsilon^2\\) en ambos modelos, es decir, la varianza del término de error.\n\\[\n\\sigma^2_{\\epsilon \\,pre-post} = \\sigma^2_{\\epsilon \\, post} (1 - \\rho_{pre-post}^2)\n\\]\nDonde \\(\\sigma^2_{\\epsilon \\,pre-post}\\) es la varianza del término de error en el modelo que incluye la medida pre y \\(\\sigma^2_{\\epsilon \\, post}\\) es la varianza del término de error en el modelo que no incluye la medida pre. \\(\\rho_{pre-post}\\) es la correlación entre las medidas pre y post. Esta relación nos dice que al incluir la medida pre en el modelo, estamos reduciendo la varianza del término de error en un porcentaje igual a \\(1 - \\rho_{pre-post}^2\\). Esto significa que cuanto mayor sea la correlación entre las medidas pre y post, mayor será la reducción de la varianza del término de error y, por lo tanto, mayor será la mejora en la precisión de nuestras estimaciones y la potencia estadística de nuestros tests.\nEsta relación para n infinito podemos verla gráficamente en la siguiente figura. En la figura se muestra la relación entre la correlación entre las medidas pre y post y el error estándar de la estimación del efecto del tratamiento.\n\n\nVer el código\nerrores <- tibble(rho = seq(0, 1, 0.01),\n                  sigma_Ancova = (1-rho^2))\n\nerrores %>% ggplot(aes(x = rho,\n           y = sigma_Ancova)) +\n  geom_line(linewidth = 1) + \n  geom_hline(yintercept = c(0,1), linetype = \"dashed\") +\n  labs(x = \"Correlación entre pre y post\",\n       y = \"Error estándar de la estimación del efecto del tratamiento\") +\n  theme_bw()\n\n\n\n\n\nPodemos ver que con correlación \\(1\\) entre las medidas pre y post la potencia sería infinita, pero bueno, recordemos que esto es para n infinito."
  },
  {
    "objectID": "matching.html",
    "href": "matching.html",
    "title": "6  Subclasificación y matching",
    "section": "",
    "text": "En construcción 🚧",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Subclasificación y *matching*</span>"
    ]
  },
  {
    "objectID": "index.html#lo-que-vas-a-aprender-en-este-libro",
    "href": "index.html#lo-que-vas-a-aprender-en-este-libro",
    "title": "Diseños experimentales y cuasiexperimentales",
    "section": "Lo que vas a aprender en este libro",
    "text": "Lo que vas a aprender en este libro\nEl objetivo de este libro es acercar a los lectores y lectoras los conceptos básicos del diseño experimental y cuasiexperimental para que de esta manera sean capaces de diseñar sus propios experimentos para expresar y verificar efectivamente hipótesis científicas. Asimismo se busca generar intuiciones que les permitan evaluar diseños experimentales con los que se puedan encontrar tanto en la literatura científica como en cualquier dato obtenido experimentalmente que se les presente al momento de tomar una decisión.\nSe espera que los lectores y lectoras sean capaces de comunicar los diseños experimentales, sus resultados y las implicancias de los mismos de manera clara, concisa y “apta para todo público”. Asímismo, un concepto transversal es que no siempre es posible implementar un diseño experimental “ideal” (si este existiera) y que tomar decisiones informadas sobre los mismos (modelos estadísticos, métricas, diseños, etc.) es una parte importante de nuestra labor como generadores de evidencia o tomadores de decisión basada en evidencia.\n\n\n\n\n\n\nSIGA SIGA…\n\n\n\nSi bien los ejemplos que se presentan en el libro están orientados a las ciencias del comportamiento, su contenido puede ser adaptado a cualquier ciencia experimental, desde la biología hasta la economía.",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#qué-es-este-libro",
    "href": "index.html#qué-es-este-libro",
    "title": "Diseños experimentales y cuasiexperimentales",
    "section": "¿Qué es este libro?",
    "text": "¿Qué es este libro?\nEn este libro no vas a encontrar grandes desarrollos teóricos ni ejemplos complejos. Es simplemente una guía de lectura que tiene como objetivo ser la puerta de entrada para algunos conceptos clave del diseño experimental y la inferencia causal. Para esto vamos a chapotear en R y tidyverse, mojar las patas en la estadística, aguantar un poco la respiración en inferencia y potential outcomes, bucear en diseños aleatorizados (experimentos) para finalmente sumergirnos (con la idea de volver a salir a flote) en las profundas aguas del diseño cuasiexperimental y la inferencia causal.",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#lo-que-no-vas-a-aprender-en-este-libro",
    "href": "index.html#lo-que-no-vas-a-aprender-en-este-libro",
    "title": "Diseños experimentales y cuasiexperimentales",
    "section": "Lo que NO vas a aprender en este libro",
    "text": "Lo que NO vas a aprender en este libro\nEste libro no es un libro de inferencia estadística y no vamos a hablar de tests estadísticos sino en el contexto de una hipótesis científica y de un diseño experimental en particular. Es decir, este libro NO es un manual de estadística. Existen cientos de libros que desarrollan en detalle esos contenidos y para nada este libro pretende cubrir esos contenidos.\nEste libro tampoco es un manual de programación ni de análisis de datos en R. Si bien en la primera sección del libro haremos una presentación de algunas de las funcionalidades de la colección de paquetes para análisis de datos que es el tidyverse, no vamos a repasar ninguna de las bases de R ni de Rstudio. Existen infinidad de recursos invreíbles para aprender esto y sentimos que no hay necesida de, a eso, sumarle uno mediocre.",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#prerequisitos",
    "href": "index.html#prerequisitos",
    "title": "Diseños experimentales y cuasiexperimentales",
    "section": "Prerequisitos",
    "text": "Prerequisitos\nPara sacarle el jugo a los contenidos de este libro hace falta tener conocimientos básicos de probabilidad y estadística así como estar familiarizado con la programación en R. Ninguno de estos son obstáculos hoy en día ya que hay cientos de fuentes (libros, cursos, etc.) a las que el lector puede consultar previo o durante la lectura de este libro.\n\n\n\n\n\n\nDON’T PANIC\n\n\n\nEl libro comienza con un breve repaso de conceptos básicos de probabilidad y estadística y presenta los comandos básicos para correr códigos en R.",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#agradecimientos",
    "href": "index.html#agradecimientos",
    "title": "Diseños experimentales y cuasiexperimentales",
    "section": "Agradecimientos",
    "text": "Agradecimientos",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#contacto",
    "href": "index.html#contacto",
    "title": "Diseños experimentales y cuasiexperimentales",
    "section": "Contacto",
    "text": "Contacto\nAnte cualquier duda pueden contactarme vía e-mail a ispiousas@udesa.edu.ar.",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#licencia",
    "href": "index.html#licencia",
    "title": "Diseños experimentales y cuasiexperimentales",
    "section": "Licencia",
    "text": "Licencia\nEste sitio web es y siempre será gratuito, licencia bajo [CC BY-NC-ND 3.0 License]{https://creativecommons.org/licenses/by-nc-nd/3.0/us/}.",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "var_instrumentales.html",
    "href": "var_instrumentales.html",
    "title": "9  Variables instrumentales",
    "section": "",
    "text": "En construcción 🚧",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Variables instrumentales</span>"
    ]
  },
  {
    "objectID": "reg_discontinua.html",
    "href": "reg_discontinua.html",
    "title": "8  Regresión discontinua",
    "section": "",
    "text": "En construcción 🚧",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Regresión discontinua</span>"
    ]
  },
  {
    "objectID": "diff_in_diff.html",
    "href": "diff_in_diff.html",
    "title": "7  Diferencias en diferencias",
    "section": "",
    "text": "En construcción 🚧",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Diferencias en diferencias</span>"
    ]
  },
  {
    "objectID": "intro_stat.html",
    "href": "intro_stat.html",
    "title": "2  Repaso de probabilidad y estadística",
    "section": "",
    "text": "2.1 Variables aleatorias\nWasserman(Wasserman 2004) nos dice que una variable aleatoria es un mapeo entre el espacio de eventos y los números reales (\\(X:\\Omega \\rightarrow \\mathbb{R}\\)). Momento cerebrito ¿Esto que quiere decir? En términos prácticos, lo que implica es definición es que una variable aleatoria nos da un número para cada evento del posible espacio de eventos.\nVamos con un ejemplo. Supongan que tiramos una moneda justa dos veces y tenemos la variabla aleatoria \\(X\\) que cuenta la cantidad de caras (H)1. Los posibles eventos \\(\\omega\\) del espacio de eventos \\(\\Omega\\) son \\(\\Omega = \\{ TT, TH, HT, HH \\}\\). En este caso, la variable aleatoria \\(X\\) va a tomar los valores \\(X = \\{ 0, 1, 1, 2\\}\\) para cada \\(\\omega\\). Esto, en resumidas cuentas, es lo que hace una variable aleatoria.\nEl ejemplo anterior se trata de una variable aleatoria discreta, es decir, que sólo puede tomar algunos valores posibles, pero también existen variables aleatorias continuas como por ejemplo la altura de una nueva persona que nace.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Repaso de probabilidad y estadística</span>"
    ]
  }
]