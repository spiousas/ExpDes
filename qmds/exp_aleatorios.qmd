# Experimentos aleatorios {#sec-random-exp}

```{r}
#| echo: false
ggplot2::theme_set(ggplot2::theme_minimal(base_size = 13))
ggplot2::update_geom_defaults("point", list(color = "#1380A1",
                                            fill = "#1380A1",
                                            size = 3,
                                            alpha = .7))
ggplot2::update_geom_defaults("line", list(color = "#ED6A5A"))
ggplot2::update_geom_defaults("smooth", list(color = "#ED6A5A")) 

source("../R/_common.R")
```

El capítulo que sigue está en construcción `r emo::ji("construction")`. Por favor tengan paciencia.

## ¿Por qué son importantes los experimentos aleatorios?

En los experimentos aleatorios[^aleatorio] los sujetos son asignados a los grupos (por ejemplo, tratamiento y control) aleatoriamente. Esto significa que en la asignación de los grupos aleatorios hay involucrado un proceso realmente aleatorio, como arrojar un moneda. Ojo con confundir el concepto de asignación aleatoria con el de muestra aleatoria: Que el muestreo sea aleatorio significa que los participantes son una muestra seleccionada al azar de una población más amplia, mientras que la asignación aleatoria significa que los participantes, independientemente de si fueron seleccionados de una población más amplia o no, son asignados al azar a diferentes condiciones experimentales.

[^aleatorio]: A lo largo del capítulo vamos a usar de forma intercambiable las expresiones experimentos aleatorios y experimentos aleatorizados. También vamos a usar la sigla **RCT** del inglés *randomized controlled trials*.

::: {.callout-warning icon="false"}
## Sobre la aleatoridad de las computadoras

Cuando hablamos de un evento aleatorio, hablamos de una entidad abstracta cuyo resultado no se puede predecir exactamente. Para poner este tipo de eventos en el mundo real solemos hechar mano de ejemplos clásicos que involucran una complejidad fìsica tal que resulta imposible predecirlos exactamente, como arrojar un dado o una moneda. El ejemplo de la moneda es la forma más usual de hablar de una variable aleatoria con dos posibles valores equiprobables (aunque parezca que no tanto [@bartovs2023fair]). Sin embargo, esta aleatoridad es muy costosa de reproducir. Es por eso que las computadores utilizan lo que se llama generadores de números pseudo aleatorios[^pseudo-random]. Estos generadores utilizan series de números generados de forma pseudo aleatoria pero que puede ser recuperada determinìsticamente a partir de una "semilla". Es por eso que cuando simulamos datos en este libro lo primero que hacemos es ejecutar `set.seed(42)` (42 o el número que sea), para de esa forma poder obtener el mismo resultado cada vez que replicamos, o el lector quiere replicar, las simulaciones.

Dicho esto. A fines prácticos, es totalmente razonable utilizar un generador de números pseudo aleatorios para la asignación a grupos experimentales en los experimentos aleatorios.
:::

[^pseudo-random]: Para más información pueden ir a leer [esto](https://en.wikipedia.org/wiki/Pseudorandom_number_generator).

Por ejemplo, en el caso más simple, esto significa que dada una muestra de personas, vamos a asignar a cada de una de ellas "tirando una moneda" al grupo control ($D=0$) o tratamiento ($D=1$) como se ve en la siguiente figura.

![](imgs/exp_aleatorio.png){fig-align="center"}

Los experimentos aleatorios son el *gold-standard* para estimar el efecto de un tratamiento. De hecho, al ser la asignación aleatoria, podemos asegurar que, como mencionamos en el capítulo [@sec-pot-outcomes], existe independencia ($(Y^0, Y^1) \perp D$). Esto nos asegura que la diferencia de medias de los grupos tratamiento y control son un estimador consistente del **ATE**. Dicho esto, veremos que hay formas más "eficientes" de estimar el **ATE**, es decir, con mayo potencia estadística.

Hay una razón extra para que en este libro empecemos hablando en detalle de los experimentos aleatorizados, y es que cuando entremos de lleno en el mundo de los cuasiexperimentos nos será de gran ayuda entender cuál es el problema y cuál es la solución que se propone. Esto nos va a permitir tener una idea más concreta de las ventajas y limitaciones de cada uno de los diseños cuasiexperimentales que vamos a estudiar más adelante. 

En muchas ocasiones los experimentos aleatorios terminan siendo degradados a la categoría de cuasiexperimento. Por ejemplo: Supongamos que hay un estudio que quiere evaluar el efecto de un programa de *mindfulness* en la cantidad de hechos de violencia en un establecimiento educativo. Para esto se asigno aleatoriamente a diez escuelas al grupo *mindfulness* y diez escuelas al grupo control. Hasta acá todo muy lindo, deberíamos llevar adelante el programa, medir la cantidad de hechos de violencia en cada escuela, hacer la diferencia de medias y *voilá*, ya tenemos un estimador del **ATE**. Pero a veces las cosas no son tan sencillas y en el medio de este experimento van a pasar cosas. Por ejemplo, hay un grupo de colegios del grupo control que, por presión de los padres, incorporan un programa de *mindfulness* propio, mientras que otro grupo del colegios, esta vez del grupo tratamiento, deciden no implementar el programa de *mindfulness* propuesto por nosotros porque les interfiere con la curricula. Para colmo, varios colegios de ambos grupos deciden que la participación sea voluntaria. En fin, **el horror**. Lo que nos termina pasando es que, aunque el diseño sea un experimento aleatorio, la pérdida de control sobre la implementación y la participación voluntaria generan contaminación y sesgo de selección, degradando el estudio a un cuasiexperimento. Es decir, la comparación entre grupos ya no se basa en la aleatorización y vamos a requerir de otros controles estadísticos para corregir posibles sesgos. Más adelante vamos a charlar un poquito más de esto.

Dicho esto volvamos al maravilloso mundo de los `r emo::ji("rainbow")`experimentos aleatorizados ideales`r emo::ji("rainbow")`.

## El experimento ideal

El experimento ideal es ese experimento tan bien planificado, tan bien implementado y tan bien acatado por sus participantes que en la realidad nunca ocurre. Sin embargo, hay una excepción y son, en general, los _medical trials_. De hecho hay algunas características que esperaríamos ver en un **RCT** y son las siguientes.

* **Controles adecuados**: Si diseñamos un experimento para estimar el efecto de un tratamiento, debemos tener un grupo control adecuado con el que comparar. Por ejemplo, . Sin embargo, esto no significa que el *grupo control* sea siempre un grupo simplemente no expuesto al tratamiento. Por ejemplo, es muy conocido el ejemplo de la determinación de la efectividad de un fármaco, en los que al *grupo control* se le ofrece una pastilla que no contiene a la droga siendo estudiada sino unas pastilla de igual forma, tamaño y prescripción de consumo pero, típicamente, de azucar. Esto lo que nos permite es poder descontar el efecto de consumir un placebo en la estimación final de la efectividad del fármaco[^nocebo].

[^nocebo]: Si les interesa, también existen el efecto [nocebo](https://pmc.ncbi.nlm.nih.gov/articles/PMC4804316/) y [*know-cebo*](https://themicrodose.substack.com/p/the-power-of-know-cebo-5-questions?publication_id=371945&post_id=159587451&isFreemail=true&r=3zjda&triedRedirect=true).

* **Asignación aleatoria a los grupos experimentles**: Como vimos en el capítulo [@sec-pot-outcomes], la mejor forma de asegurar que los grupos control y tratamiento son lo más iguales posibles es asignando aleatoriamente a los participantes. Esto, junto con una cantidad de participantes suficiente nos asegura que ambos grupos son iguales en todos los factores que pueden influenciar el resultado del experimento, incluyendo los factores de los que no sabemos.

* **Los individuos deben ser considerados en el grupo asignado**: Los participantes asignados al grupo tratamiento deben ser considerados como tratamiento, independientemente de si se expusieron o no al mismo. Esto es conocidocomo el principio *intention to treat* y puede sonar un poco raro. Sin embargo, lo podemos pensar como un cambio del tratamiento que queremos evaluar. Por ejemplo, hay un experimento en el que se quiere evaluar el efecto de la estatinas en el colesterol LDL. Hay un grupo al que le dan estatinas y otro grupo al que le dan un placebo. Un $18%$ de los que fueron originalmente asignados al grupo estatinas dejó de tomarlas y un $38%$ de los que fueron asignados al grupo placebo empezó a tomar estatinas durante el trial. Esto significa que nuestro experimento no estimaría correctamente el efecto de *tomar* las estatinas, pero por otro lado, sí estimaría bien el efecto de *ser recetado* con estatinas. Y si lo pensamos un poco: ¿No es algo más razonable estimar el efecto de lo segundo?

* **Todos los grupos deben ser tratados igual**: Por ejemplo, si en el ejemplo anterior invitamos a la gente del grupo de estatinas a controles médicos más seguidos, o los evaluamos con más dedicación, va a ser imposible separar los beneficios de la droga de los beneficios de las diferencias en cómo tratamos a los pacientes.

* **Blinded**: Para que las estimaciones de un experimento no se contaminen, resulta necesario que los participantes (o unidad experimental) no conozcan a que grupo experimental pertenecen. Esto es importante porque podría haber algún tipo

* **Double blinded**: Siguiendo con lo mencionado antes, también resulta deseable que los investigadores tampoco sepan a que grupo experimental pertenece un sujeto o unidad experimental. Esto tiene como objetivo reducir al mínimo las diferencias entre los grupos. Por ejemplo, en un experimento para estimar la efectividad de una campaña de comunicación para motivar la vacunación, los investigadores podrían espaciar menos las comunicaciones con alguno de los grupos experimentales, contaminando así el efecto de la intervención en sí misma.

  Por supuesto que esto no siempre es posible. Por ejemplo, si un experimento quiere estimar la efectividad de una nueva cirujía laparoscopica versus su alternativa tradicional, resulta imposible que el cirujano que va a llevar adelante la misma no sepa a qué grupo pertenece el paciente. Sin embargo, es importante que en estos casos la asignación al grupo se retrase lo más posible disminuyendo la posible influencia de otros participantes (por ejemplo, un investigador podría estar más atento a la preparación preoperatoria de algún grupo experimental).

* **Medir a todos los individuos**: Todos los individuos que comenzaron el experimento deben ser medidos para evaluar el efecto del tratamiento. Esto no siempre pasa y es algo de lo que vamos a hablar más adelante en este capítulo.

Que lindo es el diseño experimental. Todos somos felices, todo funciona. ¿El libro debería terminar acá?

![](imgs/abogados.jpeg){fig-align="center" width=50%}

Pues no mi ciela. Ojalá llevar adelante experimentos fuera tan fácil.

## Cuando la cosa no es tan ideal

### Aleatorización por bloques

Por ejemplo, se quiere testear la ventaja de una intervención laparoscópica sobre una cirugía tradicionales. Es razonable pensar que los cirujanos se vuelven mejores con el tiempo, por eso no es razonable separar todos los pacientes de una, sino más bien por bloques temporales.

### *Spillover*

El concepto de *spillover*

### Reversión de la cadena causal (o *reverse causation*)

## Experimentos *between groups*

::: {.callout-warning icon="false"}
## Hablemos un poco de la nomenclatura
:::

### Sólo *posttest*

$$
\begin{array}
_Y_{i} &=& \beta_0 + \beta_T T_i + \epsilon_{i}
\end{array}
$${#eq-cluster_model}

Donde $T_i$ es una variable indicadora que toma el valor $1$ si el participante pertenece al grupo tratamiento y el valor $0$ si no.

### *Pretest-posttest*

## Diseños clúster

Los diseños clúster son una forma de diseño experimental donde los sujetos son asignados a grupos (clústeres) y luego se asignan tratamientos a esos grupos. Este enfoque es útil cuando no es práctico o posible asignar tratamientos a individuos de manera independiente. 

Las ventajas de los diseños cluster son varias:

* A veces puede resultar más práctico o conveniente asignar aleatoriamente a grupos que a individuos. Por ejemplo, en el sistema escolar nos pueden permitir asignar cursos o escuelas a distintos tratamientos pero no a estudiantes

* La aleatorización a nivel clúster puede ser útiles para minimizar los efectos de difusión, imitación de tratamientos u otros problemas de adherencia. Por ejemplo, para un estudiante es más difícil ser *crossover* si el tratamiento diferente lo tienen en otro aula o escuela en lugar de su compañero de banco.

* Pueden ser necesarios para evitar los *spillovers*. En el estudio de la campaña de SMSs para mejorar la tasa de vacunación contra el HPV hubieran hecho la aleatorización a nivel barrio o cioudad, no hubieran tenido el *spillover* debido a que un vecino te comenta del SMS que recibió.

* Pueden ser necesarios para evitar las externalidades. Por ejemplo, si se está haciendo un experimento para evaluar el efecto de un tratamiento dentro de un determinado grupo cerrado (una ciudad), el aumento de empleabilidad para el grupo tratamiento puede generar que haya menos empleos disponibles para el grupo control y que baje su tasa de empleo, no como consecuencia de ser menos “empleables”. Aleatorizando por ciudad se puede reducir este efecto.

* Algunos programas se aplican sí o sí a grupos. Por ejemplo, una campaña mediática, una terapia de grupo o un cambio de política a nivel escuela. 

* Los efectos pueden ser mayores cuando se aplican a todo un grupo. Esto tiene que ver con que debemos tener en cuenta que, si lo que queremos evaluar es una intervención que se va a aplicar a nivel grupo, si lo hacemos aleatorizando a nivel individual podemos estar subestimando su efecto. Por ejemplo, una intervención que mejore las habilidades de lectura de todo un curso puede tener un efecto sinergético que no estaría presente si sólo la mitad del curso está expuesto al tratamiento y la maestra debe alternar entre un subgrupo y el otro.

Algo muy importante es que la aleatorización a nivel clúster no significa que vamos a dejar de prestar atención a los individuos y utilizar medidas a nivel clúster. De hecho todo lo contrario, si bien vamos a aleatorizar a nivel grupo, vamos a medir el *outcome* para cada individuo y la relaciòn entre la variabilidad entre e intra grupos va a jugar un papel importante (más de esto en las siguietne secciones). En caso de que aleatoricemos a nivel grupo y después tomemos simplemente un *outcome* por grupo no estamos ante un diseño clúster sino que simplemente cambiamos la unidad experimental del individuo al grupo.

Todo parece ideal, ¿No? Pero nada de esto viene sin un costo. En general el costo es la potencia estadística. Es decir, para tener la misma potencia estadística que aleatorizando a nivel de individuo, vamos a necesitar más (y a veces muchos más) sujetos experimentales divididos en grupos. Más de eso en la sección que sigue.

### Análisis de datos jerárquicos

Para analizar este tipo de datos utilizamos modelos estadísticos que tienen en cuenta la estructura jerárquica de los datos. En este libro los vamos a llamar de forma general modelos jerárquicos[^nombres]. A continuación tenemos la estructura de un modelo lineal jerárquico con un sólo nivel de agrupamiento[^agrupamiento].

[^nombres]: También se pueden llamar *hierarchical linear models*, *linear mixed-effect model* , *mixed models*, *nested data models*, *random coefficient*, *random-effects models*, *random parameter models* o *split-plot designs*. Pero siempre estamos hablando de los mismo.

[^agrupamiento]: Por ejemplo, sirve para modelar los estudiantes de una escuela, pero también podríamos tener modelos que nos permitan modelar los estudiantes de una escuela, que a su vez pertenece a un distrito escolar, a una provincia, etc. Teniendo más niveles de agrupamiento, pero eso queda afuera del alcance de este libro.

$$
\begin{array}
_Y_{ij} &=& \mu_j + \epsilon_{ij} \\
\mu_j &=& \beta_0 + \beta_T T_j + r_j 
\end{array}
$${#eq-cluster_model}

Donde tanto $r_j$ como $\epsilon_{ij}$ tiene esperanza cero y varianza $\sigma^2_{inter-clúster}$ y $\sigma^2_{intra-clúster}$ respectivamente. En la ecuación anterior $T_j$ es una variable indicadora que toma el valor $1$ si la escuela, y no el participante como antes, pertenece al grupo tratamiento y el valor $0$ si no. De esta forma, si la escuela pertenece al grupo tratamineto su media será $\mu_{j|D_j=1} = \beta_0 + \beta_T + r_j$ mientras que si pertenece al grupo control será $\mu_{j|D_j=0} = \beta_0 + r_j$, y la esperanza de la diferencia entre ambas (dado que la esperanza de $E(r_j)=0$) será justamente la magnitud del efecto del tratamiento $\beta_T$. 

### La potenncia y la correlación intraclase (ICC)

La correlación intraclase (ICC) es una estadística descriptiva que indica en qué medida los resultados: 1) tienden a ser similares dentro de cada clúster, o 2) tienden a diferir entre distintos clústers, en relación con los resultados observados en otros grupos. Se define de la siguiente forma:

$$
ICC = \frac{\sigma^2_{inter-clúster}}{\sigma^2_{inter-clúster} + \sigma^2_{intra-clúster}}
$$

donde $\sigma^2_{inter-clúster}$ es la varianza entre clústers, es decir, cuánto se varían las medias de los clústers entre clústers, y $\sigma^2_{intra-clúster}$ es la varianza dentro de los clústers, es decir, cuánto varías las mediciones de cada individuo dentro de cada clúster.

Como mencionamos anteriormente, la aleatorización a nivel de clúster tiene su costo. Si los outcomes dentro de cada clúster están altamente correlacionados y la magnitud de los resultados varía considerablemente entre clústers, entonces es probable que los participantes dentro de un mismo grupo tengan resultados similares, y el ICC será alto. En estos casos, los datos provenientes de un individuo aportan casi tanta información como si se incluyera a todos los miembros. Por lo tanto, el tamaño muestral efectivo se aproxima más al número de clústers que al tamaño total de la muestra de individuoos.

Pasando en limpio. Si los clústers son más similares entre sí, el modelo estadístico será más potente, con un tamaño de muestra efectivo cercano a la cantidad de individuos mientras que si los clústers difieren mucho entre sí la potencia estadística cae, aproximándonos a un tamaño de muestra efectivo igual a la cantidad de clústers.

Es por esto último que en la práctica siempre conviene agergar más clústers que individuos[^potencia_cluster]. Pero claro, eso es lo que suele ser más costoso.

[^potencia_cluster]:Un ejemplo numérico, dado un total de $1000$ participantes, la potencia sería de $0.75$ si hubiera $50$ grupos de $20$ participantes cada uno, mientras que el poder sería sólo de $0.45$ con $20$ grupos de $50$ participantes cada uno, suponiendo un $ICC$ de $0.1$.

### Un ejemplo con datos

Simulemos un pequeño ejemplo. Supongamos que, sin un ápice de creatividad, queremos evaluar la efectividad de una intervención educativa que sólo se puede aplicar a nivel de escuela. El *outcome* de interés a nivel estudiante va a ser la nota obtenida en un examen estandarizado de matemáticas. Tengamos en cuenta la ecuación @eq-cluster_model, en nuestro caso $Y_{ij}$ sería la nota de cada estudiante, mientras que $mu_j$ sería la media de cada colegio.

Las medias de cada colegio las crearemos usitilizando los parámetros $beta_0 = 50$ y $beta_T = 10$, es decir, la magnitud del efecto que deberíamos recuperar luego es $10$. Además el error será $r_j \sim \mathcal{N}(0, \sigma_{escuelas}^2)$, con $\sigma_{escuelas} =   5$. Vamos a simular $40$ escuelas, asignando la mitad al grupo *tratamiento* y la otra mitad al grupo *control*. Veamos qué pasa con las medias de las escuelas que vamos a simular.

```{r}
#| code-fold: true
# Data jerárquica
set.seed(42)
n_escuelas <- 40

# Supongamos que tengo n_escuelas escuelas, cada una de ellas tiene una media de la calificacion de nota de matemática
mu_j <- rnorm(n_escuelas, 50, 5)
  
# Las primera 3 son asignadas al grupo tratamiento y las otrasa tres al grupo control
d <- c(rep("Tratamiento", n_escuelas/2), rep("Control",  n_escuelas/2))

# El efecto del tratamiento es 10, entonces a la media de cada escuela que pertenece al grupo tratamiento
# le sumamos 10
beta_T <- 10

# Armo un tibble con las escuelas
escuelas <- tibble(tratamiento = d, media = mu_j) |>
    mutate(media = if_else(tratamiento == "Tratamiento", media + beta_T, media)) 

# Graficamos los promedios de las escuelas
escuelas |>
  ggplot(aes(x = tratamiento, 
             y = media,
             color = tratamiento)) +
  geom_jitter(size = 2, 
              alpha = .6,
              width = .2) +
  scale_color_manual(values = c("#1380A1", "#ED6A5A")) +
  labs(color = NULL, x = NULL, y = "Media de la escuela j") +
  theme_bw() +
  theme(legend.position = "top")

```

Como era esperable, las medias de las escuelas en el grupo tratamiento están por encima de las medias en el grupo control. Sin embargo, hay escuelas para las que esto no es así. Es por eso que es muy importante modelar a la escuela (el clúster) como una posible fuente de variabilidad. 

Ahora lo que podemos hacer es simular las notas de los estudiantes dentro de cada colegio $Y_{ij}$. Para eso vamos a echar mano a la primera línea de la ecuación @eq-cluster_model. En este caso el $mu_j$ será el obtenido en el punto anterior con un $\epsilon_{ij} \sim \mathcal{N}(0, \sigma_{estudiante}^2)$, con $\sigma_{estudiante} = 10$. Veamos ahora qué pinta tienen estos datos.

```{r}
#| code-fold: true
#| fig-width: 9
#| fig-height: 12
# Data jerárquica

# Ahora vamos a muestrear 20 estudiantes en cada escuela, con media mu_j y un sigma de 10
alumnos <- tibble(tratamiento = rep(d, each = 20), 
                  order =rep(1:n_escuelas, each = 20),
                  escuela = rep(paste("Escuela", 1:n_escuelas), each = 20),
                  media = rep(mu_j, each = 20)) |>
  mutate(media = if_else(tratamiento == "Tratamiento", media + beta_T, media)) |>
  rowwise() |>
  mutate(Yij = rnorm(1, media, 10)) |>
  select(-media)

# Graficamos los promedios de las escuelas
alumnos |>
  ggplot(aes(x =  fct_reorder(escuela, desc(order)), 
             y = Yij,
             color = tratamiento)) +
  geom_jitter(size = 1, 
              alpha = .6,
              width = .2) +
  scale_color_manual(values = c("#1380A1", "#ED6A5A")) +
  labs(color = NULL, x = NULL, y = "Yij") +
  coord_flip() +
  theme(legend.position = "top")

```

Acá vemos que a la variabilidad de las escuelas se suma la variabilidad de los sujetos.

Ahora vamos a tratar de recuperar el tamaño del efecto ajustando un modelo lineal de efectos mixtos[^lmem].

[^lmem]: Sin entrar en demasiado detalle, un modelo lineal de efectos mixtos tiene en cuenta la estructura jerarquica del efecto. En este caso en particular vamos a permitirle al modelo que el punto medio de cada colegio sea considerado un *factor aleatorio*.

```{r}
#| code-fold: true
mlmer <- lmer(Yij ~ tratamiento + (1|escuela), data = alumnos)
modelsummary(list("Escuelas"= mlmer),
             coef_rename = c("tratamientoTratamiento" = "Tratamiento"),
             statistic = c("p = {p.value}"),
             gof_omit = ".*",)
```

Tratemos de entender qué nos dice este modelo. `(Intecept)` no es otra cosa que $\hat{\beta_0}$ que, de acuerdo a lo que simulamos, debería valer $50$, que era el valor del parámetro que usamos para generar las medias de las escuelas antes de sumarles el error $r_j$ y el efecto del tratamiento. Hablando del efecto del tratamiento, podemos ver que para esta simulación en particular, la estimación del efecto de la intervención $\beta_T$ que sabemos que vale $10$ es estimada como $\hat{\beta_T} = 12.92$. Otra cosa interesante que podemos ver es que el modelo también estima la variabilidad de los errores donde `SD (Intercept escuela)` es una estimación de $r_j$ y `SD (Observations)` es una estimación de $\epsilon_{ij}$, con un valor de $9.73$. Ambos valores de variabilidad son similares a los que usamos para hacer las simulaciones.

Pero... ¿Por qué el valor estimado del efecto es $\hat{\beta_T} = 12.92$ en lugar de $10$? Bueno, porque se trata de una simulación con su respectiva variabilidad. Por ejemplo, veamos qué pasa si simulamos $1000$ experimentos.

```{r}
#| code-fold: true
# Data jerárquica
set.seed(12)

n_escuelas <- 100
betalmer <- c()
beta_T <- 10
d <- c(rep("Tratamiento", n_escuelas/2), rep("Control",  n_escuelas/2))

for (i in 1:1000) {
  mu_j <- rnorm(n_escuelas, 50, 5)
  
  alumnos <- tibble(tratamiento = rep(d, each = 20), 
                    escuela = rep(paste("Escuela", 1:n_escuelas), each = 20),
                    media = rep(mu_j, each = 20)) |>
    mutate(media = if_else(tratamiento == "Tratamiento", media + beta_T, media)) |>
    rowwise() |>
    mutate(Yij = rnorm(1, media, 10)) |>
    select(-media)
  
  mlmer <- lmer(Yij ~ tratamiento + (1|escuela), data = alumnos)
  betalmer <- c(betalmer, fixef(mlmer)[2])
}

betas <- tibble(betalmer = betalmer)
mean_beta <- betas |>
  summarise(m_beta = mean(betalmer))

betas |>
  ggplot(aes(x = betalmer)) +
  geom_histogram(fill = "#1380A1", 
                 alpha = .6,
                 bins = 30) +
  geom_vline(xintercept = mean_beta$m_beta, 
             color = "#1380A1", 
             linewidth = 1) +
  geom_label(data = mean_beta,
            aes(label = paste("Efecto promedio =", round(m_beta,2))),
            x = 10, 
            y = 50)  +
  labs(x = "Estimación del efecto del tratamiento",
       y = NULL) +
  theme_bw()
```

Vemos que si hacemos un histograma de todas las estimaciones del parámetro en base a las $1000$ simulaciones de los datos, el promedio es `r round(mean_beta$m_beta,2)`, un valor bastante cercano al valor real de $10$[^simulaciones]. Ahora sí nos podemos quedar tranquilos.

[^simulaciones]: Recordemos que en la práctica **nunca** vamos a conocer el valor real del parámetro y que esa es un ventaja que sólo tenemos en estos casos en los que simulamos "muestras" a partir de valores conocidos de los parámetros.
