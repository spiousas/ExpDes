# Variables instrumentales {#sec-random-exp}

```{r}
#| echo: false
ggplot2::theme_set(ggplot2::theme_minimal(base_size = 13))
ggplot2::update_geom_defaults("point", list(color = "#1380A1",
                                            fill = "#1380A1",
                                            size = 3,
                                            alpha = .7))
ggplot2::update_geom_defaults("line", list(color = "#ED6A5A"))
ggplot2::update_geom_defaults("smooth", list(color = "#ED6A5A")) 

source("../R/_common.R")
```

Versión recontra en borrador, condumir con precaución `r emo::ji("construction")`

Así como Arquímedes dijo: “Dadme un punto de apoyo, y moveré el mundo,” con una variable instrumental lo suficientemente buena, se podría decir que es posible identificar cualquier efecto causal. Si bien esto es una hipérbole, el diseño de **variables instrumentales (VI)** es potencialmente uno de los diseños de investigación más importantes jamás concebidos. Es único porque es una de las pocas instancias en las que el estimador econométrico no fue simplemente "tomado prestado" de la estadística o importado de otro campo; las VI fueron inventadas por un economista, y su historia es fascinante.

## Historia de las Variables Instrumentales: Padre e Hijo

La historia de las variables instrumentales está entrelazada con la vida de Philip Wright (nacido en 1861, fallecido en 1934) y su hijo, Sewall Wright (nacido en 1889). Philip fue un prolífico autor en economía, publicando en revistas destacadas como *Quarterly Journal of Economics* y *American Economic Review*. Un tema recurrente en sus publicaciones fue el **problema de identificación**, que buscó resolver intensamente.

En 1928, Philip estaba escribiendo un libro sobre aceites animales y vegetales, motivado por la creencia de que los recientes aumentos arancelarios estaban dañando las relaciones internacionales. Este libro se convertiría en un clásico, no por su contenido sobre aranceles, sino por contener la primera prueba de la existencia de un estimador de variables instrumentales. El cálculo del estimador de variables instrumentales se desarrolló en un apéndice (Apéndice B) de este libro. Philip agradeció a su hijo por sus valiosas contribuciones, refiriéndose al **análisis de rutas** que Sewall le había enseñado, el cual jugó un papel clave en el Apéndice B.

Sewall Wright, por su parte, revolucionaba el campo de la genética, inventando el análisis de rutas, precursor de los modelos gráficos acíclicos dirigidos de Pearl. Historiadores han debatido la autoría del Apéndice B, ya que pudo haber sido escrito por cualquiera de los dos, dado que el libro era de economía (Philip) pero usaba el análisis de rutas (Sewall). Stock y Trebbi (2003) utilizaron un **análisis estilométrico** para determinar la autoría, un método similar a las técnicas contemporáneas de aprendizaje automático. Recopilaron escritos conocidos de ambos hombres, y analizaron la frecuencia de 70 palabras de función y 18 construcciones gramaticales en bloques de 1,000 palabras. Sus resultados, basados en un análisis de regresión, atribuyeron **todos los bloques del Apéndice B y el capítulo 1 a Philip, no a Sewall**.

Aunque la redacción y la solución del problema de identificación son técnicamente distintas, esta historia destaca que un estimador econométrico tan importante como las variables instrumentales tiene sus raíces en la economía. También resalta la posibilidad de superar diferencias a través de colaboraciones intelectuales entre padre e hijo.

## Intuición de las Variables Instrumentales

### El DAG Canónico de VI

Para entender el estimador de variables instrumentales, es útil comenzar con un **Diagrama Acíclico Dirigido (DAG)** que ilustra una cadena de efectos causales. Considere un camino de puerta trasera entre una variable de tratamiento \(D\) y una variable de resultado \(Y\): \(D \leftarrow U \rightarrow Y\), donde \(U\) es una variable no observada por el econometrista. Si existe este tipo de **selección en variables no observables**, ninguna estrategia de condicionamiento (control) satisfará el criterio de puerta trasera con los datos disponibles.

Aquí es donde entra la variable instrumental \(Z\). El diseño de VI busca **aislar la variación** en el tratamiento que es puramente exógena, es decir, que no está influenciada por factores de confusión no observados. Piense en ello como un molde que permite que solo la forma deseada (el efecto causal) se manifieste, en lugar de esculpir el mármol quitando la variación indeseable. Un buen instrumento imita un experimento aleatorizado.

La intuición clave es que \(Z\) afecta a \(Y\) **"solo a través de"** \(D\). Esto significa que si \(Z\) varía, causa que \(D\) varíe, lo que a su vez causa que \(Y\) cambie, pero *solo* debido a la variación en \(D\). En otras palabras, \(Z\) debe ser **independiente de las variables que determinan \(Y\) excepto por \(D\)**. Esta es la **restricción de exclusión**. Además, \(Z\) debe estar correlacionada con \(D\); esta relación se conoce como la **primera etapa**.

### Los Buenos Instrumentos Deben Parecer Extraños

¿Cómo saber si tiene un buen instrumento? Primero, requiere **conocimiento previo**. Debe poder defender teórica y lógicamente la **restricción de exclusión**, ya que es un supuesto no testeable. Los microeconomistas aplicados son cada vez más escépticos con las VI porque pueden contar historias ilimitadas en las que las restricciones de exclusión no se cumplen.

Una condición necesaria (aunque no suficiente) para un instrumento válido es que la gente se confunda cuando usted les explique su relación con el resultado. Por ejemplo, a nadie le sorprendería que el tamaño de la familia reduzca la oferta laboral de las mujeres. Pero, ¿qué pensarían si les dijera que las madres cuyos dos primeros hijos eran del mismo sexo trabajaban menos fuera del hogar que aquellas con un ratio de sexos equilibrado?. Esto es "extraño", ya que la composición de género no parece lógicamente cambiar los incentivos laborales. Sin embargo, empíricamente, las familias con dos hijos del mismo sexo son más propensas a tener un tercero buscando diversidad de género, lo que afecta el tamaño de la familia y, por ende, la oferta laboral.

El "instrumento extraño" (tener dos niños o dos niñas) solo cambia el resultado (oferta laboral) al cambiar primero una variable de tratamiento endógena (tamaño de la familia). Sin conocimiento de la variable endógena, la relación entre el instrumento y el resultado no tiene sentido. Esto se debe a que el instrumento es irrelevante para los determinantes del resultado excepto por su efecto en la variable de tratamiento endógena. Los buenos instrumentos suelen ser **cuasi-aleatorios**.

Compare esto con un mal instrumento: si conocer a Kanye West te llevara a la fama. Esto sería un mal instrumento para el éxito musical, ya que hay muchas formas directas en que Kanye West puede afectar el éxito de un músico, sin pasar por una única variable de tratamiento, violando la restricción de exclusión. En resumen, los buenos instrumentos son **chocantes** precisamente por la restricción de exclusión; si la relación fuera obvia, la restricción de exclusión probablemente estaría violada.

## Efectos de Tratamiento Homogéneos y los Estimadores de Dos Etapas de Mínimos Cuadrados (2SLS)

Las VI se utilizan típicamente para abordar el **sesgo por variables omitidas**, el **error de medición** y la **simultaneidad**. Por ejemplo, en el caso de la cantidad y el precio, que se determinan por la intersección de la oferta y la demanda, cualquier correlación observacional entre ellos no es informativa sobre las elasticidades de la oferta o la demanda. Philip Wright entendió este problema profundamente.

Asumiremos un **efecto de tratamiento homogéneo** \(\delta\), que es el mismo para cada persona. Consideremos el problema clásico laboral de estimar el efecto causal de la escolaridad (\(S\)) en los ingresos (\(Y\)). La escolaridad es endógena debido a la **habilidad no observada** (\(A\)). El modelo verdadero sería:
\[ Y_i = \alpha + \delta S_i + \gamma A_i + \varepsilon_i \]
Donde \(\varepsilon\) es un término de error no correlacionado con \(S\) o \(A\). Si \(A\) no se observa, estimamos:
\[ Y_i = \alpha + \delta S_i + \eta_i \]
Donde \(\eta_i = \gamma A_i + \varepsilon_i\). Si \(S\) está correlacionada con \(A\), entonces \(S\) está correlacionada con \(\eta_i\), haciéndola endógena y sesgando la estimación de OLS.

Si encontramos un instrumento \(Z_i\) que causa más escolaridad pero es independiente de la habilidad (\(A\)) y del término de error estructural (\(\varepsilon\)), podemos estimar \(\delta\). El estimador de VI se puede expresar como el **cociente de la covarianza de \(Y\) y \(Z\), y la covarianza de \(S\) y \(Z\)**:
\[ \widehat{\delta} = \dfrac{C(Y,Z)}{C(S,Z)} \]
Esto es válido siempre que \(C(A,Z)=0\) y \(C(\varepsilon,Z)=0\), lo cual es el contenido estadístico de la **restricción de exclusión**: el instrumento debe ser independiente de ambas partes del término de error compuesto.

Pero la restricción de exclusión es solo una condición necesaria, no suficiente. El instrumento debe estar **altamente correlacionado** con la variable endógena \(S\) (la **primera etapa** debe ser fuerte). El numerador se llama a veces **forma reducida** (la relación entre el instrumento y el resultado), y el denominador es la **primera etapa**. Si \(Z\) no es independiente de \(\eta\), o si la correlación entre \(S\) y \(Z\) es débil, el estimador \(\widehat{\delta}\) estará severamente sesgado en muestras finitas.

##### 7.3.1 Dos Etapas de Mínimos Cuadrados (2SLS)

El estimador de **Dos Etapas de Mínimos Cuadrados (2SLS)** es uno de los estimadores de VI más intuitivos. Dada la instrumentación de \(S\) con \(Z\), se descompone en dos pasos:
1.  **Primera etapa:** Se predice la variable de tratamiento (\(S\)) usando el instrumento (\(Z\)) y otros controles.
    \[ S_i = \gamma + \beta Z_i + \epsilon_i \]
2.  **Segunda etapa:** Se usan los valores predichos de \(S\) (denotados \(\widehat{S}\)) para estimar el efecto sobre el resultado (\(Y\)).
    \[ Y_i = \alpha + \delta \widehat{S}_i + \varepsilon_i \]
La intuición de 2SLS es que utiliza **solo la variación en la escolaridad que es exógena**, impulsada por el instrumento. Es como un experimento: al aislar la variación de \(S\) impulsada por \(Z\), estamos identificando efectos causales de cambios exógenos en \(S\). Sin embargo, esta variación exógena es solo un subconjunto de la variación total en la escolaridad, lo que reduce la información disponible para la identificación y puede generar errores estándar más grandes.

## El Problema de los Instrumentos Débiles

Un **instrumento débil** es aquel que, aunque válido, predice la variable de tratamiento de manera insuficiente. Cuando la covarianza entre \(Z\) y \(X\) (\(Cov(Z,X)\)) es pequeña, el estimador de IV (\(Cov(Z,Y)/Cov(Z,X)\)) tiende a ser inestable y tener una alta variabilidad de muestreo. Además, el sesgo de 2SLS se acerca al sesgo de OLS si el instrumento es débil.

La forma más común de verificar la **relevancia** del instrumento es la **estadística F de la primera etapa**. Si esta estadística es baja, sugiere que el instrumento es débil. Bound, Jaeger, y Baker (1995) demostraron que añadir más instrumentos con poco poder predictivo puede hacer que la estadística F de la primera etapa se acerque a cero, aumentando el sesgo de 2SLS. Por ejemplo, en su replicación del estudio de Angrist y Krueger (1991) sobre la escolaridad, mostraron que al agregar instrumentos (como las interacciones de trimestre de nacimiento con el año), la estadística F de la primera etapa caía significativamente, señalando un problema de instrumentos débiles.

No existe un corte único para la estadística F, ya que el valor deseado depende de la cantidad de sesgo que uno esté dispuesto a aceptar. Stock y Yogo (2005) proporcionan tablas que relacionan la estadística F con el sesgo relativo de IV respecto al sesgo de OLS. Una regla general común, aunque muy aproximada, es que la estadística F debe ser 10 o superior.

Si se enfrenta a un problema de instrumentos débiles, las opciones son limitadas. Se podría usar un modelo justo identificado con el IV más fuerte, o un estimador de máxima verosimilitud de información limitada (LIML), que es aproximadamente insesgado para modelos de efectos constantes sobreidentificados. Sin embargo, la **verdadera solución para un problema de instrumentos débiles es conseguir mejores instrumentos**.

## Efectos de Tratamiento Heterogéneos

Relajando el supuesto de que los efectos de tratamiento son los mismos para todos, introducimos los **efectos de tratamiento heterogéneos**, donde \((Y_i^1 - Y_i^0 = \delta_i)\) varía para cada individuo \(i\). Esto es crucial porque introduce una tensión entre la **validez interna** (el efecto causal se identifica para la población estudiada) y la **validez externa** (el hallazgo se aplica a poblaciones diferentes). Bajo efectos homogéneos no hay tensión, pero bajo heterogeneidad la tensión es enorme y puede minar la relevancia del efecto estimado.

Para la identificación bajo efectos heterogéneos, se requieren **cinco supuestos**:
1.  **Supuesto de Valor de Tratamiento Unitario Estable (SUTVA):** Establece que los resultados potenciales para cada persona \(i\) no están relacionados con el estado de tratamiento de otros individuos. Rara vez se menciona o se toma en serio en estudios aplicados.
2.  **Supuesto de Independencia:** El instrumento es independiente de los resultados potenciales y de las asignaciones de tratamiento potenciales. A menudo se describe como una asignación "tan buena como aleatoria". Este supuesto es suficiente para una interpretación causal de la forma reducida.
3.  **Restricción de Exclusión:** Cualquier efecto de \(Z\) sobre \(Y\) debe ser a través del efecto de \(Z\) sobre \(D\). Formalmente: \(Y_i(D_i,0) = Y_i(D_i,1)\). La aleatoriedad del instrumento (independencia) no implica automáticamente la restricción de exclusión.
4.  **Primera Etapa:** \(Z\) debe estar correlacionada con la variable endógena \(D\), de modo que \(E[D_i^1 - D_i^0] \ne 0\). Este es el único supuesto testeable directamente a partir de los datos.
5.  **Monotonicidad:** Requiere que la variable instrumental opere (débilmente) en la misma dirección para todas las unidades individuales. Es decir, si afecta a alguien, siempre lo hace en la misma dirección (positiva o negativa, pero no ambas). Sin este supuesto, los estimadores de IV no garantizan estimar un promedio ponderado de los efectos causales subyacentes del grupo afectado. Esto es importante porque si existen **"Defiers"** (personas que se ven afectadas en la dirección opuesta a lo esperado por el instrumento), el estimador de IV pierde su interpretación como un promedio.

Si se satisfacen los cinco supuestos, se tiene una estrategia de VI válida. Sin embargo, bajo efectos de tratamiento heterogéneos, el estimador de VI ya no recupera el efecto de tratamiento promedio (ATE) para toda la población, sino un **efecto de tratamiento promedio local (LATE - Local Average Treatment Effect)**.
\[ \delta_{IV,LATE} = E\big[(Y_i^1-Y_i^0)\mid D_i^1-D_i^0=1\big] \]
El LATE es el efecto causal promedio de \(D\) sobre \(Y\) para aquellos cuya situación de tratamiento fue cambiada por el instrumento \(Z\). Estas personas se conocen como **"Compliers"** (cumplidores). No identifica el efecto causal en los **"Always-takers"** (siempre-tomadores, quienes siempre reciben el tratamiento independientemente del instrumento) ni en los **"Never-takers"** (nunca-tomadores, quienes nunca reciben el tratamiento). Esto es importante porque el ATE poblacional es a menudo el de mayor interés, pero no siempre es posible con IV.

El **LATE** es "local" en el sentido de que es el efecto de tratamiento promedio solo para los compliers. En contraste, en el diseño tradicional de IV con efectos homogéneos, los compliers tienen los mismos efectos de tratamiento que los no-compliers, por lo que la distinción es irrelevante.

Ahora, exploremos algunas aplicaciones reales de las variables instrumentales.

## Ejemplo: Conscripción y Crimen: Evidencia de la Lotería del Servicio Militar Obligatorio en Argentina

Este ejemplo se basa en el estudio de Galiani, Rossi, y Schargrodsky (2010), que busca estimar el efecto causal de la participación obligatoria en el servicio militar en las actividades delictivas.

**Contexto del Problema:**
Se ha afirmado que el servicio militar obligatorio (conscripción) podría tener un impacto en el comportamiento criminal de los jóvenes. Existen hipótesis contradictorias: podría tener una influencia positiva al enseñar disciplina, mejorar la salud y las perspectivas laborales, o incapacitar la comisión de delitos al mantener a los jóvenes en instalaciones militares. Alternativamente, podría tener una influencia negativa al retrasar la inserción laboral, proporcionar entrenamiento con armas o crear un ambiente social propenso a respuestas violentas y efectos negativos de pares. La literatura previa se centró principalmente en veteranos de guerra (como el draft de Vietnam), lo que podría introducir sesgos por el trauma de combate. El objetivo de este estudio es estimar el efecto causal del servicio militar en **tiempos de paz**.

**El Experimento Natural y el Instrumento:**
Para identificar el efecto causal, los autores explotan la **asignación aleatoria de jóvenes al servicio militar en Argentina a través de una lotería de conscripción**. El servicio militar fue obligatorio en Argentina de 1901 a 1995. La elegibilidad se asignaba anualmente mediante una lotería que emparejaba un número (del 1 al 1,000) con los últimos tres dígitos del documento de identidad nacional de los individuos. Después, se anunciaba un número de corte: aquellos con números de lotería por encima del corte y que pasaban un examen médico eran llamados a servir. El instrumento en este estudio es la variable dummy **"Draft Eligible" (Elegible para el Servicio Militar)**, que toma el valor de uno si el número de lotería asignado a un individuo lo hacía elegible, y cero en caso contrario. Por diseño, esta variable se asigna aleatoriamente.

**Datos Utilizados:**
Los autores utilizaron un conjunto único de **datos administrativos**.
*   **Registros criminales:** Información sobre todos los hombres con antecedentes penales en el sistema de justicia para adultos desde 1934 hasta 2005 (aproximadamente un millón de observaciones), incluyendo los últimos tres dígitos del DNI y el año de nacimiento. Un antecedente penal significa que el individuo fue procesado o condenado por un delito. Otro conjunto de datos, más corto (2000-2005), incluye el **tipo de delito** (armas, propiedad, ataque sexual, etc.).
*   **Datos de servicio militar:** Resultados de la lotería del servicio militar, estado del servicio militar y números de corte del Ejército Argentino.
*   **Datos del mercado laboral:** Participación en el mercado laboral formal (contribuciones a la seguridad social), tasas de desempleo e ingresos (derivados de la ocupación declarada en el registro nacional de votantes de 2003).

La unidad de observación principal es la combinación de cohorte de nacimiento y los últimos tres números de identificación. Los autores se enfocan en las cohortes de 1958 a 1962, para las cuales tienen información tanto sobre la intención de tratar como sobre el estado de tratamiento real. También se dispone de datos sobre características previas al tratamiento para estas cohortes, como origen y distrito de residencia.

**Validación de la Aleatoriedad:**
Aunque la elegibilidad se asignó aleatoriamente, los autores examinaron si las **características previas al tratamiento estaban equilibradas** entre los grupos elegibles y exentos. La Tabla 2 (fuente: NDL2010-055.pdf) muestra que, para la mayoría de las variables, **no hay diferencias estadísticamente significativas**, lo que sugiere que la aleatorización de la elegibilidad tuvo éxito. En los pocos casos de diferencias significativas, estas eran pequeñas y no alteraban los resultados principales al incluirse como controles.

Los autores también analizaron los resultados de los exámenes médicos previos a la inducción. Aunque las tasas de fracaso eran más altas para el grupo elegible (Tabla 3), esto se debía a que los individuos con números bajos (no elegibles) tenían menos incentivos para falsear sus condiciones médicas. Cuando se controló por estas diferencias de incentivos (examinando solo a los individuos con números de lotería cercanos al corte), las tasas de fracaso se equilibraron, lo que **proporciona más evidencia de la exogeneidad de la elegibilidad** y sugiere que los exámenes médicos fueron manipulados. Esta manipulación hace que el estado de servicio militar sea endógeno, pero no afecta la consistencia del estimador de IV.

**Resultados Principales - Primera Etapa:**
Los resultados de la primera etapa (Tabla 4 en la fuente) muestran una **fuerte relación entre la elegibilidad para el servicio militar y la probabilidad de servir**. Para los hombres de las cohortes de 1958 a 1962, la probabilidad de servir en el ejército fue **66 puntos porcentuales más alta** para los del grupo elegible en comparación con los exentos. Todos los efectos de la primera etapa están estimados con gran precisión y son significativamente diferentes de cero.

**Resultados Principales - Efecto en la Criminalidad (LATE):**
El estimador de VI, bajo supuestos razonables (incluida la monotonicidad), recupera el **Efecto de Tratamiento Promedio Local (LATE)**. En este contexto, el LATE es el efecto promedio de la participación en el servicio militar en aquellos individuos cuyo estado de tratamiento fue inducido a cambiar por el instrumento: los **"compliers"** (cumplidores). Estos son hombres que sirvieron porque fueron asignados a un número de lotería alto, pero no habrían servido de otra manera. Los resultados, por lo tanto, **no necesariamente se generalizan a la población de voluntarios o a aquellos que nunca habrían servido**.

Los resultados de 2SLS (Tabla 5 en la fuente) indican que el **servicio militar obligatorio aumenta significativamente las tasas de criminalidad**. Los estimadores 2SLS preferidos en la columna (4) muestran que el servicio militar aumenta las tasas de criminalidad en un **3.96%**. Esto implica que la conscripción elevaría la probabilidad de ser procesado o condenado en la vida adulta en 0.27 puntos porcentuales, desde una tasa de referencia del 6.8% a un 7.07%. En términos porcentuales, esto es aproximadamente un tercio del efecto positivo de un año adicional de escolaridad en la reducción de la encarcelación.

**Análisis de Heterogeneidad y Canales:**
*   **Servicio en tiempos de paz vs. guerra:** El efecto de la conscripción sobre el crimen es **mayor para aquellos reclutas en las cohortes que participaron en la Guerra de Malvinas** (1982), aunque el efecto sigue siendo significativo para las cohortes que sirvieron en tiempos de paz, que constituyen la mayor parte de la muestra (Tabla 6). Esto destaca la distinción entre el trauma de combate y los efectos generales de la conscripción.
*   **Duración del servicio:** El efecto sobre el crimen fue **mayor para quienes sirvieron en la Armada (dos años) en comparación con el Ejército o la Fuerza Aérea (un año)** (Tabla 6). Este resultado es consistente con la hipótesis de que las experiencias tempranas en el mercado laboral son un canal a través del cual el servicio militar afecta el comportamiento criminal.
*   **Tipo de delito:** El servicio militar aumenta la probabilidad de desarrollar un expediente criminal, especialmente para **delitos pecuniarios** (contra la propiedad y de cuello blanco) (Tabla 7). Esto apoya la idea de que la conscripción podría afectar negativamente las perspectivas laborales de los jóvenes, llevándolos a cometer este tipo de delitos.
*   **Resultados en el mercado laboral:** El estudio encuentra que los hombres que sirvieron en el ejército tienen una **menor probabilidad de participar en el mercado laboral formal, una tasa de desempleo más alta (aunque no significativa) y menores ingresos futuros** (Tabla 8). Estos hallazgos de efectos perjudiciales a largo plazo en el mercado laboral respaldan la hipótesis de que la conscripción aumenta la criminalidad a través de este canal.

**Pruebas de Falsificación (Experimentos Falsos):**
Para reforzar la exogeneidad del instrumento, los autores realizaron tres "experimentos falsos":
1.  **Restricción a números de lotería bajos:** Dividieron el grupo no elegible por la mediana y asignaron un "falso estatus de tratamiento". No encontraron diferencias en las tasas de criminalidad entre estos grupos, lo que confirma la aleatoriedad de la lotería.
2.  **Cohortes no reclutadas:** Analizaron las cohortes de 1956 y 1957, que saltaron el servicio militar debido a un cambio de edad. Al imputarles resultados de lotería de cohortes posteriores, no se observaron diferencias significativas en las tasas de criminalidad, como era de esperar.
3.  **Lotería sin incorporación:** La cohorte de 1976 pasó por la lotería pero no fue incorporada al servicio militar. Al crear un "falso número de corte", no se encontraron diferencias en las tasas de criminalidad entre los grupos "elegibles" y "no elegibles" falsos. Esta prueba es importante porque aborda la preocupación de que el resultado de la lotería pudiera tener un efecto directo en la moral de los jóvenes, independientemente de la participación real en el servicio.

En conclusión, este estudio demuestra de manera convincente un **efecto causal de la conscripción en tiempos de paz en el aumento de la probabilidad de desarrollar un expediente criminal**. Los hallazgos sugieren que, a pesar de los posibles beneficios (disciplina, incapacitación), los mecanismos que operan en la dirección opuesta (retraso en la inserción laboral) dominan, llevando a mayores tasas de criminalidad, especialmente en delitos pecuniarios.
